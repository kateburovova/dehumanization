{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/katerynaburovova/PycharmProjects/dehumanization/annotation/final_labels.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log Reg over lemmatized text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                      Emotion Dehumanization Mention   External ID  \\\n1219  так, присутня негативна            так     так     row_0.txt   \n1218   ні, оцінка не присутня             ні      ні     row_1.txt   \n1591  так, присутня негативна            так     так    row_10.txt   \n1198  так, присутня негативна            так     так   row_100.txt   \n3247   ні, оцінка не присутня             ні     так  row_1000.txt   \n...                       ...            ...     ...           ...   \n3613   ні, оцінка не присутня             ні     так   row_995.txt   \n3612  так, присутня негативна             ні     так   row_996.txt   \n4121  так, присутня негативна             ні     так   row_997.txt   \n4120   ні, оцінка не присутня            так     так   row_998.txt   \n3248   ні, оцінка не присутня             ні      ні   row_999.txt   \n\n                        Created By  \\\n1219      snizannabotvin@gmail.com   \n1218      snizannabotvin@gmail.com   \n1591      snizannabotvin@gmail.com   \n1198      snizannabotvin@gmail.com   \n3247        tutovadesign@gmail.com   \n...                            ...   \n3613        tutovadesign@gmail.com   \n3612        tutovadesign@gmail.com   \n4121  yevhen.marchenko91@gmail.com   \n4120  yevhen.marchenko91@gmail.com   \n3248        tutovadesign@gmail.com   \n\n                                                   text  rating  \n1219  Всвязи с этим немного поправлю коллег ⤵️  \"Они...       4  \n1218  Литературный критик Галина Юзефович о новом ро...       4  \n1591  Почему на базах неонацистов стоят языческие ис...       4  \n1198  Группа добровольцев-медиков из Чеченской Респу...       4  \n3247  ВСУшники, переходите на сторону добра, у нас т...       5  \n...                                                 ...     ...  \n3613  Утренний брифинг Минобороны России:  ▪️ россий...       5  \n3612  И понеслась мазепинщино-петлюровщино-бандеровщ...       5  \n4121  Наш соратник по русскому движению Алексей Сели...       3  \n4120  Хорошее видео от 4 бригады НМ ЛНР https://t.me...       3  \n3248  Замоскворецкий районный суд Москвы отклонил ис...       5  \n\n[3546 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotion</th>\n      <th>Dehumanization</th>\n      <th>Mention</th>\n      <th>External ID</th>\n      <th>Created By</th>\n      <th>text</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1219</th>\n      <td>так, присутня негативна</td>\n      <td>так</td>\n      <td>так</td>\n      <td>row_0.txt</td>\n      <td>snizannabotvin@gmail.com</td>\n      <td>Всвязи с этим немного поправлю коллег ⤵️  \"Они...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1218</th>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>ні</td>\n      <td>row_1.txt</td>\n      <td>snizannabotvin@gmail.com</td>\n      <td>Литературный критик Галина Юзефович о новом ро...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1591</th>\n      <td>так, присутня негативна</td>\n      <td>так</td>\n      <td>так</td>\n      <td>row_10.txt</td>\n      <td>snizannabotvin@gmail.com</td>\n      <td>Почему на базах неонацистов стоят языческие ис...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>так, присутня негативна</td>\n      <td>так</td>\n      <td>так</td>\n      <td>row_100.txt</td>\n      <td>snizannabotvin@gmail.com</td>\n      <td>Группа добровольцев-медиков из Чеченской Респу...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3247</th>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_1000.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>ВСУшники, переходите на сторону добра, у нас т...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3613</th>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_995.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>Утренний брифинг Минобороны России:  ▪️ россий...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3612</th>\n      <td>так, присутня негативна</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_996.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>И понеслась мазепинщино-петлюровщино-бандеровщ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4121</th>\n      <td>так, присутня негативна</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_997.txt</td>\n      <td>yevhen.marchenko91@gmail.com</td>\n      <td>Наш соратник по русскому движению Алексей Сели...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4120</th>\n      <td>ні, оцінка не присутня</td>\n      <td>так</td>\n      <td>так</td>\n      <td>row_998.txt</td>\n      <td>yevhen.marchenko91@gmail.com</td>\n      <td>Хорошее видео от 4 бригады НМ ЛНР https://t.me...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3248</th>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>ні</td>\n      <td>row_999.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>Замоскворецкий районный суд Москвы отклонил ис...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>3546 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_dehumanization = df[['Dehumanization', 'text']].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_dehumanization = df_dehumanization[df_dehumanization['Dehumanization']!='не можу визначитись з правильною відповіддю']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "3494"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dehumanization)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_dehumanization['label'] = df_dehumanization['Dehumanization'].apply(lambda x: 0 if x=='ні' else 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     Dehumanization                                               text  label\n0               так  Всвязи с этим немного поправлю коллег ⤵️  \"Они...      1\n1                ні  Литературный критик Галина Юзефович о новом ро...      0\n2               так  Почему на базах неонацистов стоят языческие ис...      1\n3               так  Группа добровольцев-медиков из Чеченской Респу...      1\n4                ні  ВСУшники, переходите на сторону добра, у нас т...      0\n...             ...                                                ...    ...\n3541             ні  Утренний брифинг Минобороны России:  ▪️ россий...      0\n3542             ні  И понеслась мазепинщино-петлюровщино-бандеровщ...      0\n3543             ні  Наш соратник по русскому движению Алексей Сели...      0\n3544            так  Хорошее видео от 4 бригады НМ ЛНР https://t.me...      1\n3545             ні  Замоскворецкий районный суд Москвы отклонил ис...      0\n\n[3494 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dehumanization</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>так</td>\n      <td>Всвязи с этим немного поправлю коллег ⤵️  \"Они...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ні</td>\n      <td>Литературный критик Галина Юзефович о новом ро...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>так</td>\n      <td>Почему на базах неонацистов стоят языческие ис...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>так</td>\n      <td>Группа добровольцев-медиков из Чеченской Респу...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ні</td>\n      <td>ВСУшники, переходите на сторону добра, у нас т...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3541</th>\n      <td>ні</td>\n      <td>Утренний брифинг Минобороны России:  ▪️ россий...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3542</th>\n      <td>ні</td>\n      <td>И понеслась мазепинщино-петлюровщино-бандеровщ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3543</th>\n      <td>ні</td>\n      <td>Наш соратник по русскому движению Алексей Сели...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3544</th>\n      <td>так</td>\n      <td>Хорошее видео от 4 бригады НМ ЛНР https://t.me...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3545</th>\n      <td>ні</td>\n      <td>Замоскворецкий районный суд Москвы отклонил ис...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3494 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dehumanization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ru_core_news_md',disable=['ner', 'attribute_ruler'])\n",
    "\n",
    "def lemmatize_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    result = \" \".join([token.lemma_ for token in doc])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "cyrillic_letters = u\"абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ \"\n",
    "\n",
    "def clean_text(string, allowed_symbols):\n",
    "    getVals = list(filter(lambda x: x in allowed_symbols, string))\n",
    "    result = \"\".join(getVals)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df['text_clean'] = df['text'].apply(lambda x: clean_text(x.lower(), cyrillic_letters))\n",
    "    df['text_lemmatized'] = df['text_clean'].apply(lambda x: lemmatize_spacy(x))\n",
    "    df=df[df['text_clean']!='']\n",
    "    df.reset_index(inplace=True)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 197 ms, total: 20.2 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_dehumanization = preprocess_df(df_dehumanization)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logreg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train_, X_test_, y_train, y_test = train_test_split(df_dehumanization[\"text_clean\"], df_dehumanization[\"label\"], test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_)\n",
    "X_test = vectorizer.transform(X_test_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=1000)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Precision: 0.82\n",
      "Recall: 0.66\n",
      "F1 Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gridsearch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(C=10, penalty='l1', random_state=42, solver='liblinear')",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(solver='liblinear', random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "logreg_best = grid_search.best_estimator_\n",
    "\n",
    "logreg_best.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Precision: 0.79\n",
      "Recall: 0.72\n",
      "F1 Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l1\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    }
   ],
   "source": [
    "best_params = logreg_best.get_params()\n",
    "print(\"Best hyperparameters for the logistic regression model:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param}: {value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "original_data = df_dehumanization.loc[X_test_.index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "original_data['Predicted Label'] = y_pred\n",
    "original_data['Prediction Status'] = original_data['label'] == original_data['Predicted Label']\n",
    "incorrect_predictions = original_data[~original_data['Prediction Status']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrectly predicted samples:\n",
      "Index: 2396\n",
      "Original Text: Ведь безо всякой конкуренции, по словам ряда источников, Zе обходит Залужный, а антирейтинг Ze делают посаженные им в СИЗО генералы и посаженные на места \"слуги народу\"  П.С. упоминания РФ и РБ из рейтинга убрали, пусть хохлы упражняются в острословии сами для себя и между собой\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1175\n",
      "Original Text: В 2004 году проскакались за демократию, к власти пришел Ющенко, \"Оранжевая революция\".  2006 и 2007 год, скачки за Тимошенко и Ющенко.  2010 год, \"налоговый Майдан\", правительство Азарова согласилось пересмотреть нормы налогового кодекса.  2012, \"языковой Майдан\", успех партии бандеровцев и нацистов \"Свобода\".  2013 год, март-август, опять \"Восстань Украина\", партии Фронт перемен, Удар, Свобода.  2013 год, ноябрь-декабрь, собственно Евромайдан.  2014 год, январь-март и по настоящее время, \"Революция достоинства\".  ...  2020 год - ситуация в дурдоме стабильна.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1688\n",
      "Original Text: Явка на референдумы по итогам трех дней:  ▫️ в ДНР — 77,12%;  ▫️ в ЛНР — 76,09%;  ▫️ в Запорожской области — 51,55%;  ▫️ в Херсонской области — 48,91%.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1600\n",
      "Original Text: На Николаевском направлении арта распугала стайку хохлов.  \"Анонимный Военный\"\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 990\n",
      "Original Text: Стрелков вызвал на дебаты Соловьева, однако, похоже, что их не будет - Соловьев привычно на грани печатных выражений оскорбляет Стрелкова, что, по сути, является специфической формой отказа.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2540\n",
      "Original Text: Выходит, что, по мнению японских экспертов, экстремистская символика, лозунги и идеология «Азова» недостаточны, чтобы считать его неонацистским.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1737\n",
      "Original Text: Опасались боевых комаров - а напали бандеровские вши, не боящиеся морозов.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 676\n",
      "Original Text: Один из крупных петушиных каналов празднует перемогу над Белгородской областью из-за того, что там окружение, гуманитарная катастрофа, господство ВСУ в небе и на земле  ПОЖАР на объекте МО… Только такое жалкое существо как хохол может одновременно терять города-миллионники, сосать хуй и праздновать перемогу.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2110\n",
      "Original Text: Хохлы бродили вокруг, в нескольких метрах от ребят, потом нашли аварийные \"Комары\" и парашюты, и часть поехала увозить их на свои позиции, выманивать вертолеты ПСС. Оставшиеся погнали выносить окна и двери в деревеньке неподалёку, думая, что наш экипаж там…       Хрен его знает, куда бы двинулись хохлы дальше их искать, но тут начала херачить арта.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 3266\n",
      "Original Text: Возвращаться туда он не собирается, и пусть лучше дома не будет совсем, чем в нем будут жить ВСУшники.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2087\n",
      "Original Text: ‼️🇷🇺 От наших с места: 3 бригада ДНР выбила врага из укрепрайона под Горловкой, полностью освободив Зайцево  ▪️Зайцево в ходе войны оказалось разделено на 2 части: нижнее Зайцево и нижняя Жованка всегда были нашими, враг занимал верхнее Зайцево и верхнюю Жованку. ▪️Верхнее Зайцево наши взяли несколько недель назад, взяв ВСУшников в полукольцо. ▪️Бои были упорными, там сопротивлялись несколько сотен хоро вооруженных боевиков из спецназа, морской пехоты и десанта ВСУ. ▪️Сегодня силы 3 бригады ДНР вошли в Верхнюю Жованку, таким образом завершив освобождение большого Зайцево ▪️После освобождения Зайцево наши подступили к Майорску, находящемуся в 2 км левее.  \"Военкоры Русской Весны\"\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2044\n",
      "Original Text: В Мариуполе вблизи завода «Азовсталь» кадыровский спецназ задвухсотил всушников.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2716\n",
      "Original Text: \"Законами играют как хотят.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2702\n",
      "Original Text: Онуфрий сознательно нарушил правила Церкви ради сиюминутных выгод и впал в ересь этнофилетизма – «святое украинство» (с поклонением живодеру Бандере, «святому Хаймарсу» и «святой Джавелине»).\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3018\n",
      "Original Text: Отец сатаниста пока не знает что сынуля ВСушник (и 2 его друга) находятся в пикантной связи с матерью аж с 2017 года.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3133\n",
      "Original Text: Кстати, у чубатых все ещё потери многократно превышают наши потери.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1032\n",
      "Original Text: Путин выглянул в окошко и сбросил гршок с Геранью на проходящего мимо хохлопоросенка в Николаеве.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 183\n",
      "Original Text: Причем в укропабликах этот ролик называется \"Прилет снаряда в дом\" https://t.me/opersvodki/596, угу, снаряда.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1344\n",
      "Original Text: В ходе спецоперации русскими солдатами денацифицирован и отправлен спецрейсом прямо к Бандере Тарас Хаммер, лидер львовского \"Правого сектора\".  @voenkorKotenok\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2499\n",
      "Original Text: Хотя есть и менее оптимистичная версия причин этой \"эвакуации\".  🟠Хотя куда им ехать, если вон даже из рiдной Польши их гонят?  🟠Ну зато вон британский индус в Киев приехал.  🟠А Макрону дали леща.  🟠Шо по протестам? Факельное шествие в Латвии, \"жёлтые жилеты\" в Париже, антиукраинский митинг в Испании, пророссийский – в Германии и опять попытки рыпаться в Одессе, которые, впрочем, ничем хорошим не заканчиваются.  🟠В Малайзии выборы.  🟠И в Казахстане тоже.  🟠В который раз Tesla отзывает сотни тысяч своих машин из-за каких-то косяков.  🟠Громкая история с приговором американской миллионерше из Кремниевой долины, кому интересно – читать здесь.  🟠Снова новости из вселенной со 100500 гендерами – где очередной недомужик лезет в женские соревнования.  🟠Бэнкси тут познал сущность хохлов.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2030\n",
      "Original Text: По случаю месяца с начала дебандеризации имею заметить - в последние дни отчетливо чувствуется, что с ее военной составляющей мы не спешим.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3095\n",
      "Original Text: Первый российский снаряд лег где-то вблизи укрытия ВСУшника, а второй, по всей видимости, попал четко в цель.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 229\n",
      "Original Text: А вот опустившийся бывший русский, ставший укробандерой, готов лизать задницу англосаксов даже тогда, когда тот ему в его рожу пердит💨 и срёт💩.   🏳‍🌈Забавный случай с Евровидения.😁 Как укробандеры не пытались вылизать своим хозяевам ЛГБТ-задницу, называя в своих топовых соцсетях британцев \"по-настоящему братским народом\" и давая им высшие 12 баллов.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 387\n",
      "Original Text: Пан гетьман возомнил, что его хлопцы одержали великую победу под Киевом, а хозяева гетмана из Великобритании и США пана похвалили и погладили по головке.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1477\n",
      "Original Text: В связи со спам-атакой укро-существ, все письма в личку будут блокироваться без прочтения.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2171\n",
      "Original Text: Над байками укрогеббельсов про контрнаступление на Херсон и над прочими мифическими перемогами уже и укровояки смеются половиной окопа.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3309\n",
      "Original Text: Центральные рынки освобожденных населенных пунктов Харьковской области приступили к работе при поддержке российских военных, сообщили в Минобороны России.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2431\n",
      "Original Text: Этим и объясняется, что наши забрали тело украинского бойца.  4. 🔺Дальше начала работать арта укров, прикрывая отход группы. (Есть версия, что от своей арты укропам тоже досталось)  5.🔺Начала работать наша арта.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2247\n",
      "Original Text: В Риге майданутые орут в костюмах зомби, в Кишиневе раскрашиваю памятники в сине-желтый и требуют общаться с ними на украинском.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 170\n",
      "Original Text: Пошла ответочка свинорейху 🐷😎\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3461\n",
      "Original Text: Зеленский в новом обращении рассказал об обстреле больницы в Мариуполе.  «Детская больница, роддом — чем они угрожали Российской Федерации? Что это за страна такая, Российская Федерация, которая боится больниц, боится роддомов и уничтожает их? Там что были маленькие бендеровцы? Беременные женщины собирались стрелять по Ростову? Кто-то в роддоме унижал русскоязычных? Что это было — денацификация больницы? Все что оккупанты делают с Мариуполем — это уже за пределом зверства.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2215\n",
      "Original Text: Чубатые, бегите до пана.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2967\n",
      "Original Text: Пьяный всука повздорил с охранниками дома и открыл стрельбу из пистолета в сторону двора с играющими детьми в Киеве.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 479\n",
      "Original Text: Хохлы как дьявол, они берут все прикольное и оскверняют это.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2379\n",
      "Original Text: Про того, которого любила, Про того, чьи письма берегла.  - Ахмат - сила! Аллаху Акбар!\"  Интернациональный отряд спецназа \"Ахмат\" идёт собирать урожай укропа.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 787\n",
      "Original Text: Не хохлорейхом единым...\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 33\n",
      "Original Text: Число погибших от коронавируса во всем мире превысило 250 000.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 3420\n",
      "Original Text: Конечно же, это денацификация, потому что разгул неонацизма при прямом попустительстве просвещенной Европы приобрел уже угрожающий уровень.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1606\n",
      "Original Text: Повесть о бандерлогах...  @tv360\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2597\n",
      "Original Text: При этом мосты подорваны укропами и люди фактически отрезаны.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2256\n",
      "Original Text: Но если эта реконструкция верна, значит, вероятность, что чубатое воинство таки сорвется с поводка, оценивается как весьма и весьма ненулевая.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3471\n",
      "Original Text: И по видосам с укропскими свинособаками это видно хорошо.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2439\n",
      "Original Text: Китайцы охренели - прислали чубатым бесплатно  тесты низкого качества 😱  https://t.me/c/1271443470/552\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2148\n",
      "Original Text: Хохлостан в очередной раз показывает, что государство 404 является абсолютно неправовой субстанцией.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1538\n",
      "Original Text: Мерзавцы, которые числятся руководителями Украины, превратили её из нормальной страны в то нацистско-бандитское государство, которым она сейчас является, ограбили и разорили дотла, подставили под спецоперацию России, на протяжении восьми лет бомбили и обстреливали свой собственный народ на юго-востоке и травили русско-, мадьяро- и остальные неукраиноязычные меньшинства на всей прочей территории, гнобили и раскалывали РПЦ, реабилитировали Петлюру, Бандеру и прочую погромную сволочь и совершили в отношении нашей страны все гнусности, которые только могли придумать, захотели, как сообщил невесть зачем ведущий с ними переговоры Мединский, отделаться \"нейтралитетом по шведскому или австрийскому варианту\".\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 291\n",
      "Original Text: Два самолета МО Турции с 24 февраля не могут вылететь из Киева для эвакуации граждан Турции из-за закрытого воздушного пространства, сообщили в Минобороны.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1717\n",
      "Original Text: Техника уже в строю и помогает косить укроп.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1660\n",
      "Original Text: Пока одни выступают за смягчение 282-й статьи УК, другие предлагают за «явное неуважение» к обществу и государству в интернете сажать на 15 суток\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1729\n",
      "Original Text: Депутат Госдумы от ЛДПР Иван Сухарев предложил отказаться от Дня Защитника Отечества 23 февраля и перенести его на август.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2119\n",
      "Original Text: Если ты не знаешь, что за слово - посмотри в словаре, майданутенький.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1480\n",
      "Original Text: Исламистов с хохлами объединяет как ненависть к России (которая им мешает), так и общие хозяева.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3176\n",
      "Original Text: От украинцев начали избавляться  Жители Швейцарии выражают недовольство из-за наплыва в их страну украинских беженцев.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1128\n",
      "Original Text: Мы должны по максимуму поддержать Украину, отметив, что Бандера - это бяка.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1511\n",
      "Original Text: Ветераны спецчастей ЦАХАЛ, объединившись в одно подразделение, проводят подготовку укрорейхских наёмников  по израильской системе .\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1929\n",
      "Original Text: Ну все, теперь можно завозить \"правильные\" книги с идеологией Бандеры и прочих нацистов?   Теперь при входе в лавру будет висеть икона святой \"Джавелины\"?\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2803\n",
      "Original Text: Невероятно, но вот этих бандеровцев скорость все-таки подвела, и не пришлось нашим воинам тратить время на их преследование.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 279\n",
      "Original Text: «Мне нужно будет спросить у моих друзей, что значит «бандеровцы».\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 102\n",
      "Original Text: Грош нам всем цена, если хохлятская мразь сегодня не утонет в собственной крови.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3291\n",
      "Original Text: Киев ограничивает выезд из страны для мужчин в возрасте 18-45 лет и обращается к странам Запада за помощью в возвращении граждан Украины призывного возраста обратно в страну. —- Ну что, сильно хитрые хохлы, любящие Украину с польских грядок и прочих Португалий, доскакались?  P.S. Из Канады надо всех выгнать.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 44\n",
      "Original Text: Почему \"Роснано\" стало черной дырой в российском бюджете и что не так с нашим госкапитализмом  История с Чубайсом заставляет задуматься, все ли правильно в области инноваций и в управлении российскими госкомпаниями.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1455\n",
      "Original Text: Безжалостного и неутомимого хищника и охотника, уничтожающего хохлов мышей сотнями.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2409\n",
      "Original Text: 🇷🇺Русский боец превратил укронацистский танк в «тандыр»  Осташко! Важное - подпишись\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1743\n",
      "Original Text: Украинский комик Олег Грюндик выступает во Львове:   \"Семьям погибших ВСУшников компенсируют 15 миллионов гривень, слышали такое? А вы знаете, что их можно потратить только на книги, кинотеатры, спортзал\".\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 3277\n",
      "Original Text: Сейчас война продолжается, идет активная фаза освобождения русских земель от бандерофашистов и практически каждый день погибают русские люди.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 461\n",
      "Original Text: В одном из съёмочных павильонов студии укро-нацисты установили средства ПВО.  Всего на киностудии таких установок много, сообщает наш источник.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 527\n",
      "Original Text: Сейчас, в 21-м веке, снова наш враг на Западе, используя деградировавших до скотского состояния хохлов, пытается разрушить нашу страну.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 712\n",
      "Original Text: Также сбиты пять беспилотных летательных аппаратов в районах населенных пунктов Валерьяновка Донецкой Народной Республики, Чубаревка Запорожской области, Капитоловка, Изюм и Красное Харьковской области.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2692\n",
      "Original Text: Отреагировал на хохлофейки про спутники Илона Маска.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3370\n",
      "Original Text: С разгромом в Мариуполе самых законченных укронацистов завершилось освобождение азовского побережья.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 3274\n",
      "Original Text: Захарова о выступлении Лукашенко по задержанным россиянам: их вина не доказана, мы их в обиду не дадим, и в Минске это прекрасно знают\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 463\n",
      "Original Text: Уже тогда в Чечне террористам активно помогали укронацисты.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1104\n",
      "Original Text: ✔️С кем воюют наши бойцы? Сейчас с неонацистами-бандеровцами.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2512\n",
      "Original Text: В ходе митинга звучали антинацистские лозунги, а также ставший широко известным и очень популярным во всём мире чеченский девиз справедливости и борьбы за правду: \"АХМАТ-СИЛА!!! АЛЛАХУ АКБАР!!!\".   Радует то, что люди во многих странах понимают, что фашизм на Украине - это проблема мирового масштаба, с которой успешно борятся чеченские и российские воины совместно с силовыми подразделениями ДНР и ЛНР.   Люди видят, как Запад и США открыто финансируют нацистский терроризм и поставляют тяжёлое вооружение бандеровским формированиям на Украине.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3259\n",
      "Original Text: ⚡️В Германии пропала девчонка, которая калинку танцевала 9 мая на фоне беснующихся хохлов!  https://t.me/kanzlerdaddy/3826\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 254\n",
      "Original Text: Вот что натворил господин Зеленский со своей шайкой бандеровцев, нациками, шайтанами.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3047\n",
      "Original Text: Он заявил, что готов отправиться на самый опасный участок фронта и работать фельдшером, вытаскивая бойцов с поля боя.   «Если сегодня там, на Украине, мы не остановим бандеровцев, то завтра они придут сюда.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 864\n",
      "Original Text: Никакую бандеровскую песню не репостил (про «русский военный корабль»).\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2833\n",
      "Original Text: Да уж, подвести научную базу под вандализм - до такого  украинские свидомые во время своего \"ленинопада\" не догадались! https://www.popularmechanics.com/science/a32870657/remove-statue-science/\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 599\n",
      "Original Text: А после того, как ему не дали выступить на форуме в память холокоста в Израиле (что неудивительно, не то место и время для зигующего клоуна с портретиком Бандеры), оно обиделось и вообще уехало.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1135\n",
      "Original Text: Такая вот маленькая укронацисткая радость.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 573\n",
      "Original Text: Одним словом ЛГБТ-укробандеры, как цепные псы воюют под командованием ЛГБТ-НАТО на 4-й ЛГБТ-рейх.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3211\n",
      "Original Text: У недорейха заканчиваются боты.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 478\n",
      "Original Text: ​​Известный писатель и драматург Юрий Поляков (@yuripoliakov) о значении общественной поддержки нашей армии, борющейся с неонацизмом на Украине и в Донбассе:      💬 За годы, пока на Украине властвует неонацистский режим, русофобия проникла всюду: в кино, в театр, в литературу, в СМИ, в систему образования.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1220\n",
      "Original Text: Они будут создавать не военное, а экстремистское подразделение, основой которого станут не перевербованные солдаты и офицеры, а гражданские лица, исповедующие неонацистскую идеологию.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2541\n",
      "Original Text: Когда пойдут новости о пострадавшем мирном населении, хохлопитек семь раз обернётся вокруг себя и заявит, что удары осуществляли ВС РФ.  Вот и пошли новости о убитых безумцами людях.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 283\n",
      "Original Text: Знать, чтобы понимать, кто не дает «замерзнуть» укронацистскому истеблишменту. 8 лет бесперебойно.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 274\n",
      "Original Text: Доброе утро, дорогие друзья, ответ российских военных на недавний пропагандистский ролик страны 404, в котором не выспавшаяся хохлушка с герпесом на губе зачем-то убивает серпом пьяного хохла в тельняшке, называет всех русских «свиньями» и признаётся, что живёт в аду.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 109\n",
      "Original Text: Уехавшая и рвущаяся назад, потому что доходы-то здесь, уехавшая и живущая на ренту отсюда (национализация - ау?!) или не уехавшая и продолжающая лаять в соцсетях, не взирая на плашку иноагента - честное слово - если б всю эту свору сменять на пару типа раскаившихся хохлов - да мы бы жили в прекрасной стране!\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2279\n",
      "Original Text: Да, отступать с занятых позиций психологически тяжело, но если отступление проходит штатно и с минимальными потерями личного состава - с параллельным заземлением пачек хохлов – то в сложившейся ситуации это лучший вариант.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 610\n",
      "Original Text: Бандеровщина это квазирелигия, бесовская секта.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3457\n",
      "Original Text: Благодаря такому единству можно уверенно гарантировать, что больше на этих землях бандеровских прихвостней не будет!   Также в ходе пресс-тура мой дорогой БРАТ, командир Алихан Шавхалов, рассказал о высокой боеготовности чеченских спецподразделений, что они продолжают успешно выполнять задачи командования по освобождению Донбасса.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 3297\n",
      "Original Text: 🇺🇦🇷🇺Разгромленная колонна ВСУ в Херсонской области.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1814\n",
      "Original Text: Посмотрим на реакцию пана Зе, который вчера у многих украл сердечки своим новогодним поздравлением, призывая «ватников» и «бандеровцев» к объединению.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1232\n",
      "Original Text: Россия целых 8 (!!!) лет пыталась всеми возможными способами избежать военных действий, но ублюдочная бандеровская власть, подстрекаемая западными хозяевами, не оставила нам никаких шансов!   Вот за это нас хотят назвать государством-спонсором терроризма.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1580\n",
      "Original Text: 🇺🇦Украинский нарКдеп Гончаренко подключился к вылизыванию натовских \"обрезов\"  На фоне возможного боевого конфликта между Сербией и Косово член фракции \"Европейская солидарность\" объявил о готовности укронацистов помочь косовским боевикам.  \"Если Сербия вторгнется в Косово, мы должны защищать Косово.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 457\n",
      "Original Text: Очередное видео от хохлопетухов, где они с БПЛА корректирую огонь по наставленной в кучу технике.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 794\n",
      "Original Text: С этим образом можно спорить, но в случае Малера подкова работает: антикапитализм и антиамериканизм, которые поднимали на флаг левые 1970-х, в зрелом возрасте он с легкостью адаптировал к нуждам совершенно противоположного «по знаку» неонацистского движения.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 332\n",
      "Original Text: Вообщем наши там держат оборону, укропы делают атаки пытаются пробить и там дохнут! Так вот 16 мая была контратака.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 251\n",
      "Original Text: Всем читателям канала,  утренний салам!  Всем, кроме чубаноидов!\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3304\n",
      "Original Text: Труханов – идеальный бандеровский бургомистр в оппозиционном городе.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2179\n",
      "Original Text: Свершилось. «Печку-Буржуйку» на хуторе переименовали в «Бандерпечь»\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 889\n",
      "Original Text: А его бандеровский мир означает для одесситов скрытую, но тотальную войну.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2490\n",
      "Original Text: Хохлы, перешлите это видео вашему зеленскому! Скорее всего и он так же закончит, если живой будет, когда от него отвернутся все его покровители.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1178\n",
      "Original Text: Учуяв этакую неприятность видеоблогер Сяська судорожно проедает донаты в своем очередном-внеочередном отпуске, видеоблоХер Саса Сотник в ужасе давится политурой, а прочие разные укропидеровцы, эмо-комики и бессрАчники крестят дупы в ожидании неминуемой «бутылки справедливости» .\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1506\n",
      "Original Text: Установлено, что источником распространения видео является его же канал: https://t.me/ganul93/2393  Имя: Ганул Демьян Вадимович                  Статус: Неонацист, один из организаторов поджога здания Дома Профсоюзов в Одессе.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1864\n",
      "Original Text: В конце видео просят заретушировать лицо бандерлога, однако у нас ретушь сломалась;)\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2516\n",
      "Original Text: ❗️Доступ украинских неонацистов к атомной бомбе мог бы привести к невообразимым последствиям, речи об обладании Киевом ядерным оружием быть не может, заявил в интервью нашему агентству директор второго департамента СНГ МИД РФ Алексей Полищук.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3389\n",
      "Original Text: Пять хохлокеглей из шести ушло на минус .\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1985\n",
      "Original Text: Вообще совпадений в символах укрорейха и Третьего Рейха очень много, а уж об идеологии мы говорили много раз.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 3346\n",
      "Original Text: 🇺🇦Власти украинского города Марганец расклеивают листовки с рекомендациями на случай аварий на ЗАЭС  Наш подписчик из города Марганец пишет, что местные власти расклеивают листовки с планом действий на случай утечки радиации в результате обстрелов укронацистами Запорожской АЭС.  \"В результате обстрелов по позициям ВС РФ может произойти утечка радиации\", – указано в тексте листовок.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2103\n",
      "Original Text: Боевики назвали беседку в честь скандально известного львовского бандеровского кафе.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 621\n",
      "Original Text: Вопрос к хохлам, которые пасутся у нас в комментариях, вот даже банить не будем, обещаю.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2227\n",
      "Original Text: Страница военного билета русского солдата, который бился до последнего.   \"Всем мир! России слава! Смерть укропам!\"\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 211\n",
      "Original Text: Там наши ракеты хохлов ебут  @rosich_ru\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2515\n",
      "Original Text: По данным российской стороны, во время первой попытки украинская сторона «потеряла около 200 человек и 20 единиц техники».  🤔Вот и что это было? В Киеве реально верят, что смогут прорвать российскую оборону? Или это программа по утилизации населения Украины. 70 украинских хлопцев не вернутся к своим жинкам и будут кормить полевых кротов и бродячих собак.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3135\n",
      "Original Text: Говорят, на Днепре бандеровцы применили новую тактику уклонения от снарядов. 😆 Ну, или просто слишком буквально поняли словосочетание \"морская пехота\" и решили форсировать реку по дну.   🤷‍♂️ В любом из случаев, захватить ЗАЭС у террористов снова не вышло.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3118\n",
      "Original Text: Стратегическая проблема, стоящая перед Россией — это вопрос, кто не допустит возвращения \"бандеровщины\" на Украину  (Этим постом Readovka продолжает серию аналитических публикаций от ведущих экспертов по теме текущих событий)  Важной проблемой является не только налаживание снабжения освобожденных территории и укрепления контроля военно-гражданских администраций, но и насыщение этих территорий лояльным личным составом, который деятельно покажет, что времена бандеровщины — в прошлом.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2503\n",
      "Original Text: 240-мм самоходные миномёты 2С4 «Тюльпан» и 152-мм дивизионные самоходные гаубицы 2С3 «Акация»  группировки \"V\" союзных сил направляются \"косить укроп\"  в зоне проведения СВО на Украине.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 175\n",
      "Original Text: На данном видео, вы можете наблюдать прибытие астронавтов в челноке Svinovoz 1M. Ребятам не повезло - проходя плотную русскую атмосферу потерпели фиаско  Ну ничего, в национальном космическом агенстве укрорейха целых восемь волн покорителей Плутона! Зеля, присылай ещё! ЗСУ ты космос!\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 430\n",
      "Original Text: И если по итогам этой работы политическая цель дебандеризации будет изменена в сторону требования безоговорочной капитуляции свиноты, более весомого и исчерпывающего основания для такого изменения невозможно и представить.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2127\n",
      "Original Text: Преступления неонацистов продолжаются, к сожалению...\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1113\n",
      "Original Text: Эти бандеровские мрази, когда передают координаты целей на огневые позиции, прекрасно отдают себе отчёт куда, по каким целям полетят снаряды.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2091\n",
      "Original Text: А все эти укроперевертыши типа Пономарева, которые перебегают, к тому, кто сильнее, и не имеют иной идеологии, кроме как набить себе карман любым способом, должны быть лишены власти и активов.   https://t.me/georgy_ma/499\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 879\n",
      "Original Text: Мы сами не забудем и миру не дадим забыть преступления, которые совершены украинским неонацистским режимом.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 258\n",
      "Original Text: Отход наших войск из намечающегося котла не только позволил избежать больших жертв, но и разрушил план – максимум бандеровцев и их хозяев.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2739\n",
      "Original Text: Под нашим вчерашним постом об эффектном задержании видного змагара Протасевича в комментах порвались на британский флаг не только закоренелые свидомиты, но и многие россиянцы.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2830\n",
      "Original Text: Польские националисты наконец занялись делом - отлавливают украинских почитателей Бандеры.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2519\n",
      "Original Text: 💭 Одесские депутаты забыли украинский язык из-за волнения во время выступления на сессии.  «Этот вопрос находится на постоянном контроле...», — начал отчет чиновник Борис Панов, однако закончить фразу не смог.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1800\n",
      "Original Text: 💥☢Пробитая в результате удара боевиков Зеленского крыша спецкорпуса №1 Запорожской АЭС.  В данном корпусе хранится свежее топливо для реакторов ЗАЭС.  #StopUkrainianNuclearTerrorism  Владимир Рогов\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2357\n",
      "Original Text: Это к вопросу о \"наступе\" укропианцев на потемкинский Херсон.  @voenkorKotenok\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3110\n",
      "Original Text: Вы или находитесь в русской орбите и солидаризируетесь с нашей победой в Великой Отечественной Войне или вы этого не делаете, и значит вы определены в ту же низкую касту, где хохлы-бандеровцы и татары-сепаратисты с их Идель-Уралом.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2043\n",
      "Original Text: Идеальный бандеровский бургомистр в оппозиционном городе  Главным предвыборным месседжем второго тура Труханов избрал мир.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 746\n",
      "Original Text: Некоторые свидомые граждане пошли в так называемую территориальную оборону и готовят коктейли «Молотова».\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3472\n",
      "Original Text: ⚡️Путин: Нам нужно ответить на вопрос, который поставлен давно и зафиксирован в обращении Госдумы: вопрос о признании ДНР И ЛНР  @srochnow\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2689\n",
      "Original Text: Примечательно, что ВСУшники пытались сбить беспилотник, но это у них не получилось.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1446\n",
      "Original Text: 🎆 Праздничный салют в Москве в честь 77-й годовщины Победы в Великой Отечественной войне!  Ура!  @infomoscow24\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 25\n",
      "Original Text: Ланцет наглухо отменил ВСУкам связь на этом участке.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3270\n",
      "Original Text: Кадыров заявил, что «бандеровцев в Мариуполе добьют уже сегодня» и полностью заберут «Азовсталь»\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1610\n",
      "Original Text: 🤷🏻‍♀️Сегодня ночью на Кантемировской KIA протаранила подъезд жилого дома  И это ещё не все: после аварии водитель вызвал такси, чтобы отбуксировать свою машину, но ударился в припаркованную Audi.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 997\n",
      "Original Text: ❗️Мединский: Тема денацификации и ужесточения наказания за героизацию нацизма, неонацизма, экстремизма на их основе по-прежнему является важным пунктом повестки дня переговоров.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 343\n",
      "Original Text: Хохлы, спасибо за ништяки.  \"Повёрнутые на Z войне\"\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 1450\n",
      "Original Text: Эти ребята вырвались из окружения двое суток назад...\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 839\n",
      "Original Text: К этим траншам с удовольствием присасывается вся террористическая верхушка Хохлостана.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 1665\n",
      "Original Text: Всем утренний салам!  Всем, кроме чубаноидов!\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3220\n",
      "Original Text: Контрабанда кокоса на завод азовсталь Хохлы заебали я от них очень устал Заебало нюхать горящее сало Заебали страшно хохлы заебали  Котелок вари хохлов Котелок вари хохлов Котелок вари хохлов  @karga4 #каргач_эксклюзив\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2312\n",
      "Original Text: Главным тезисом, который Маклиллан постоянно повторяет во всех своих переписках – это то, что «Азов» не воюет ни за Зеленского, ни за НАТО, ни за ЕС. По его словам, «Азов» уже не столько полк, сколько идея неонацистского «возрождения».\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 2860\n",
      "Original Text: Советник рейхсфюрера Мишаня Подоляк пообещал через 6 месяцев включиться в эфир бандеровского канала с набережной в Ялте.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 3012\n",
      "Original Text: Ему, на полном серьезе кажется, что там живут «чубатые салоеды», которые угнетают «русских», то есть таких же угро-финнов как и они сами.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2587\n",
      "Original Text: В данную минуту бой под Ольховкой продолжается, ВСУки взорвали мост.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 3194\n",
      "Original Text: Причём было 230 тысяч читателей!  Между тем её видео в поддержку наших солдат залетало на миллионы просмотров в TikTok 🇷🇺  Но укропы забанили её и в TikTokе...\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 693\n",
      "Original Text: Фонд «Свободная Якутия» опубликовал две фотографии отряда наемников «Боотур» — одну, сделанную в день отправки военных на фронт, другую — в день их возвращения в Россию   28 июля «Боотур» в составе 105 человек отправился на войну с Украиной, провожал их лично глава республики Айсен Николаев, заявив, что военнослужащие идут «освобождать братский народ Украины от бандеровского режима», и поблагодарив их за решение «поддержать нашего президента Владимира Владимировича Путина».   2 ноября «Боотур» вернулся в Россию.\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n",
      "Index: 162\n",
      "Original Text: Там оказалась 60-тысячная бандеровская полуфашистская террористическая армия, судьба которой должна решиться в ближайшие дни.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 776\n",
      "Original Text: При этом я вполне допускаю, что в украдинский порт катера вошли уже без лампочек и унитазов - сами же хохлы и спиздили по дороге (как известно, на мировом чемпионате по спиздингу украдинцы спиздили судью).\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 2874\n",
      "Original Text: На Украине начали создавать культ УПА*, Бандеры, Шухевича и прочих нацистских мразей.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Index: 568\n",
      "Original Text: Хохлы, ловите чапалах от народного избранника ❤️\n",
      "True Label: 0\n",
      "Predicted Label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Incorrectly predicted samples:\")\n",
    "for index, row in incorrect_predictions.iterrows():\n",
    "    print(f\"Index: {index}\\nOriginal Text: {row['text']}\\nTrue Label: {row['label']}\\nPredicted Label: {row['Predicted Label']}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preliminary error analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Укрвояки сприймається системою як дегуманізація\n",
    "\n",
    "Рядок 2562, 2210, 1288, 1188, 291, 2486 - сумнівний лейбл, цілком можливо що система права\n",
    "\n",
    "Хохлофейки тригерить систему\n",
    "\n",
    "Чомусь тригерить коронавірус (93, 33)\n",
    "\n",
    "Не впізнає місцями свинорейх (як в 3419, 170)\n",
    "\n",
    "Майже весь неонацизм постійно тригерить систему - 2775, 1011, 289 (але от в 2320 - неонацизм как раковая опухоль - ні, 3193 - )\n",
    "\n",
    "1070 - система тригериться на чубатих\n",
    "\n",
    "Система гірше зчитує subtle cues - 554 (накапливаются), 2335 (зондероотряд), 486 (не бандероукропианці, а держава = навоз), 2646 (опис а не фразеологізм)\n",
    "\n",
    "Не всі атрибути нацизма впізнає - 678 (бандерюгенд), 2335 (зондероотряд), 2293 (бандерофашисти)\n",
    "\n",
    "2086 - укропские мартішки\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log Reg over lemmatized text plus (or exclusively) collocations (with concatenaction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from collocation_extraction import collect_verb_obl_obj, collect_core, collect_nmod, collect_amod, collect_comp, collect_appos, show_dependency, lst_to_str"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/1996300300.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['core_noun_verb'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_core(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/1996300300.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['verb_obl_obj'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_verb_obl_obj(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/1996300300.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['nmod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_nmod(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/1996300300.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['amod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_amod(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/1996300300.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['comp'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_comp(x)))\n"
     ]
    }
   ],
   "source": [
    "df_dehumanization['core_noun_verb'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_core(x)))\n",
    "df_dehumanization['verb_obl_obj'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_verb_obl_obj(x)))\n",
    "df_dehumanization['nmod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_nmod(x)))\n",
    "df_dehumanization['amod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_amod(x)))\n",
    "df_dehumanization['comp'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_comp(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/2166550837.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization.drop(columns='index', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_dehumanization.drop(columns='index', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dehumanization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_logreg_best(col_list = ['text_lemmatized'], df=df_dehumanization, vectorizer = TfidfVectorizer(), random_state=42):\n",
    "    df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "    X_train_, X_test_, y_train, y_test = train_test_split(df[\"merged_col\"], df[\"label\"], test_size=0.2, random_state=random_state)\n",
    "    X_train = vectorizer.fit_transform(X_train_)\n",
    "    X_test = vectorizer.transform(X_test_)\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "    grid_search = GridSearchCV(LogisticRegression(solver='liblinear', random_state=random_state), param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    logreg_best = grid_search.best_estimator_\n",
    "    logreg_best.fit(X_train, y_train)\n",
    "    y_pred = logreg_best.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    best_params = logreg_best.get_params()\n",
    "    print(\"Best hyperparameters for the logistic regression model:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.82\n",
      "Recall: 0.75\n",
      "F1 Score: 0.79\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l1\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Precision: 0.79\n",
      "Recall: 0.72\n",
      "F1 Score: 0.75\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l1\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['text_clean'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61\n",
      "Precision: 0.70\n",
      "Recall: 0.30\n",
      "F1 Score: 0.42\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 1\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l1\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['core_noun_verb'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58\n",
      "Precision: 0.57\n",
      "Recall: 0.39\n",
      "F1 Score: 0.46\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l2\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['verb_obl_obj'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "Precision: 0.66\n",
      "Recall: 0.49\n",
      "F1 Score: 0.56\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l2\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['nmod'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58\n",
      "Precision: 0.59\n",
      "Recall: 0.36\n",
      "F1 Score: 0.45\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l2\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['amod'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "Precision: 0.70\n",
      "Recall: 0.57\n",
      "F1 Score: 0.63\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l2\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['nmod', 'verb_obl_obj'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Precision: 0.80\n",
      "Recall: 0.62\n",
      "F1 Score: 0.70\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l1\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['nmod', 'verb_obl_obj', 'core_noun_verb'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Precision: 0.79\n",
      "Recall: 0.64\n",
      "F1 Score: 0.71\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l1\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "Precision: 0.82\n",
      "Recall: 0.70\n",
      "F1 Score: 0.76\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l1\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod', 'text_clean'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/85191952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'merged_col'] = df[col_list].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "Precision: 0.85\n",
      "Recall: 0.74\n",
      "F1 Score: 0.79\n",
      "Best hyperparameters for the logistic regression model:\n",
      "C: 10\n",
      "class_weight: None\n",
      "dual: False\n",
      "fit_intercept: True\n",
      "intercept_scaling: 1\n",
      "l1_ratio: None\n",
      "max_iter: 100\n",
      "multi_class: auto\n",
      "n_jobs: None\n",
      "penalty: l1\n",
      "random_state: 42\n",
      "solver: liblinear\n",
      "tol: 0.0001\n",
      "verbose: 0\n",
      "warm_start: False\n"
     ]
    }
   ],
   "source": [
    "get_logreg_best(col_list=['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod', 'text_lemmatized', 'text_clean'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Dehumanization', 'text', 'label', 'text_clean', 'text_lemmatized',\n       'core_noun_verb', 'verb_obl_obj', 'nmod', 'amod', 'comp', 'merged_col'],\n      dtype='object')"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dehumanization.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log Reg over lemmatized text plus (or exclusively) collocations (as separate features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MultiColumnTfidfVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, **kwargs):\n",
    "        self.columns = columns\n",
    "        self.vectorizers = [TfidfVectorizer(**kwargs) for _ in columns]\n",
    "        self.fitted_models = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col, vec in zip(self.columns, self.vectorizers):\n",
    "            vec.fit(X[col])\n",
    "            self.fitted_models.append(vec.fit(X[col]))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        for col, vec in zip(self.columns, self.vectorizers):\n",
    "            features.append(vec.transform(X[col]))\n",
    "        return hstack(features)\n",
    "\n",
    "\n",
    "def train_logistic_regression(data, text_columns, label_column, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=0.2, random_state=random_state)\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', MultiColumnTfidfVectorizer(columns=text_columns)),\n",
    "        ('regressor', LogisticRegression(solver='liblinear', random_state=random_state, max_iter=100))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'regressor__fit_intercept': [True, False],\n",
    "        'regressor__C': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 100],\n",
    "        'regressor__penalty': ['l1', 'l2']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    logreg_best = grid_search.best_estimator_\n",
    "    logreg_best.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg_best.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    return logreg_best"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "text_columns = ['nmod', 'verb_obl_obj']\n",
    "label_column = ['label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "Precision: 0.70\n",
      "Recall: 0.58\n",
      "F1 Score: 0.64\n",
      "CPU times: user 1min 12s, sys: 26.9 s, total: 1min 39s\n",
      "Wall time: 34.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trained_pipeline = train_logistic_regression(df_dehumanization, text_columns, label_column)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Precision: 0.80\n",
      "Recall: 0.71\n",
      "F1 Score: 0.75\n",
      "CPU times: user 2min 9s, sys: 1min 14s, total: 3min 24s\n",
      "Wall time: 50.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_columns = ['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod', 'text_lemmatized', 'text_clean']\n",
    "\n",
    "trained_pipeline = train_logistic_regression(df_dehumanization, text_columns, label_column)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature importance of unique vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_feature_names(vectorizer):\n",
    "    feature_names = []\n",
    "    for col, vec in zip(vectorizer.columns, vectorizer.vectorizers):\n",
    "        feature_names.extend([f\"{col}_{f}\" for f in vec.get_feature_names_out()])\n",
    "    return feature_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def display_feature_importance(pipeline, n=10):\n",
    "    vectorizer = pipeline.named_steps['vectorizer']\n",
    "    classifier = pipeline.named_steps['regressor']\n",
    "    feature_names = get_feature_names(vectorizer)\n",
    "    coefficients = classifier.coef_[0]\n",
    "    sorted_indices = np.argsort(np.abs(coefficients))[::-1]\n",
    "    print(f\"Top {n} important features:\")\n",
    "    for i in sorted_indices[:n]:\n",
    "        print(f\"{feature_names[i]}: {coefficients[i]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 important features:\n",
      "text_lemmatized_укронацистов: 6.378262550346116\n",
      "text_lemmatized_неонацист: 6.085057392767983\n",
      "core_noun_verb_укронацисты: 5.91855169444555\n",
      "text_clean_укронацистов: 5.899070697524357\n",
      "text_lemmatized_укрорейха: 5.276251591374416\n",
      "nmod_укронацистов: 5.018582192359891\n",
      "text_clean_укрорейха: 4.852979284465811\n",
      "text_lemmatized_укронацисты: 4.632180415751175\n",
      "text_clean_укронацисты: 4.249282732972154\n",
      "nmod_укрорейха: 4.186660657334475\n"
     ]
    }
   ],
   "source": [
    "display_feature_importance(trained_pipeline)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "top_features = pd.DataFrame()\n",
    "\n",
    "# looping over each text column and apply TF-IDF vectorization followed by chi-squared test\n",
    "for col in text_columns:\n",
    "    tfidf_features = tfidf_vectorizer.fit_transform(df_dehumanization[col])\n",
    "\n",
    "    # chi-squared test to select the top-k features with the lowest p-values\n",
    "    selector = SelectKBest(chi2, k=100)\n",
    "    selector.fit(tfidf_features, df_dehumanization['label'])\n",
    "    feature_scores = pd.DataFrame({\n",
    "        'feature': tfidf_vectorizer.get_feature_names_out(),\n",
    "        'p_value': selector.pvalues_,\n",
    "    })\n",
    "\n",
    "    # sorting the features by p-value and add the top-k features to the top_features\n",
    "    top_k_features = feature_scores.sort_values(by='p_value').head(100)['feature']\n",
    "    top_features[col] = top_k_features\n",
    "\n",
    "final_features = pd.concat([top_features[col] for col in top_features.columns]).unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "['укронацистов',\n 'укрорейха',\n 'неонацистов',\n 'чубайса',\n 'укропитеков',\n 'донецка',\n 'укронацисты',\n 'всушников',\n 'салорейха',\n 'нацистов',\n 'президента',\n 'обстрела',\n 'москве',\n 'хохлорейха',\n 'укронациста',\n 'города',\n 'шайкой',\n 'боевиков',\n 'горловки',\n 'свинособаки',\n 'пропаганды',\n 'укронацизма',\n 'неонацистами',\n 'коронавируса',\n 'укрорейхом',\n 'оружия',\n 'наркоманов',\n 'свинорейха',\n 'позициям',\n 'бригады',\n 'хозяева',\n 'мид',\n 'укронацистами',\n 'подразделений',\n 'укрорейху',\n 'жизней',\n 'атаки',\n 'обстрелы',\n 'задача',\n 'их',\n 'укрорейхе',\n 'захвата',\n 'нациков',\n 'укронациков',\n 'позиции',\n 'рядах',\n 'координаты',\n 'рублей',\n 'смерти',\n 'дислокации',\n 'перемога',\n 'представитель',\n 'лица',\n 'работа',\n 'неонацисты',\n 'атаку',\n 'режима',\n 'новостей',\n 'склады',\n 'стиле',\n 'жители',\n 'утилизации',\n 'хунты',\n 'всу',\n 'воевать',\n 'новости',\n 'коронавирусом',\n 'командование',\n 'место',\n 'тактике',\n 'уничтожить',\n 'сектора',\n 'освобождения',\n 'войск',\n 'рсзо',\n 'просвещения',\n 'мариуполя',\n 'бойцы',\n 'рождения',\n 'желание',\n 'преступление',\n 'бандеровцами',\n 'убийства',\n 'года',\n 'случаев',\n 'азова',\n 'удара',\n 'уничтожения',\n 'референдума',\n 'рейха',\n 'со',\n 'солдат',\n 'посты',\n 'укровермахта',\n 'располага',\n 'консенсуса',\n 'история',\n 'церкви',\n 'паблики',\n 'репортаж',\n nan,\n 'бьют',\n 'ждет',\n 'губернатор',\n 'готовят',\n 'людей',\n 'технику',\n 'люди',\n 'москва']"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_features, columns=['final_features'])\n",
    "df.to_json('most_important_features.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importance of columns (ie collocations and versions of pre-processing)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Averaged importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def get_average_importance(trained_pipeline):\n",
    "    multi_column_tfidf_vectorizer = trained_pipeline.named_steps['vectorizer']\n",
    "    logistic_regression = trained_pipeline.named_steps['regressor']\n",
    "    coef = logistic_regression.coef_\n",
    "\n",
    "    column_importance = pd.DataFrame()\n",
    "    start = 0\n",
    "    for i, col in enumerate(multi_column_tfidf_vectorizer.columns):\n",
    "        vec = multi_column_tfidf_vectorizer.fitted_models[i]\n",
    "        end = start + len(vec.get_feature_names_out())\n",
    "        feature_scores = pd.DataFrame({\n",
    "            'feature': vec.get_feature_names_out(),\n",
    "            'importance': abs(coef[0][start:end])\n",
    "        })\n",
    "        column_importance[col] = feature_scores.set_index('feature')['importance']\n",
    "        start = end\n",
    "\n",
    "    mean_importance = column_importance.mean(axis=0).sort_values(ascending=False)\n",
    "    return mean_importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_noun_verb     0.259424\n",
      "text_lemmatized    0.249534\n",
      "amod               0.235747\n",
      "nmod               0.207353\n",
      "verb_obl_obj       0.189647\n",
      "text_clean         0.162578\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_importance = get_average_importance(trained_pipeline)\n",
    "print(mean_importance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importance of columns by permutation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[['nmod'],\n ['verb_obl_obj'],\n ['core_noun_verb'],\n ['amod'],\n ['text_lemmatized'],\n ['text_clean'],\n ['nmod', 'verb_obl_obj'],\n ['nmod', 'core_noun_verb'],\n ['nmod', 'amod'],\n ['nmod', 'text_lemmatized'],\n ['nmod', 'text_clean'],\n ['verb_obl_obj', 'core_noun_verb'],\n ['verb_obl_obj', 'amod'],\n ['verb_obl_obj', 'text_lemmatized'],\n ['verb_obl_obj', 'text_clean'],\n ['core_noun_verb', 'amod'],\n ['core_noun_verb', 'text_lemmatized'],\n ['core_noun_verb', 'text_clean'],\n ['amod', 'text_lemmatized'],\n ['amod', 'text_clean'],\n ['text_lemmatized', 'text_clean'],\n ['nmod', 'verb_obl_obj', 'core_noun_verb'],\n ['nmod', 'verb_obl_obj', 'amod'],\n ['nmod', 'verb_obl_obj', 'text_lemmatized'],\n ['nmod', 'verb_obl_obj', 'text_clean'],\n ['nmod', 'core_noun_verb', 'amod'],\n ['nmod', 'core_noun_verb', 'text_lemmatized'],\n ['nmod', 'core_noun_verb', 'text_clean'],\n ['nmod', 'amod', 'text_lemmatized'],\n ['nmod', 'amod', 'text_clean'],\n ['nmod', 'text_lemmatized', 'text_clean'],\n ['verb_obl_obj', 'core_noun_verb', 'amod'],\n ['verb_obl_obj', 'core_noun_verb', 'text_lemmatized'],\n ['verb_obl_obj', 'core_noun_verb', 'text_clean'],\n ['verb_obl_obj', 'amod', 'text_lemmatized'],\n ['verb_obl_obj', 'amod', 'text_clean'],\n ['verb_obl_obj', 'text_lemmatized', 'text_clean'],\n ['core_noun_verb', 'amod', 'text_lemmatized'],\n ['core_noun_verb', 'amod', 'text_clean'],\n ['core_noun_verb', 'text_lemmatized', 'text_clean'],\n ['amod', 'text_lemmatized', 'text_clean'],\n ['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod'],\n ['nmod', 'verb_obl_obj', 'core_noun_verb', 'text_lemmatized'],\n ['nmod', 'verb_obl_obj', 'core_noun_verb', 'text_clean'],\n ['nmod', 'verb_obl_obj', 'amod', 'text_lemmatized'],\n ['nmod', 'verb_obl_obj', 'amod', 'text_clean'],\n ['nmod', 'verb_obl_obj', 'text_lemmatized', 'text_clean'],\n ['nmod', 'core_noun_verb', 'amod', 'text_lemmatized'],\n ['nmod', 'core_noun_verb', 'amod', 'text_clean'],\n ['nmod', 'core_noun_verb', 'text_lemmatized', 'text_clean'],\n ['nmod', 'amod', 'text_lemmatized', 'text_clean'],\n ['verb_obl_obj', 'core_noun_verb', 'amod', 'text_lemmatized'],\n ['verb_obl_obj', 'core_noun_verb', 'amod', 'text_clean'],\n ['verb_obl_obj', 'core_noun_verb', 'text_lemmatized', 'text_clean'],\n ['verb_obl_obj', 'amod', 'text_lemmatized', 'text_clean'],\n ['core_noun_verb', 'amod', 'text_lemmatized', 'text_clean'],\n ['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod', 'text_lemmatized'],\n ['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod', 'text_clean'],\n ['nmod', 'verb_obl_obj', 'core_noun_verb', 'text_lemmatized', 'text_clean'],\n ['nmod', 'verb_obl_obj', 'amod', 'text_lemmatized', 'text_clean'],\n ['nmod', 'core_noun_verb', 'amod', 'text_lemmatized', 'text_clean'],\n ['verb_obl_obj', 'core_noun_verb', 'amod', 'text_lemmatized', 'text_clean'],\n ['nmod',\n  'verb_obl_obj',\n  'core_noun_verb',\n  'amod',\n  'text_lemmatized',\n  'text_clean']]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "text_columns = ['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod', 'text_lemmatized', 'text_clean']\n",
    "\n",
    "all_col_variations = list(chain.from_iterable(combinations(text_columns, r) for r in range(1, len(text_columns)+1)))\n",
    "all_col_variations = [list(p) for p in all_col_variations]\n",
    "all_col_variations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MultiColumnTfidfVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, **kwargs):\n",
    "        self.columns = columns\n",
    "        self.vectorizers = [TfidfVectorizer(**kwargs) for _ in columns]\n",
    "        self.fitted_models = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col, vec in zip(self.columns, self.vectorizers):\n",
    "            vec.fit(X[col])\n",
    "            self.fitted_models.append(vec.fit(X[col]))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        for col, vec in zip(self.columns, self.vectorizers):\n",
    "            features.append(vec.transform(X[col]))\n",
    "        return hstack(features)\n",
    "\n",
    "\n",
    "def train_logistic_regression(data, text_columns, label_column, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=0.2, random_state=random_state)\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', MultiColumnTfidfVectorizer(columns=text_columns)),\n",
    "        ('regressor', LogisticRegression(solver='liblinear', random_state=random_state, max_iter=100))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'regressor__fit_intercept': [True, False],\n",
    "        'regressor__C': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 100],\n",
    "        'regressor__penalty': ['l1', 'l2']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    logreg_best = grid_search.best_estimator_\n",
    "    logreg_best.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg_best.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return logreg_best, [accuracy, precision, recall, f1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 30min 46s, sys: 49min 12s, total: 2h 19min 58s\n",
      "Wall time: 37min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_trained_pipelines = []\n",
    "all_results = []\n",
    "for col_set in all_col_variations:\n",
    "    current_pipe, results = train_logistic_regression(df_dehumanization, col_set, label_column)\n",
    "    all_trained_pipelines.append(current_pipe)\n",
    "    all_results.append(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "idx_largest = max(range(len(all_results)), key=lambda i: all_results[i][-1])\n",
    "\n",
    "next_largest = max([all_results[i][-1] for i in range(len(all_results)) if all_results[i][-1] < all_results[idx_largest][-1]])\n",
    "idx_next_largest = max([i for i in range(len(all_results)) if all_results[i][-1] == next_largest])\n",
    "\n",
    "print(idx_next_largest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.8074712643678161,\n 0.8193979933110368,\n 0.7538461538461538,\n 0.7852564102564102]"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[idx_largest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('vectorizer',\n                 MultiColumnTfidfVectorizer(columns=['text_lemmatized'])),\n                ('regressor',\n                 LogisticRegression(C=10, penalty='l1', random_state=42,\n                                    solver='liblinear'))])",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n                 MultiColumnTfidfVectorizer(columns=[&#x27;text_lemmatized&#x27;])),\n                (&#x27;regressor&#x27;,\n                 LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=42,\n                                    solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n                 MultiColumnTfidfVectorizer(columns=[&#x27;text_lemmatized&#x27;])),\n                (&#x27;regressor&#x27;,\n                 LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=42,\n                                    solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiColumnTfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>MultiColumnTfidfVectorizer(columns=[&#x27;text_lemmatized&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trained_pipelines[idx_largest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('vectorizer',\n                 MultiColumnTfidfVectorizer(columns=['verb_obl_obj',\n                                                     'text_lemmatized',\n                                                     'text_clean'])),\n                ('regressor',\n                 LogisticRegression(C=10, penalty='l1', random_state=42,\n                                    solver='liblinear'))])",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n                 MultiColumnTfidfVectorizer(columns=[&#x27;verb_obl_obj&#x27;,\n                                                     &#x27;text_lemmatized&#x27;,\n                                                     &#x27;text_clean&#x27;])),\n                (&#x27;regressor&#x27;,\n                 LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=42,\n                                    solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n                 MultiColumnTfidfVectorizer(columns=[&#x27;verb_obl_obj&#x27;,\n                                                     &#x27;text_lemmatized&#x27;,\n                                                     &#x27;text_clean&#x27;])),\n                (&#x27;regressor&#x27;,\n                 LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=42,\n                                    solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiColumnTfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>MultiColumnTfidfVectorizer(columns=[&#x27;verb_obl_obj&#x27;, &#x27;text_lemmatized&#x27;,\n                                    &#x27;text_clean&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trained_pipelines[idx_next_largest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.8074712643678161,\n 0.8281786941580757,\n 0.7415384615384616,\n 0.7824675324675325]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[idx_next_largest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "label_column = ['label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "class MultiColumnTfidfVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, **kwargs):\n",
    "        self.columns = columns\n",
    "        self.vectorizers = [TfidfVectorizer(**kwargs) for _ in columns]\n",
    "        self.fitted_models = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col, vec in zip(self.columns, self.vectorizers):\n",
    "            vec.fit(X[col])\n",
    "            self.fitted_models.append(vec.fit(X[col]))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        for col, vec in zip(self.columns, self.vectorizers):\n",
    "            features.append(vec.transform(X[col]))\n",
    "        return hstack(features)\n",
    "\n",
    "\n",
    "def train_svm(data, text_columns, label_column, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=0.2, random_state=random_state)\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', MultiColumnTfidfVectorizer(columns=text_columns)),\n",
    "        ('classifier', SVC(kernel='linear', random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 100],\n",
    "        # 'classifier__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    svm_best = grid_search.best_estimator_\n",
    "    svm_best.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svm_best.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return svm_best, [accuracy, precision, recall, f1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39min 20s, sys: 14.2 s, total: 39min 34s\n",
      "Wall time: 1h 15min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_trained_pipelines = []\n",
    "all_results = []\n",
    "for col_set in all_col_variations:\n",
    "    current_pipe, results = train_svm(df_dehumanization, col_set, label_column)\n",
    "    all_trained_pipelines.append(current_pipe)\n",
    "    all_results.append(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "idx_largest = max(range(len(all_results)), key=lambda i: all_results[i][-1])\n",
    "\n",
    "next_largest = max([all_results[i][-1] for i in range(len(all_results)) if all_results[i][-1] < all_results[idx_largest][-1]])\n",
    "idx_next_largest = max([i for i in range(len(all_results)) if all_results[i][-1] == next_largest])\n",
    "\n",
    "print(idx_next_largest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.7945402298850575,\n 0.8053691275167785,\n 0.7384615384615385,\n 0.7704654895666131]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[idx_largest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('vectorizer',\n                 MultiColumnTfidfVectorizer(columns=['text_lemmatized'])),\n                ('classifier', SVC(C=1, kernel='linear', random_state=42))])",
      "text/html": "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n                 MultiColumnTfidfVectorizer(columns=[&#x27;text_lemmatized&#x27;])),\n                (&#x27;classifier&#x27;, SVC(C=1, kernel=&#x27;linear&#x27;, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n                 MultiColumnTfidfVectorizer(columns=[&#x27;text_lemmatized&#x27;])),\n                (&#x27;classifier&#x27;, SVC(C=1, kernel=&#x27;linear&#x27;, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiColumnTfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>MultiColumnTfidfVectorizer(columns=[&#x27;text_lemmatized&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trained_pipelines[idx_largest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('vectorizer',\n   MultiColumnTfidfVectorizer(columns=['text_lemmatized'])),\n  ('classifier', SVC(C=1, kernel='linear', random_state=42))],\n 'verbose': False,\n 'vectorizer': MultiColumnTfidfVectorizer(columns=['text_lemmatized']),\n 'classifier': SVC(C=1, kernel='linear', random_state=42),\n 'vectorizer__columns': ['text_lemmatized'],\n 'classifier__C': 1,\n 'classifier__break_ties': False,\n 'classifier__cache_size': 200,\n 'classifier__class_weight': None,\n 'classifier__coef0': 0.0,\n 'classifier__decision_function_shape': 'ovr',\n 'classifier__degree': 3,\n 'classifier__gamma': 'scale',\n 'classifier__kernel': 'linear',\n 'classifier__max_iter': -1,\n 'classifier__probability': False,\n 'classifier__random_state': 42,\n 'classifier__shrinking': True,\n 'classifier__tol': 0.001,\n 'classifier__verbose': False}"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trained_pipelines[idx_largest].get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "     Dehumanization                                               text  label  \\\n0               так  Всвязи с этим немного поправлю коллег ⤵️  \"Они...      1   \n1                ні  Литературный критик Галина Юзефович о новом ро...      0   \n2               так  Почему на базах неонацистов стоят языческие ис...      1   \n3               так  Группа добровольцев-медиков из Чеченской Респу...      1   \n4                ні  ВСУшники, переходите на сторону добра, у нас т...      0   \n...             ...                                                ...    ...   \n3474             ні  Утренний брифинг Минобороны России:  ▪️ россий...      0   \n3475             ні  И понеслась мазепинщино-петлюровщино-бандеровщ...      0   \n3476             ні  Наш соратник по русскому движению Алексей Сели...      0   \n3477            так  Хорошее видео от 4 бригады НМ ЛНР https://t.me...      1   \n3478             ні  Замоскворецкий районный суд Москвы отклонил ис...      0   \n\n                                             text_clean  \\\n0     всвязи с этим немного поправлю коллег   они не...   \n1     литературный критик галина юзефович о новом ро...   \n2     почему на базах неонацистов стоят языческие ис...   \n3     группа добровольцевмедиков из чеченской респуб...   \n4     всушники переходите на сторону добра у нас теп...   \n...                                                 ...   \n3474  утренний брифинг минобороны россии   российски...   \n3475    и понеслась мазепинщинопетлюровщинобандеровщина   \n3476  наш соратник по русскому движению алексей сели...   \n3477  хорошее видео от  бригады нм лнр  обработка по...   \n3478  замоскворецкий районный суд москвы отклонил ис...   \n\n                                        text_lemmatized  \\\n0     всвязи с это немного поправить коллега    они ...   \n1     литературный критик галина юзефович о новый ро...   \n2     почему на база неонацист стоять языческий исту...   \n3     группа добровольцевмедиков из чеченский респуб...   \n4     всушники переходить на сторона добро у нас тёп...   \n...                                                 ...   \n3474  утренний брифинг минобороны россия    российск...   \n3475    и понестись мазепинщинопетлюровщинобандеровщина   \n3476  наш соратник по русский движение алексей селив...   \n3477  хороший видео от   бригада нм лнр   обработка ...   \n3478  замоскворецкий районный суд москва отклонить и...   \n\n                                         core_noun_verb  \\\n0     Всвязи немного поправлю, Они не начинать, мы д...   \n1     критик все состоит, достоинство все состоит, э...   \n2                                 истуканы Почему стоят   \n3                Группа наравне вносит, врачи оказывают   \n4                        ВСУшники переходите, тепло нас   \n...                                                 ...   \n3474  брифинг продвинулись, силы продвинулись, групп...   \n3475                                                      \n3476                             соратник вместе прибыл   \n3477                                                      \n3478                                       суд отклонил   \n\n                                           verb_obl_obj  \\\n0     немного поправлю коллег, не начинать армагеддо...   \n1            состоит в том, захватывающе читать которую   \n2                                 Почему стоят на базах   \n3     вносит лепту, вносит в дело, вносит -, вносит ...   \n4                                 переходите на сторону   \n...                                                 ...   \n3474  продвинулись за ночь, продвинулись на км, разв...   \n3475  понеслась петлюровщино, понеслась -, понеслась...   \n3476  прибыл в область, создавать органы, создавать ...   \n3477                                                      \n3478                     отклонил иск, отменить решение   \n\n                                                   nmod  \\\n0     Всвязи с этим, диверсии в Польше, удар ТЯО, уд...   \n1     критик петербуржца романе, романе петербуржца,...   \n2     базах неонацистов, Гость студии, протоиерей СМ...   \n3     Группа добровольцев, Группа -, Группа медиков,...   \n4                                         сторону добра   \n...                                                 ...   \n3474  брифинг Минобороны, наступление бригады подраз...   \n3475                                                      \n3476  соратник русскому движению, армией России, орг...   \n3477  видео НМ бригады, бригады НМ, обработка позици...   \n3478  суд Москвы, иск историка, иск РФ Минюсту, иск ...   \n\n                                                   amod comp  \\\n0     ядерный армагеддон, осознанный удар, Львовской...        \n1     Литературный критик, новом романе, Главное дос...        \n2                                    языческие истуканы        \n3     бандеровских мразей, подлых шайтанов, Республи...        \n4                                      вкусные печеньки        \n...                                                 ...  ...   \n3474  Утренний брифинг, российские силы, украинской ...        \n3475                                                           \n3476  русскому движению, Запорожскую область, мирной...        \n3477                  Хорошее видео, пифтонными бомбами        \n3478                   Замоскворецкий суд, районный суд        \n\n                                             merged_col  \n0     Всвязи с этим, диверсии в Польше, удар ТЯО, уд...  \n1     критик петербуржца романе, романе петербуржца,...  \n2     базах неонацистов, Гость студии, протоиерей СМ...  \n3     Группа добровольцев, Группа -, Группа медиков,...  \n4     сторону добра переходите на сторону ВСУшники п...  \n...                                                 ...  \n3474  брифинг Минобороны, наступление бригады подраз...  \n3475   понеслась петлюровщино, понеслась -, понеслас...  \n3476  соратник русскому движению, армией России, орг...  \n3477  видео НМ бригады, бригады НМ, обработка позици...  \n3478  суд Москвы, иск историка, иск РФ Минюсту, иск ...  \n\n[3479 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dehumanization</th>\n      <th>text</th>\n      <th>label</th>\n      <th>text_clean</th>\n      <th>text_lemmatized</th>\n      <th>core_noun_verb</th>\n      <th>verb_obl_obj</th>\n      <th>nmod</th>\n      <th>amod</th>\n      <th>comp</th>\n      <th>merged_col</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>так</td>\n      <td>Всвязи с этим немного поправлю коллег ⤵️  \"Они...</td>\n      <td>1</td>\n      <td>всвязи с этим немного поправлю коллег   они не...</td>\n      <td>всвязи с это немного поправить коллега    они ...</td>\n      <td>Всвязи немного поправлю, Они не начинать, мы д...</td>\n      <td>немного поправлю коллег, не начинать армагеддо...</td>\n      <td>Всвязи с этим, диверсии в Польше, удар ТЯО, уд...</td>\n      <td>ядерный армагеддон, осознанный удар, Львовской...</td>\n      <td></td>\n      <td>Всвязи с этим, диверсии в Польше, удар ТЯО, уд...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ні</td>\n      <td>Литературный критик Галина Юзефович о новом ро...</td>\n      <td>0</td>\n      <td>литературный критик галина юзефович о новом ро...</td>\n      <td>литературный критик галина юзефович о новый ро...</td>\n      <td>критик все состоит, достоинство все состоит, э...</td>\n      <td>состоит в том, захватывающе читать которую</td>\n      <td>критик петербуржца романе, романе петербуржца,...</td>\n      <td>Литературный критик, новом романе, Главное дос...</td>\n      <td></td>\n      <td>критик петербуржца романе, романе петербуржца,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>так</td>\n      <td>Почему на базах неонацистов стоят языческие ис...</td>\n      <td>1</td>\n      <td>почему на базах неонацистов стоят языческие ис...</td>\n      <td>почему на база неонацист стоять языческий исту...</td>\n      <td>истуканы Почему стоят</td>\n      <td>Почему стоят на базах</td>\n      <td>базах неонацистов, Гость студии, протоиерей СМ...</td>\n      <td>языческие истуканы</td>\n      <td></td>\n      <td>базах неонацистов, Гость студии, протоиерей СМ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>так</td>\n      <td>Группа добровольцев-медиков из Чеченской Респу...</td>\n      <td>1</td>\n      <td>группа добровольцевмедиков из чеченской респуб...</td>\n      <td>группа добровольцевмедиков из чеченский респуб...</td>\n      <td>Группа наравне вносит, врачи оказывают</td>\n      <td>вносит лепту, вносит в дело, вносит -, вносит ...</td>\n      <td>Группа добровольцев, Группа -, Группа медиков,...</td>\n      <td>бандеровских мразей, подлых шайтанов, Республи...</td>\n      <td></td>\n      <td>Группа добровольцев, Группа -, Группа медиков,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ні</td>\n      <td>ВСУшники, переходите на сторону добра, у нас т...</td>\n      <td>0</td>\n      <td>всушники переходите на сторону добра у нас теп...</td>\n      <td>всушники переходить на сторона добро у нас тёп...</td>\n      <td>ВСУшники переходите, тепло нас</td>\n      <td>переходите на сторону</td>\n      <td>сторону добра</td>\n      <td>вкусные печеньки</td>\n      <td></td>\n      <td>сторону добра переходите на сторону ВСУшники п...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3474</th>\n      <td>ні</td>\n      <td>Утренний брифинг Минобороны России:  ▪️ россий...</td>\n      <td>0</td>\n      <td>утренний брифинг минобороны россии   российски...</td>\n      <td>утренний брифинг минобороны россия    российск...</td>\n      <td>брифинг продвинулись, силы продвинулись, групп...</td>\n      <td>продвинулись за ночь, продвинулись на км, разв...</td>\n      <td>брифинг Минобороны, наступление бригады подраз...</td>\n      <td>Утренний брифинг, российские силы, украинской ...</td>\n      <td></td>\n      <td>брифинг Минобороны, наступление бригады подраз...</td>\n    </tr>\n    <tr>\n      <th>3475</th>\n      <td>ні</td>\n      <td>И понеслась мазепинщино-петлюровщино-бандеровщ...</td>\n      <td>0</td>\n      <td>и понеслась мазепинщинопетлюровщинобандеровщина</td>\n      <td>и понестись мазепинщинопетлюровщинобандеровщина</td>\n      <td></td>\n      <td>понеслась петлюровщино, понеслась -, понеслась...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>понеслась петлюровщино, понеслась -, понеслас...</td>\n    </tr>\n    <tr>\n      <th>3476</th>\n      <td>ні</td>\n      <td>Наш соратник по русскому движению Алексей Сели...</td>\n      <td>0</td>\n      <td>наш соратник по русскому движению алексей сели...</td>\n      <td>наш соратник по русский движение алексей селив...</td>\n      <td>соратник вместе прибыл</td>\n      <td>прибыл в область, создавать органы, создавать ...</td>\n      <td>соратник русскому движению, армией России, орг...</td>\n      <td>русскому движению, Запорожскую область, мирной...</td>\n      <td></td>\n      <td>соратник русскому движению, армией России, орг...</td>\n    </tr>\n    <tr>\n      <th>3477</th>\n      <td>так</td>\n      <td>Хорошее видео от 4 бригады НМ ЛНР https://t.me...</td>\n      <td>1</td>\n      <td>хорошее видео от  бригады нм лнр  обработка по...</td>\n      <td>хороший видео от   бригада нм лнр   обработка ...</td>\n      <td></td>\n      <td></td>\n      <td>видео НМ бригады, бригады НМ, обработка позици...</td>\n      <td>Хорошее видео, пифтонными бомбами</td>\n      <td></td>\n      <td>видео НМ бригады, бригады НМ, обработка позици...</td>\n    </tr>\n    <tr>\n      <th>3478</th>\n      <td>ні</td>\n      <td>Замоскворецкий районный суд Москвы отклонил ис...</td>\n      <td>0</td>\n      <td>замоскворецкий районный суд москвы отклонил ис...</td>\n      <td>замоскворецкий районный суд москва отклонить и...</td>\n      <td>суд отклонил</td>\n      <td>отклонил иск, отменить решение</td>\n      <td>суд Москвы, иск историка, иск РФ Минюсту, иск ...</td>\n      <td>Замоскворецкий суд, районный суд</td>\n      <td></td>\n      <td>суд Москвы, иск историка, иск РФ Минюсту, иск ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3479 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dehumanization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## With augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df_rm = pd.read_csv('/Users/katerynaburovova/PycharmProjects/dehumanization/augmentation/augm_removed_dehumanization.csv', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from collocation_extraction import collect_verb_obl_obj, collect_core, collect_nmod, collect_amod, collect_comp, collect_appos, show_dependency, lst_to_str\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# df_add = pd.read_csv('/Users/katerynaburovova/PycharmProjects/dehumanization/augmentation/augm_added_dehumanization.csv', index_col=[0])\n",
    "df_augmentation = pd.read_csv('/Users/katerynaburovova/PycharmProjects/dehumanization/augmentation/augm_neutal_in_class.csv', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "      index                  Emotion Dehumanization Mention   External ID  \\\n3      3247   ні, оцінка не присутня             ні     так  row_1000.txt   \n4      3246   ні, оцінка не присутня             ні     так  row_1001.txt   \n8      3240   ні, оцінка не присутня             ні     так  row_1007.txt   \n10     3238   ні, оцінка не присутня             ні     так  row_1009.txt   \n12     3288   ні, оцінка не присутня             ні     так  row_1011.txt   \n...     ...                      ...            ...     ...           ...   \n2490   2402  так, присутня негативна             ні     так    row_99.txt   \n2494   3615   ні, оцінка не присутня             ні     так   row_993.txt   \n2495   3613   ні, оцінка не присутня             ні     так   row_995.txt   \n2496   3612  так, присутня негативна             ні     так   row_996.txt   \n2497   4121  так, присутня негативна             ні     так   row_997.txt   \n\n                        Created By  \\\n3           tutovadesign@gmail.com   \n4           tutovadesign@gmail.com   \n8           tutovadesign@gmail.com   \n10          tutovadesign@gmail.com   \n12          tutovadesign@gmail.com   \n...                            ...   \n2490  nazariy.melnychuk9@gmail.com   \n2494        tutovadesign@gmail.com   \n2495        tutovadesign@gmail.com   \n2496        tutovadesign@gmail.com   \n2497  yevhen.marchenko91@gmail.com   \n\n                                                   text  rating  \\\n3     ВСУшники, переходите на сторону добра, у нас т...       5   \n4     Наши ребята столкнулись с полком «Азов» и морс...       5   \n8     ⚡️ВСУ нанесли артиллерийский удар по больнице ...       5   \n10    Применение Коллективных сил Организации Догово...       5   \n12    В этом списке есть Кум, есть уважаемые партнер...       5   \n...                                                 ...     ...   \n2490  🇺🇦❌Очередной фейк укропропаганды  Укропаблики ...       7   \n2494  ⚡️Путин: Нам нужно ответить на вопрос, который...       5   \n2495  Утренний брифинг Минобороны России:  ▪️ россий...       5   \n2496  И понеслась мазепинщино-петлюровщино-бандеровщ...       5   \n2497  Наш соратник по русскому движению Алексей Сели...       3   \n\n                                             text_clean  \\\n3     всушники, переходите на сторону добра, у нас т...   \n4     наши ребята столкнулись с полком азов и морско...   \n8     всу нанесли артиллерийский удар по больнице в ...   \n10    применение коллективных сил организации догово...   \n12    в этом списке есть кум, есть уважаемые партнер...   \n...                                                 ...   \n2490  очередной фейк укропропаганды  укропаблики сег...   \n2494  путин: нам нужно ответить на вопрос, который п...   \n2495  утренний брифинг минобороны россии:   российск...   \n2496  и понеслась мазепинщино-петлюровщино-бандеровщ...   \n2497  наш соратник по русскому движению алексей сели...   \n\n                                        text_lemmatized  \\\n3     ['всушники', ',', 'переходить', 'на', 'сторона...   \n4     ['наш', 'ребята', 'столкнуться', 'с', 'полок',...   \n8     ['всу', 'нанести', 'артиллерийский', 'удар', '...   \n10    ['применение', 'коллективный', 'сила', 'органи...   \n12    ['в', 'этот', 'список', 'быть', 'кум', ',', 'б...   \n...                                                 ...   \n2490  ['очередной', 'фейк', 'укропропаганды', ' ', '...   \n2494  ['путин', ':', 'нам', 'нужный', 'ответить', 'н...   \n2495  ['утренний', 'брифинг', 'минобороны', 'россия'...   \n2496  ['и', 'понестись', 'мазепинщино', '-', 'петлюр...   \n2497  ['наш', 'соратник', 'по', 'русский', 'движение...   \n\n                                       found_ukrainians  \\\n3     [{'lemma': 'всушник', 'position': 0, 'morph_fo...   \n4     [{'lemma': 'всу', 'position': 9, 'morph_form':...   \n8     [{'lemma': 'всу', 'position': 0, 'morph_form':...   \n10                                                   []   \n12                                                   []   \n...                                                 ...   \n2490                                                 []   \n2494                                                 []   \n2495                                                 []   \n2496                                                 []   \n2497  [{'lemma': 'укроп', 'position': 27, 'morph_for...   \n\n                       replaced_neutral_sent_ukrainians  \n3     украинцы, переходите на сторону добра, у нас т...  \n4     наши ребята столкнулись с полком азов и морско...  \n8     украинцы нанесли артиллерийский удар по больни...  \n10    применение коллективных сил организации догово...  \n12    в этом списке есть кум, есть уважаемые партнер...  \n...                                                 ...  \n2490  очередной фейк укропропаганды  укропаблики сег...  \n2494  путин: нам нужно ответить на вопрос, который п...  \n2495  утренний брифинг минобороны россии:   российск...  \n2496  и понеслась мазепинщино-петлюровщино-бандеровщ...  \n2497  наш соратник по русскому движению алексей сели...  \n\n[880 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Emotion</th>\n      <th>Dehumanization</th>\n      <th>Mention</th>\n      <th>External ID</th>\n      <th>Created By</th>\n      <th>text</th>\n      <th>rating</th>\n      <th>text_clean</th>\n      <th>text_lemmatized</th>\n      <th>found_ukrainians</th>\n      <th>replaced_neutral_sent_ukrainians</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>3247</td>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_1000.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>ВСУшники, переходите на сторону добра, у нас т...</td>\n      <td>5</td>\n      <td>всушники, переходите на сторону добра, у нас т...</td>\n      <td>['всушники', ',', 'переходить', 'на', 'сторона...</td>\n      <td>[{'lemma': 'всушник', 'position': 0, 'morph_fo...</td>\n      <td>украинцы, переходите на сторону добра, у нас т...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3246</td>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_1001.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>Наши ребята столкнулись с полком «Азов» и морс...</td>\n      <td>5</td>\n      <td>наши ребята столкнулись с полком азов и морско...</td>\n      <td>['наш', 'ребята', 'столкнуться', 'с', 'полок',...</td>\n      <td>[{'lemma': 'всу', 'position': 9, 'morph_form':...</td>\n      <td>наши ребята столкнулись с полком азов и морско...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3240</td>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_1007.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>⚡️ВСУ нанесли артиллерийский удар по больнице ...</td>\n      <td>5</td>\n      <td>всу нанесли артиллерийский удар по больнице в ...</td>\n      <td>['всу', 'нанести', 'артиллерийский', 'удар', '...</td>\n      <td>[{'lemma': 'всу', 'position': 0, 'morph_form':...</td>\n      <td>украинцы нанесли артиллерийский удар по больни...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3238</td>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_1009.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>Применение Коллективных сил Организации Догово...</td>\n      <td>5</td>\n      <td>применение коллективных сил организации догово...</td>\n      <td>['применение', 'коллективный', 'сила', 'органи...</td>\n      <td>[]</td>\n      <td>применение коллективных сил организации догово...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3288</td>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_1011.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>В этом списке есть Кум, есть уважаемые партнер...</td>\n      <td>5</td>\n      <td>в этом списке есть кум, есть уважаемые партнер...</td>\n      <td>['в', 'этот', 'список', 'быть', 'кум', ',', 'б...</td>\n      <td>[]</td>\n      <td>в этом списке есть кум, есть уважаемые партнер...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2490</th>\n      <td>2402</td>\n      <td>так, присутня негативна</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_99.txt</td>\n      <td>nazariy.melnychuk9@gmail.com</td>\n      <td>🇺🇦❌Очередной фейк укропропаганды  Укропаблики ...</td>\n      <td>7</td>\n      <td>очередной фейк укропропаганды  укропаблики сег...</td>\n      <td>['очередной', 'фейк', 'укропропаганды', ' ', '...</td>\n      <td>[]</td>\n      <td>очередной фейк укропропаганды  укропаблики сег...</td>\n    </tr>\n    <tr>\n      <th>2494</th>\n      <td>3615</td>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_993.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>⚡️Путин: Нам нужно ответить на вопрос, который...</td>\n      <td>5</td>\n      <td>путин: нам нужно ответить на вопрос, который п...</td>\n      <td>['путин', ':', 'нам', 'нужный', 'ответить', 'н...</td>\n      <td>[]</td>\n      <td>путин: нам нужно ответить на вопрос, который п...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>3613</td>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_995.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>Утренний брифинг Минобороны России:  ▪️ россий...</td>\n      <td>5</td>\n      <td>утренний брифинг минобороны россии:   российск...</td>\n      <td>['утренний', 'брифинг', 'минобороны', 'россия'...</td>\n      <td>[]</td>\n      <td>утренний брифинг минобороны россии:   российск...</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>3612</td>\n      <td>так, присутня негативна</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_996.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>И понеслась мазепинщино-петлюровщино-бандеровщ...</td>\n      <td>5</td>\n      <td>и понеслась мазепинщино-петлюровщино-бандеровщ...</td>\n      <td>['и', 'понестись', 'мазепинщино', '-', 'петлюр...</td>\n      <td>[]</td>\n      <td>и понеслась мазепинщино-петлюровщино-бандеровщ...</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>4121</td>\n      <td>так, присутня негативна</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_997.txt</td>\n      <td>yevhen.marchenko91@gmail.com</td>\n      <td>Наш соратник по русскому движению Алексей Сели...</td>\n      <td>3</td>\n      <td>наш соратник по русскому движению алексей сели...</td>\n      <td>['наш', 'соратник', 'по', 'русский', 'движение...</td>\n      <td>[{'lemma': 'укроп', 'position': 27, 'morph_for...</td>\n      <td>наш соратник по русскому движению алексей сели...</td>\n    </tr>\n  </tbody>\n</table>\n<p>880 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# df_augmentation = pd.concat([df_rm,df_add])\n",
    "# df_augmentation = df_add.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# def preprocess_df_(df):\n",
    "#     df['text_clean'] = df['fixed_sentences'].apply(lambda x: clean_text(x.lower(), cyrillic_letters))\n",
    "#     df['text_lemmatized'] = df['text_clean'].apply(lambda x: lemmatize_spacy(x))\n",
    "#     df=df[df['text_clean']!='']\n",
    "#     df.reset_index(inplace=True)\n",
    "#     return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "text_columns = ['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod', 'text_lemmatized', 'text_clean']\n",
    "\n",
    "all_col_variations = list(chain.from_iterable(combinations(text_columns, r) for r in range(1, len(text_columns)+1)))\n",
    "all_col_variations = [list(p) for p in all_col_variations]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "label_column = ['label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.76 s, sys: 36.4 ms, total: 4.8 s\n",
      "Wall time: 4.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_augmentation = preprocess_df(df_augmentation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "df_augmentation['core_noun_verb'] = df_augmentation['text_clean'].apply(lambda x: lst_to_str(collect_core(x)))\n",
    "df_augmentation['verb_obl_obj'] = df_augmentation['text_clean'].apply(lambda x: lst_to_str(collect_verb_obl_obj(x)))\n",
    "df_augmentation['nmod'] = df_augmentation['text_clean'].apply(lambda x: lst_to_str(collect_nmod(x)))\n",
    "df_augmentation['amod'] = df_augmentation['text_clean'].apply(lambda x: lst_to_str(collect_amod(x)))\n",
    "df_augmentation['comp'] = df_augmentation['text_clean'].apply(lambda x: lst_to_str(collect_comp(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/1996300300.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['core_noun_verb'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_core(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/1996300300.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['verb_obl_obj'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_verb_obl_obj(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/1996300300.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['nmod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_nmod(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/1996300300.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['amod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_amod(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_40366/1996300300.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['comp'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_comp(x)))\n"
     ]
    }
   ],
   "source": [
    "df_dehumanization['core_noun_verb'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_core(x)))\n",
    "df_dehumanization['verb_obl_obj'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_verb_obl_obj(x)))\n",
    "df_dehumanization['nmod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_nmod(x)))\n",
    "df_dehumanization['amod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_amod(x)))\n",
    "df_dehumanization['comp'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_comp(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "df_augmentation['label']=0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def train_augmented_svm(data, augmentation_data, text_columns, label_column, random_state=42):\n",
    "    total_data_size = len(data) + len(augmentation_data)\n",
    "    desired_test_size = int(total_data_size * 0.2)\n",
    "    adjusted_test_size_ratio = desired_test_size / len(data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=adjusted_test_size_ratio, random_state=random_state)\n",
    "\n",
    "    X_train_augmented = pd.concat([X_train, augmentation_data[text_columns]], axis=0, join='outer', ignore_index=True)\n",
    "    y_train_augmented = pd.concat([y_train, augmentation_data[label_column]], axis=0, join='outer', ignore_index=True)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', MultiColumnTfidfVectorizer(columns=text_columns)),\n",
    "        ('classifier', SVC(kernel='linear', random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 100],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "    grid_search.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "    svm_best = grid_search.best_estimator_\n",
    "    svm_best.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "\n",
    "    y_pred = svm_best.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test.values.ravel(), y_pred)\n",
    "    precision = precision_score(y_test.values.ravel(), y_pred)\n",
    "    recall = recall_score(y_test.values.ravel(), y_pred)\n",
    "    f1 = f1_score(y_test.values.ravel(), y_pred)\n",
    "\n",
    "    return svm_best, [accuracy, precision, recall, f1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55min 52s, sys: 17.6 s, total: 56min 10s\n",
      "Wall time: 1h 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_trained_pipelines_svm = []\n",
    "all_results_svm = []\n",
    "for col_set in all_col_variations:\n",
    "    current_pipe, results = train_augmented_svm(df_dehumanization, df_augmentation, col_set, label_column)\n",
    "    all_trained_pipelines_svm.append(current_pipe)\n",
    "    all_results_svm.append(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "idx_largest = max(range(len(all_results_svm)), key=lambda i: all_results_svm[i][-1])\n",
    "\n",
    "next_largest = max([all_results_svm[i][-1] for i in range(len(all_results_svm)) if all_results_svm[i][-1] < all_results_svm[idx_largest][-1]])\n",
    "idx_next_largest = max([i for i in range(len(all_results_svm)) if all_results_svm[i][-1] == next_largest])\n",
    "\n",
    "print(idx_next_largest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.8587830080367393, 0.941358024691358, 0.7457212713936431, 0.8321964529331514]"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_svm[idx_largest]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('vectorizer',\n   MultiColumnTfidfVectorizer(columns=['text_lemmatized', 'text_clean'])),\n  ('classifier', SVC(C=100, kernel='linear', random_state=42))],\n 'verbose': False,\n 'vectorizer': MultiColumnTfidfVectorizer(columns=['text_lemmatized', 'text_clean']),\n 'classifier': SVC(C=100, kernel='linear', random_state=42),\n 'vectorizer__columns': ['text_lemmatized', 'text_clean'],\n 'classifier__C': 100,\n 'classifier__break_ties': False,\n 'classifier__cache_size': 200,\n 'classifier__class_weight': None,\n 'classifier__coef0': 0.0,\n 'classifier__decision_function_shape': 'ovr',\n 'classifier__degree': 3,\n 'classifier__gamma': 'scale',\n 'classifier__kernel': 'linear',\n 'classifier__max_iter': -1,\n 'classifier__probability': False,\n 'classifier__random_state': 42,\n 'classifier__shrinking': True,\n 'classifier__tol': 0.001,\n 'classifier__verbose': False}"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trained_pipelines_svm[idx_largest].get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Signals from lexicons"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# df_RuSentiLex = pd.read_csv('/Users/katerynaburovova/PycharmProjects/dehumanization/lexicons/RuSentiLex.csv', sep=';')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "              word   pos        lemma sentiment   source  ambiguity rest\n0            аборт  Noun        аборт  negative     fact        NaN  NaN\n1       абортивный   Adj   абортивный  negative     fact        NaN  NaN\n2      абракадабра  Noun  абракадабра  negative  opinion        NaN  NaN\n3           абсурд  Noun       абсурд  negative  opinion        NaN  NaN\n4      абсурдность  Noun  абсурдность  negative  opinion        NaN  NaN\n...            ...   ...          ...       ...      ...        ...  ...\n16049         ярый   Adj         ярый  positive  opinion  ПРЕДАННЫЙ  NaN\n16050      ясность  Noun      ясность  positive  opinion        NaN  NaN\n16051        ясный   Adj        ясный  positive  opinion        NaN  NaN\n16052         ящур  Noun         ящур  negative     fact        NaN  NaN\n16053      ящурный   Adj      ящурный  negative     fact        NaN  NaN\n\n[16054 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>pos</th>\n      <th>lemma</th>\n      <th>sentiment</th>\n      <th>source</th>\n      <th>ambiguity</th>\n      <th>rest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>аборт</td>\n      <td>Noun</td>\n      <td>аборт</td>\n      <td>negative</td>\n      <td>fact</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>абортивный</td>\n      <td>Adj</td>\n      <td>абортивный</td>\n      <td>negative</td>\n      <td>fact</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>абракадабра</td>\n      <td>Noun</td>\n      <td>абракадабра</td>\n      <td>negative</td>\n      <td>opinion</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>абсурд</td>\n      <td>Noun</td>\n      <td>абсурд</td>\n      <td>negative</td>\n      <td>opinion</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>абсурдность</td>\n      <td>Noun</td>\n      <td>абсурдность</td>\n      <td>negative</td>\n      <td>opinion</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16049</th>\n      <td>ярый</td>\n      <td>Adj</td>\n      <td>ярый</td>\n      <td>positive</td>\n      <td>opinion</td>\n      <td>ПРЕДАННЫЙ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16050</th>\n      <td>ясность</td>\n      <td>Noun</td>\n      <td>ясность</td>\n      <td>positive</td>\n      <td>opinion</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16051</th>\n      <td>ясный</td>\n      <td>Adj</td>\n      <td>ясный</td>\n      <td>positive</td>\n      <td>opinion</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16052</th>\n      <td>ящур</td>\n      <td>Noun</td>\n      <td>ящур</td>\n      <td>negative</td>\n      <td>fact</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16053</th>\n      <td>ящурный</td>\n      <td>Adj</td>\n      <td>ящурный</td>\n      <td>negative</td>\n      <td>fact</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>16054 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_RuSentiLex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separate metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# define function that separates the testing data\n",
    "# y_target_labels_test, y_general_test\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from datetime import timedelta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "model_path = \"/Users/katerynaburovova/PycharmProjects/dehumanization/w2v_models/final_models/full_dataset_word2vec_correct.model\"\n",
    "gensim_model = Word2Vec.load(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def load_dictionary_from_file(file_name):\n",
    "    with np.load(file_name) as data:\n",
    "        return {key: data[key] for key in data}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "centroids_dict = load_dictionary_from_file('centroids_dict.npz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# def find_closest_words_for_single_model(model_path: str, given_vector, topn: int = 10):\n",
    "#     try:\n",
    "#         model = Word2Vec.load(model_path)\n",
    "#         closest_words = model.wv.similar_by_vector(given_vector, topn=topn)\n",
    "#         return closest_words\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing model {model_path}: {e}\")\n",
    "#         return []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 s, sys: 477 ms, total: 1.56 s\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "closest_words = []\n",
    "\n",
    "for vector in centroids_dict.values():\n",
    "    closest_words_vector = gensim_model.wv.similar_by_vector(vector, topn=20)\n",
    "    closest_words.append(closest_words_vector)\n",
    "\n",
    "closest_words = [num for sublist in closest_words for num in sublist]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "240"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(closest_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "closest_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "dehumanizing_target_labels = ['укрорейха', 'нацистка', 'укропитеки', 'свинособаки', 'бандерлоги', 'свинорылых', 'укронацистов', 'укропитеков', 'укронацистская', 'укровермахта']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "dehumanizing_target_sequences = ['рейх', 'нацист', 'питек', 'бандерло', 'свино', 'вермахт', 'питек']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# import json\n",
    "#\n",
    "# with open('dehumanizing_target_sequences.json', 'w') as f:\n",
    "#     json.dump(dehumanizing_target_sequences, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with open('dehumanizing_target_sequences.json', 'r') as f:\n",
    "#     new_list = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def contains_target_sequence(text, target_sequences):\n",
    "    # text = text.decode(\"utf-8\")\n",
    "    for seq in target_sequences:\n",
    "        if re.search(seq, text, re.IGNORECASE):\n",
    "            return True\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_target_sequence('бандерлог укропитека', dehumanizing_target_sequences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def split_test_data_by_target_sequences(X, y, text_columns, target_sequences):\n",
    "    contains_seq = X.apply(lambda row: any(contains_target_sequence(row[col], target_sequences) for col in text_columns), axis=1)\n",
    "    X_pos, y_pos = X[contains_seq], y[contains_seq]\n",
    "    X_neg, y_neg = X[~contains_seq], y[~contains_seq]\n",
    "\n",
    "    return X_pos, y_pos, X_neg, y_neg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model selection based on the combined F1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def train_augmented_svm(data, augmentation_data, text_columns, label_column, dehumanizing_target_sequences, random_state=42):\n",
    "    total_data_size = len(data) + len(augmentation_data)\n",
    "    desired_test_size = int(total_data_size * 0.2)\n",
    "    adjusted_test_size_ratio = desired_test_size / len(data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=adjusted_test_size_ratio, random_state=random_state)\n",
    "\n",
    "    X_train_augmented = pd.concat([X_train, augmentation_data[text_columns]], axis=0, join='outer', ignore_index=True)\n",
    "    y_train_augmented = pd.concat([y_train, augmentation_data[label_column]], axis=0, join='outer', ignore_index=True)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', MultiColumnTfidfVectorizer(columns=text_columns)),\n",
    "        ('classifier', SVC(kernel='linear', random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 100],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "    grid_search.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "    svm_best = grid_search.best_estimator_\n",
    "    svm_best.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "\n",
    "    X_test_pos, y_test_pos, X_test_neg, y_test_neg = split_test_data_by_target_sequences(X_test, y_test, text_columns, dehumanizing_target_sequences)\n",
    "\n",
    "    y_pred_pos = svm_best.predict(X_test_pos)\n",
    "    accuracy_pos = accuracy_score(y_test_pos, y_pred_pos)\n",
    "    precision_pos = precision_score(y_test_pos, y_pred_pos)\n",
    "    recall_pos = recall_score(y_test_pos, y_pred_pos)\n",
    "    f1_pos = f1_score(y_test_pos, y_pred_pos)\n",
    "\n",
    "    y_pred_neg = svm_best.predict(X_test_neg)\n",
    "    accuracy_neg = accuracy_score(y_test_neg, y_pred_neg)\n",
    "    precision_neg = precision_score(y_test_neg, y_pred_neg)\n",
    "    recall_neg = recall_score(y_test_neg, y_pred_neg)\n",
    "    f1_neg = f1_score(y_test_neg, y_pred_neg)\n",
    "\n",
    "    return svm_best, [(accuracy_pos, precision_pos, recall_pos, f1_pos), (accuracy_neg, precision_neg, recall_neg, f1_neg)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56min 21s, sys: 23.7 s, total: 56min 45s\n",
      "Wall time: 1h 45min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_trained_pipelines_svm = []\n",
    "all_results_svm = []\n",
    "for col_set in all_col_variations:\n",
    "    current_pipe, (results_pos, results_neg) = train_augmented_svm(df_dehumanization, df_augmentation, col_set, label_column, dehumanizing_target_sequences)\n",
    "    all_trained_pipelines_svm.append(current_pipe)\n",
    "    all_results_svm.append({\"results_pos\": results_pos, \"results_neg\": results_neg})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "idx_largest_pos = max(range(len(all_results_svm)), key=lambda i: all_results_svm[i][\"results_pos\"][-1])\n",
    "idx_largest_neg = max(range(len(all_results_svm)), key=lambda i: all_results_svm[i][\"results_neg\"][-1])\n",
    "\n",
    "next_largest_pos = max([all_results_svm[i][\"results_pos\"][-1] for i in range(len(all_results_svm)) if all_results_svm[i][\"results_pos\"][-1] < all_results_svm[idx_largest_pos][\"results_pos\"][-1]])\n",
    "idx_next_largest_pos = max([i for i in range(len(all_results_svm)) if all_results_svm[i][\"results_pos\"][-1] == next_largest_pos])\n",
    "\n",
    "next_largest_neg = max([all_results_svm[i][\"results_neg\"][-1] for i in range(len(all_results_svm)) if all_results_svm[i][\"results_neg\"][-1] < all_results_svm[idx_largest_neg][\"results_neg\"][-1]])\n",
    "idx_next_largest_neg = max([i for i in range(len(all_results_svm)) if all_results_svm[i][\"results_neg\"][-1] == next_largest_neg])\n",
    "\n",
    "print(idx_next_largest_pos)\n",
    "print(idx_next_largest_neg)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "{'results_pos': (0.8928571428571429,\n  0.9864864864864865,\n  0.9012345679012346,\n  0.9419354838709678),\n 'results_neg': (0.6416772554002541,\n  0.6742424242424242,\n  0.27134146341463417,\n  0.3869565217391305)}"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_svm[idx_largest_pos]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "{'results_pos': (0.8745980707395499,\n  0.9807692307692307,\n  0.8823529411764706,\n  0.9289617486338797),\n 'results_neg': (0.85, 0.78125, 0.4166666666666667, 0.5434782608695653)}"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_svm[idx_largest_neg]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Non augmented"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "def train_svm(data, text_columns, label_column, dehumanizing_target_sequences, random_state=42):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=0.2, random_state=random_state)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', MultiColumnTfidfVectorizer(columns=text_columns)),\n",
    "        ('classifier', SVC(kernel='linear', random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 100],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    svm_best = grid_search.best_estimator_\n",
    "    svm_best.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    X_test_pos, y_test_pos, X_test_neg, y_test_neg = split_test_data_by_target_sequences(X_test, y_test, text_columns, dehumanizing_target_sequences)\n",
    "\n",
    "    y_pred_pos = svm_best.predict(X_test_pos)\n",
    "    accuracy_pos = accuracy_score(y_test_pos, y_pred_pos)\n",
    "    precision_pos = precision_score(y_test_pos, y_pred_pos)\n",
    "    recall_pos = recall_score(y_test_pos, y_pred_pos)\n",
    "    f1_pos = f1_score(y_test_pos, y_pred_pos)\n",
    "\n",
    "    y_pred_neg = svm_best.predict(X_test_neg)\n",
    "    accuracy_neg = accuracy_score(y_test_neg, y_pred_neg)\n",
    "    precision_neg = precision_score(y_test_neg, y_pred_neg)\n",
    "    recall_neg = recall_score(y_test_neg, y_pred_neg)\n",
    "    f1_neg = f1_score(y_test_neg, y_pred_neg)\n",
    "\n",
    "    return svm_best, [(accuracy_pos, precision_pos, recall_pos, f1_pos), (accuracy_neg, precision_neg, recall_neg, f1_neg)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "all_trained_pipelines_svm_reg = []\n",
    "all_results_svm_reg = []\n",
    "for col_set in all_col_variations:\n",
    "    current_pipe_reg, (results_pos, results_neg) = train_svm(df_dehumanization, col_set, label_column, dehumanizing_target_sequences)\n",
    "    all_trained_pipelines_svm_reg.append(current_pipe_reg)\n",
    "    all_results_svm_reg.append({\"results_pos\": results_pos, \"results_neg\": results_neg})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results_svm_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [67], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m idx_largest_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mall_results_svm_reg\u001B[49m)), key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m i: all_results_svm_reg[i][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults_pos\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m      2\u001B[0m idx_largest_neg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(all_results_svm_reg)), key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m i: all_results_svm_reg[i][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults_neg\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m      4\u001B[0m next_largest_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m([all_results_svm_reg[i][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults_pos\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(all_results_svm_reg)) \u001B[38;5;28;01mif\u001B[39;00m all_results_svm_reg[i][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults_pos\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m<\u001B[39m all_results_svm_reg[idx_largest_pos][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults_pos\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'all_results_svm_reg' is not defined"
     ]
    }
   ],
   "source": [
    "idx_largest_pos = max(range(len(all_results_svm_reg)), key=lambda i: all_results_svm_reg[i][\"results_pos\"][-1])\n",
    "idx_largest_neg = max(range(len(all_results_svm_reg)), key=lambda i: all_results_svm_reg[i][\"results_neg\"][-1])\n",
    "\n",
    "next_largest_pos = max([all_results_svm_reg[i][\"results_pos\"][-1] for i in range(len(all_results_svm_reg)) if all_results_svm_reg[i][\"results_pos\"][-1] < all_results_svm_reg[idx_largest_pos][\"results_pos\"][-1]])\n",
    "idx_next_largest_pos = max([i for i in range(len(all_results_svm_reg)) if all_results_svm_reg[i][\"results_pos\"][-1] == next_largest_pos])\n",
    "\n",
    "next_largest_neg = max([all_results_svm_reg[i][\"results_neg\"][-1] for i in range(len(all_results_svm_reg)) if all_results_svm_reg[i][\"results_neg\"][-1] < all_results_svm_reg[idx_largest_neg][\"results_neg\"][-1]])\n",
    "idx_next_largest_neg = max([i for i in range(len(all_results_svm_reg)) if all_results_svm_reg[i][\"results_neg\"][-1] == next_largest_neg])\n",
    "\n",
    "print(idx_next_largest_pos)\n",
    "print(idx_next_largest_neg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "data": {
      "text/plain": "{'results_pos': (0.8928571428571429,\n  0.9864864864864865,\n  0.9012345679012346,\n  0.9419354838709678),\n 'results_neg': (0.6416772554002541,\n  0.6742424242424242,\n  0.27134146341463417,\n  0.3869565217391305)}"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_svm[idx_largest_pos]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "{'results_pos': (0.8074534161490683,\n  0.9615384615384616,\n  0.8278145695364238,\n  0.8896797153024911),\n 'results_neg': (0.7281690140845071,\n  0.7338129496402878,\n  0.3953488372093023,\n  0.5138539042821159)}"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_svm[idx_largest_neg]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model selection based on the particular F1 with custom scoring func"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.metrics import make_scorer\n",
    "#\n",
    "# def f1_score_positive(y_true, y_pred, text_columns, dehumanizing_target_sequences):\n",
    "#     y_true = pd.Series(y_true)\n",
    "#     X_test = pd.DataFrame(y_pred, columns=text_columns)\n",
    "#     _, y_true_pos, _, _ = split_test_data_by_target_sequences(X_test, y_true, text_columns, dehumanizing_target_sequences)\n",
    "#     _, y_pred_pos, _, _ = split_test_data_by_target_sequences(X_test, pd.Series(y_pred), text_columns, dehumanizing_target_sequences)\n",
    "#     return f1_score(y_true_pos, y_pred_pos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def train_augmented_svm_pos(data, augmentation_data, text_columns, label_column, dehumanizing_target_sequences, random_state=42):\n",
    "#     total_data_size = len(data) + len(augmentation_data)\n",
    "#     desired_test_size = int(total_data_size * 0.2)\n",
    "#     adjusted_test_size_ratio = desired_test_size / len(data)\n",
    "#\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=adjusted_test_size_ratio, random_state=random_state)\n",
    "#\n",
    "#     X_train_augmented = pd.concat([X_train, augmentation_data[text_columns]], axis=0, join='outer', ignore_index=True)\n",
    "#     y_train_augmented = pd.concat([y_train, augmentation_data[label_column]], axis=0, join='outer', ignore_index=True)\n",
    "#\n",
    "#     pipeline = Pipeline([\n",
    "#         ('vectorizer', MultiColumnTfidfVectorizer(columns=text_columns)),\n",
    "#         ('classifier', SVC(kernel='linear', random_state=random_state))\n",
    "#     ])\n",
    "#\n",
    "#     param_grid = {\n",
    "#         'classifier__C': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 100],\n",
    "#     }\n",
    "#\n",
    "#     grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "#     grid_search.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "#     svm_best = grid_search.best_estimator_\n",
    "#     svm_best.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "#\n",
    "#     X_test_pos, y_test_pos, X_test_neg, y_test_neg = split_test_data_by_target_sequences(X_test, y_test, text_columns, dehumanizing_target_sequences)\n",
    "#\n",
    "#     y_pred_pos = svm_best.predict(X_test_pos)\n",
    "#     accuracy_pos = accuracy_score(y_test_pos, y_pred_pos)\n",
    "#     precision_pos = precision_score(y_test_pos, y_pred_pos)\n",
    "#     recall_pos = recall_score(y_test_pos, y_pred_pos)\n",
    "#     f1_pos = f1_score(y_test_pos, y_pred_pos)\n",
    "#\n",
    "#     y_pred_neg = svm_best.predict(X_test_neg)\n",
    "#     accuracy_neg = accuracy_score(y_test_neg, y_pred_neg)\n",
    "#     precision_neg = precision_score(y_test_neg, y_pred_neg)\n",
    "#     recall_neg = recall_score(y_test_neg, y_pred_neg)\n",
    "#     f1_neg = f1_score(y_test_neg, y_pred_neg)\n",
    "#\n",
    "#     return svm_best, [(accuracy_pos, precision_pos, recall_pos, f1_pos), (accuracy_neg, precision_neg, recall_neg, f1_neg)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%time\n",
    "# all_trained_pipelines_svm_pos = []\n",
    "# all_results_svm_pos = []\n",
    "# for col_set in all_col_variations:\n",
    "#     current_pipe_pos, (results_pos, results_neg) = train_augmented_svm_pos(df_dehumanization, df_augmentation, col_set, label_column, dehumanizing_target_sequences)\n",
    "#     all_trained_pipelines_svm_pos.append(current_pipe_pos)\n",
    "#     all_results_svm_pos.append({\"results_pos\": results_pos, \"results_neg\": results_neg})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%time\n",
    "# idx_largest_pos = max(range(len(all_results_svm_pos)), key=lambda i: all_results_svm_pos[i][\"results_pos\"][-1])\n",
    "#\n",
    "# next_largest_pos = max([all_results_svm_pos[i][\"results_pos\"][-1] for i in range(len(all_results_svm_pos)) if all_results_svm_pos[i][\"results_pos\"][-1] < all_results_svm_pos[idx_largest_pos][\"results_pos\"][-1]])\n",
    "# idx_next_largest_pos = max([i for i in range(len(all_results_svm_pos)) if all_results_svm_pos[i][\"results_pos\"][-1] == next_largest_pos])\n",
    "#\n",
    "# print(idx_next_largest_pos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all_results_svm_pos[idx_largest_pos]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.metrics import make_scorer\n",
    "#\n",
    "# def custom_scorer(estimator, X, y_true, **kwargs):\n",
    "#     text_columns = kwargs['text_columns']\n",
    "#     dehumanizing_target_sequences = kwargs['dehumanizing_target_sequences']\n",
    "#     y_pred = estimator.predict(X)\n",
    "#     X = X.copy()\n",
    "#     X['true_labels'] = y_true\n",
    "#     X['predictions'] = y_pred\n",
    "#     X_neg = X.apply(lambda row: not any(contains_target_sequence(row[col], dehumanizing_target_sequences) for col in text_columns), axis=1)\n",
    "#     y_true_neg = X_neg['true_labels']\n",
    "#     y_pred_neg = X_neg['predictions']\n",
    "#     return f1_score(y_true_neg, y_pred_neg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def train_augmented_svm_neg(data, augmentation_data, text_columns, label_column, dehumanizing_target_sequences, random_state=42):\n",
    "#     total_data_size = len(data) + len(augmentation_data)\n",
    "#     desired_test_size = int(total_data_size * 0.2)\n",
    "#     adjusted_test_size_ratio = desired_test_size / len(data)\n",
    "#\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=adjusted_test_size_ratio, random_state=random_state)\n",
    "#\n",
    "#     X_train_augmented = pd.concat([X_train, augmentation_data[text_columns]], axis=0, join='outer', ignore_index=True)\n",
    "#     y_train_augmented = pd.concat([y_train, augmentation_data[label_column]], axis=0, join='outer', ignore_index=True)\n",
    "#\n",
    "#     pipeline = Pipeline([\n",
    "#         ('vectorizer', MultiColumnTfidfVectorizer(columns=text_columns)),\n",
    "#         ('classifier', SVC(kernel='linear', random_state=random_state))\n",
    "#     ])\n",
    "#\n",
    "#     param_grid = {\n",
    "#         'classifier__C': [0.001, 0.01, 0.1, 0.5, 1, 2, 10, 100],\n",
    "#     }\n",
    "#\n",
    "#     scoring_func = make_scorer(custom_scorer, greater_is_better=True, needs_proba=False, needs_threshold=False,\n",
    "#                                text_columns=text_columns, dehumanizing_target_sequences=dehumanizing_target_sequences)\n",
    "#\n",
    "#     grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scoring_func)\n",
    "#     grid_search.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "#     svm_best = grid_search.best_estimator_\n",
    "#     svm_best.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "#\n",
    "#     X_test_pos, y_test_pos, X_test_neg, y_test_neg = split_test_data_by_target_sequences(X_test, y_test, text_columns, dehumanizing_target_sequences)\n",
    "#\n",
    "#     y_pred_pos = svm_best.predict(X_test_pos)\n",
    "#     accuracy_pos = accuracy_score(y_test_pos, y_pred_pos)\n",
    "#     precision_pos = precision_score(y_test_pos, y_pred_pos)\n",
    "#     recall_pos = recall_score(y_test_pos, y_pred_pos)\n",
    "#     f1_pos = f1_score(y_test_pos, y_pred_pos)\n",
    "#\n",
    "#     y_pred_neg = svm_best.predict(X_test_neg)\n",
    "#     accuracy_neg = accuracy_score(y_test_neg, y_pred_neg)\n",
    "#     precision_neg = precision_score(y_test_neg, y_pred_neg)\n",
    "#     recall_neg = recall_score(y_test_neg, y_pred_neg)\n",
    "#     f1_neg = f1_score(y_test_neg, y_pred_neg)\n",
    "#\n",
    "#     return svm_best, [(accuracy_pos, precision_pos, recall_pos, f1_pos), (accuracy_neg, precision_neg, recall_neg, f1_neg)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%time\n",
    "# all_trained_pipelines_svm_neg = []\n",
    "# all_results_svm_neg = []\n",
    "# for col_set in all_col_variations:\n",
    "#     current_pipe_neg, (results_pos, results_neg) = train_augmented_svm_neg(df_dehumanization, df_augmentation, col_set, label_column, dehumanizing_target_sequences)\n",
    "#     all_trained_pipelines_svm_neg.append(current_pipe_neg)\n",
    "#     all_results_svm_neg.append({\"results_pos\": results_pos, \"results_neg\": results_neg})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments with other feature extraction methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using word2vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "text_columns = ['nmod', 'verb_obl_obj', 'core_noun_verb', 'amod', 'text_lemmatized', 'text_clean']\n",
    "\n",
    "all_col_variations = list(chain.from_iterable(combinations(text_columns, r) for r in range(1, len(text_columns)+1)))\n",
    "all_col_variations = [list(p) for p in all_col_variations]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, word2vec_model, aggregation_func=np.mean):\n",
    "        self.word2vec_model = word2vec_model\n",
    "        self.aggregation_func = aggregation_func\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        def document_vector(document):\n",
    "            word_vectors = [self.word2vec_model.wv[word] for word in document.split() if word in self.word2vec_model.wv]\n",
    "            return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(self.word2vec_model.vector_size)\n",
    "\n",
    "        X_concatenated = X.apply(lambda x: ' '.join(x.dropna()), axis=1)\n",
    "        return np.array([document_vector(doc) for doc in X_concatenated])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collocation_extraction import collect_verb_obl_obj, collect_core, collect_nmod, collect_amod, collect_comp, collect_appos, show_dependency, lst_to_str\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "label_column = ['label']\n",
    "dehumanizing_target_sequences = ['рейх', 'нацист', 'питек', 'бандерло', 'свино', 'вермахт', 'питек']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/3151644473.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['core_noun_verb'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_core(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/3151644473.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['verb_obl_obj'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_verb_obl_obj(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/3151644473.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['nmod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_nmod(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/3151644473.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['amod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_amod(x)))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_1265/3151644473.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dehumanization['comp'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_comp(x)))\n"
     ]
    }
   ],
   "source": [
    "df_dehumanization['core_noun_verb'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_core(x)))\n",
    "df_dehumanization['verb_obl_obj'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_verb_obl_obj(x)))\n",
    "df_dehumanization['nmod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_nmod(x)))\n",
    "df_dehumanization['amod'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_amod(x)))\n",
    "df_dehumanization['comp'] = df_dehumanization['text'].apply(lambda x: lst_to_str(collect_comp(x)))\n",
    "# df_dehumanization.drop(columns='index', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "word2vec_model_path = \"/Users/katerynaburovova/PycharmProjects/dehumanization/w2v_models/final_models/full_dataset_word2vec_correct.model\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(word2vec_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def train_augmented_svm(data, augmentation_data, w2v_model, text_columns, label_column, dehumanizing_target_sequences,random_state=42):\n",
    "    total_data_size = len(data) + len(augmentation_data)\n",
    "    desired_test_size = int(total_data_size * 0.2)\n",
    "    adjusted_test_size_ratio = desired_test_size / len(data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[text_columns], data[label_column], test_size=adjusted_test_size_ratio, random_state=random_state)\n",
    "\n",
    "    X_train_augmented = pd.concat([X_train, augmentation_data[text_columns]], axis=0, join='outer', ignore_index=True)\n",
    "    y_train_augmented = pd.concat([y_train, augmentation_data[label_column]], axis=0, join='outer', ignore_index=True)\n",
    "\n",
    "    # w2v_model = Word2Vec.load(word2vec_model_path)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', Word2VecVectorizer(w2v_model)),\n",
    "        ('classifier', SVC(kernel='linear', random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.01, 0.1, 1, 2, 10],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "    grid_search.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "    svm_best = grid_search.best_estimator_\n",
    "    svm_best.fit(X_train_augmented, y_train_augmented.values.ravel())\n",
    "\n",
    "    X_test_pos, y_test_pos, X_test_neg, y_test_neg = split_test_data_by_target_sequences(X_test, y_test, text_columns, dehumanizing_target_sequences)\n",
    "\n",
    "    y_pred_pos = svm_best.predict(X_test_pos)\n",
    "    accuracy_pos = accuracy_score(y_test_pos, y_pred_pos)\n",
    "    precision_pos = precision_score(y_test_pos, y_pred_pos)\n",
    "    recall_pos = recall_score(y_test_pos, y_pred_pos)\n",
    "    f1_pos = f1_score(y_test_pos, y_pred_pos)\n",
    "\n",
    "    y_pred_neg = svm_best.predict(X_test_neg)\n",
    "    accuracy_neg = accuracy_score(y_test_neg, y_pred_neg)\n",
    "    precision_neg = precision_score(y_test_neg, y_pred_neg)\n",
    "    recall_neg = recall_score(y_test_neg, y_pred_neg)\n",
    "    f1_neg = f1_score(y_test_neg, y_pred_neg)\n",
    "\n",
    "    return svm_best, [(accuracy_pos, precision_pos, recall_pos, f1_pos), (accuracy_neg, precision_neg, recall_neg, f1_neg)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "all_trained_pipelines_svm_w2v = []\n",
    "all_results_svm_w2v = []\n",
    "for col_set in all_col_variations:\n",
    "    current_pipe, (results_pos, results_neg) = train_augmented_svm(df_dehumanization, df_augmentation, w2v_model, col_set, label_column,dehumanizing_target_sequences)\n",
    "    all_trained_pipelines_svm_w2v.append(current_pipe)\n",
    "    all_results_svm_w2v.append({\"results_pos\": results_pos, \"results_neg\": results_neg})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx_largest_pos = max(range(len(all_results_svm_w2v)), key=lambda i: all_results_svm_w2v[i][\"results_pos\"][-1])\n",
    "idx_largest_neg = max(range(len(all_results_svm_w2v)), key=lambda i: all_results_svm_w2v[i][\"results_neg\"][-1])\n",
    "\n",
    "next_largest_pos = max([all_results_svm_w2v[i][\"results_pos\"][-1] for i in range(len(all_results_svm_w2v)) if all_results_svm_w2v[i][\"results_pos\"][-1] < all_results_svm_w2v[idx_largest_pos][\"results_pos\"][-1]])\n",
    "idx_next_largest_pos = max([i for i in range(len(all_results_svm_w2v)) if all_results_svm_w2v[i][\"results_pos\"][-1] == next_largest_pos])\n",
    "\n",
    "next_largest_neg = max([all_results_svm_w2v[i][\"results_neg\"][-1] for i in range(len(all_results_svm_w2v)) if all_results_svm_w2v[i][\"results_neg\"][-1] < all_results_svm_w2v[idx_largest_neg][\"results_neg\"][-1]])\n",
    "idx_next_largest_neg = max([i for i in range(len(all_results_svm_w2v)) if all_results_svm_w2v[i][\"results_neg\"][-1] == next_largest_neg])\n",
    "\n",
    "print(idx_next_largest_pos)\n",
    "print(idx_next_largest_neg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}