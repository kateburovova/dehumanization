{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import fasttext\n",
    "import emoji\n",
    "import re\n",
    "import collections\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading merged data from channels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_36611/2069067117.py:1: DtypeWarning: Columns (0,1,3,4,6,9,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_channels = pd.read_csv('/Users/katerynaburovova/PycharmProjects/dehumanization/data/merged_dataset/df_channels.csv', header=None)\n"
     ]
    }
   ],
   "source": [
    "df_channels = pd.read_csv('/Users/katerynaburovova/PycharmProjects/dehumanization/data/merged_dataset/df_channels.csv', header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_channels.columns = df_channels.iloc[0]\n",
    "df_channels = df_channels[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_channels = (df_channels\n",
    "               .drop(columns=['Unnamed: 0'], axis=1)\n",
    "               .reset_index(drop=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "8108693"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_channels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0             id                       date    views  \\\n3748791   8690.0  2022-07-05 17:55:03+00:00      NaN   \n7516803  11236.0  2022-12-05 09:32:40+00:00  14657.0   \n603322   17430.0  2021-04-28 08:32:01+00:00  48847.0   \n3598705   5944.0  2020-11-15 08:27:32+00:00  17572.0   \n6107474  34271.0  2021-08-26 06:10:01+00:00  16071.0   \n\n0                                                reactions  \\\n3748791  MessageReactions(results=[ReactionCount(reacti...   \n7516803  MessageReactions(results=[ReactionCount(reacti...   \n603322                                                 NaN   \n3598705                                                NaN   \n6107474                                                NaN   \n\n0                                     to_id  \\\n3748791  PeerChannel(channel_id=1661202164)   \n7516803  PeerChannel(channel_id=1169436645)   \n603322   PeerChannel(channel_id=1223219553)   \n3598705  PeerChannel(channel_id=1263953596)   \n6107474  PeerChannel(channel_id=1099860397)   \n\n0                                                 fwd_from  \\\n3748791                                                NaN   \n7516803  MessageFwdHeader(date=datetime.datetime(2022, ...   \n603322                                                 NaN   \n3598705  MessageFwdHeader(date=datetime.datetime(2020, ...   \n6107474                                                NaN   \n\n0                                                  message   type duration  \\\n3748791                                                  üôä   text      NaN   \n7516803  #–≤–Ω–µ—ç—Ñ–∏—Ä–∞ –ü–æ –ø–æ–≤–æ–¥—É —Å–Ω–∏–º–∫–æ–≤ –≤—Å–ø–æ–º–Ω–∏–ª–∞—Å—å –¥–∞–≤–Ω—è—è...  photo      NaN   \n603322   –í –¥–µ–ª–µ –±—ã–≤—à–µ–≥–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –¥–µ–≤–µ–ª–æ–ø–µ—Ä—Å–∫–æ–π –≥—Ä—É–ø...  photo      NaN   \n3598705  –†–∞–∑–≤–µ—Ä–Ω—É–≤—à–∞—è—Å—è —Å—Ä–µ–¥–∏ –∫–æ–ª–ª–µ–≥ –∫—Ä–∞–π–Ω–µ –≤–∞–∂–Ω–∞—è –¥–∏—Å–∫...   text      NaN   \n6107474  –í–ª–∞—Å—Ç–∏ –ú–æ—Å–∫–≤—ã –≤—ã–¥–µ–ª–∏–ª–∏ 1 –º–ª—Ä–¥ —Ä—É–±. –¥–ª—è –∫–æ–º–ø–µ–Ω—Å...   text      NaN   \n\n0           channel_name   frw_from_title  frw_from_name  \\\n3748791        moscowach              NaN            NaN   \n7516803  grishkafilippov              NaN            NaN   \n603322          vchkogpu              NaN            NaN   \n3598705        grey_zone  –ê–Ω–¥—Ä–µ–π –ú–µ–¥–≤–µ–¥–µ–≤  MedvedevVesti   \n6107474         rbc_news              NaN            NaN   \n\n0                                               msg_entity  \n3748791                                                NaN  \n7516803                                                NaN  \n603322                                                 NaN  \n3598705  [<telethon.tl.types.MessageEntityUrl object at...  \n6107474                                                NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>views</th>\n      <th>reactions</th>\n      <th>to_id</th>\n      <th>fwd_from</th>\n      <th>message</th>\n      <th>type</th>\n      <th>duration</th>\n      <th>channel_name</th>\n      <th>frw_from_title</th>\n      <th>frw_from_name</th>\n      <th>msg_entity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3748791</th>\n      <td>8690.0</td>\n      <td>2022-07-05 17:55:03+00:00</td>\n      <td>NaN</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1661202164)</td>\n      <td>NaN</td>\n      <td>üôä</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>moscowach</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7516803</th>\n      <td>11236.0</td>\n      <td>2022-12-05 09:32:40+00:00</td>\n      <td>14657.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1169436645)</td>\n      <td>MessageFwdHeader(date=datetime.datetime(2022, ...</td>\n      <td>#–≤–Ω–µ—ç—Ñ–∏—Ä–∞ –ü–æ –ø–æ–≤–æ–¥—É —Å–Ω–∏–º–∫–æ–≤ –≤—Å–ø–æ–º–Ω–∏–ª–∞—Å—å –¥–∞–≤–Ω—è—è...</td>\n      <td>photo</td>\n      <td>NaN</td>\n      <td>grishkafilippov</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>603322</th>\n      <td>17430.0</td>\n      <td>2021-04-28 08:32:01+00:00</td>\n      <td>48847.0</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1223219553)</td>\n      <td>NaN</td>\n      <td>–í –¥–µ–ª–µ –±—ã–≤—à–µ–≥–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –¥–µ–≤–µ–ª–æ–ø–µ—Ä—Å–∫–æ–π –≥—Ä—É–ø...</td>\n      <td>photo</td>\n      <td>NaN</td>\n      <td>vchkogpu</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3598705</th>\n      <td>5944.0</td>\n      <td>2020-11-15 08:27:32+00:00</td>\n      <td>17572.0</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1263953596)</td>\n      <td>MessageFwdHeader(date=datetime.datetime(2020, ...</td>\n      <td>–†–∞–∑–≤–µ—Ä–Ω—É–≤—à–∞—è—Å—è —Å—Ä–µ–¥–∏ –∫–æ–ª–ª–µ–≥ –∫—Ä–∞–π–Ω–µ –≤–∞–∂–Ω–∞—è –¥–∏—Å–∫...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>grey_zone</td>\n      <td>–ê–Ω–¥—Ä–µ–π –ú–µ–¥–≤–µ–¥–µ–≤</td>\n      <td>MedvedevVesti</td>\n      <td>[&lt;telethon.tl.types.MessageEntityUrl object at...</td>\n    </tr>\n    <tr>\n      <th>6107474</th>\n      <td>34271.0</td>\n      <td>2021-08-26 06:10:01+00:00</td>\n      <td>16071.0</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1099860397)</td>\n      <td>NaN</td>\n      <td>–í–ª–∞—Å—Ç–∏ –ú–æ—Å–∫–≤—ã –≤—ã–¥–µ–ª–∏–ª–∏ 1 –º–ª—Ä–¥ —Ä—É–±. –¥–ª—è –∫–æ–º–ø–µ–Ω—Å...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>rbc_news</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We drop na for now (needs some mending)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_channels = df_channels[~df_channels['message'].isna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'We have 0.0000% nans'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"We have {len(df_channels[(df_channels['message']=='nan')&(df_channels['type']=='text')].channel_name.unique())/len(df_channels):.4%} nans\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading list of unique channel name handles referenced by the group"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "1959"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = (df_channels['frw_from_name']\n",
    "              .value_counts()\n",
    "              .reset_index(name=\"count\")[1:]['index']\n",
    "              .to_list())\n",
    "len(names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "1959"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "dict_names = {\"titles\": names}\n",
    "json_object = json.dumps(dict_names, indent=4)\n",
    "with open(\"/Users/katerynaburovova/PycharmProjects/dehumanization/data/names_channels_list.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploring the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class LanguageIdentification:\n",
    "\n",
    "    def __init__(self):\n",
    "        pretrained_lang_model = \"/Users/katerynaburovova/PycharmProjects/comp_soc_sci_projects/fasttext/lid.176.bin\"\n",
    "        self.model = fasttext.load_model(pretrained_lang_model)\n",
    "\n",
    "    def predict_lang(self, text, label_only=True):\n",
    "        predictions = self.model.predict(text, k=1)\n",
    "        if label_only:\n",
    "            return predictions[0][0][-2:]\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_36611/324986298.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_channels['message'] = df_channels['message'].apply(lambda x: str(x).replace('\\n', ' '))\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_36611/324986298.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_channels['lang'] = df_channels['message'].apply(lambda x: lang_identifier.predict_lang(x))\n"
     ]
    }
   ],
   "source": [
    "lang_identifier = LanguageIdentification()\n",
    "df_channels['message'] = df_channels['message'].apply(lambda x: str(x).replace('\\n', ' '))\n",
    "df_channels['lang'] = df_channels['message'].apply(lambda x: lang_identifier.predict_lang(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "ru    6901187\nen      48321\nuk      21941\nbg       5814\nde       5520\n       ...   \nmf          1\nan          1\nnb          1\niq          1\nep          1\nName: lang, Length: 138, dtype: int64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels['lang'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text preprocesing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separating comments from posts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0              id                       date   views  \\\n5847662    2762.0  2022-12-02 18:01:03+00:00  8538.0   \n5847663  980465.0  2022-12-02 18:01:55+00:00     NaN   \n5847664  980466.0  2022-12-02 18:02:11+00:00     NaN   \n5847665  980467.0  2022-12-02 18:02:31+00:00     NaN   \n5847666  980468.0  2022-12-02 18:02:37+00:00     NaN   \n...           ...                        ...     ...   \n5860896      10.0  2019-07-29 16:08:49+00:00  1793.0   \n5860898       8.0  2019-07-29 15:31:10+00:00  1727.0   \n5860899       7.0  2019-07-29 15:15:42+00:00  1924.0   \n5860900       6.0  2019-07-29 14:20:06+00:00  1935.0   \n5860901       2.0  2019-07-29 13:37:58+00:00  1840.0   \n\n0                                                reactions  \\\n5847662  MessageReactions(results=[ReactionCount(reacti...   \n5847663                                                NaN   \n5847664  MessageReactions(results=[ReactionCount(reacti...   \n5847665                                                NaN   \n5847666                                                NaN   \n...                                                    ...   \n5860896  MessageReactions(results=[ReactionCount(reacti...   \n5860898  MessageReactions(results=[ReactionCount(reacti...   \n5860899  MessageReactions(results=[ReactionCount(reacti...   \n5860900  MessageReactions(results=[ReactionCount(reacti...   \n5860901  MessageReactions(results=[ReactionCount(reacti...   \n\n0                                     to_id fwd_from  \\\n5847662  PeerChannel(channel_id=1321128351)      NaN   \n5847663  PeerChannel(channel_id=1679205140)      NaN   \n5847664  PeerChannel(channel_id=1679205140)      NaN   \n5847665  PeerChannel(channel_id=1679205140)      NaN   \n5847666  PeerChannel(channel_id=1679205140)      NaN   \n...                                     ...      ...   \n5860896  PeerChannel(channel_id=1321128351)      NaN   \n5860898  PeerChannel(channel_id=1321128351)      NaN   \n5860899  PeerChannel(channel_id=1321128351)      NaN   \n5860900  PeerChannel(channel_id=1321128351)      NaN   \n5860901  PeerChannel(channel_id=1321128351)      NaN   \n\n0                                                  message   type duration  \\\n5847662  –ü–æ–º–Ω–∏—Ç—Å—è, —á—Ç–æ –∑–∞ –º–µ—Å—è—Ü –¥–æ –Ω–∞—á–∞–ª–∞ –≤–æ–π–Ω—ã —Å –°–æ—Ñ–∏–π...   text      NaN   \n5847663                        –ù–∞ –±—É–º–∞–≥–µ –Ω–∏–∫–∞–∫–æ–π –≤–æ–π–Ω—ã –Ω–µ—Ç   text      NaN   \n5847664  –¢–∞–∫ —ç—Ç–æ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å –í–° –†–§ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –Ω–µ ...   text      NaN   \n5847665  –∏ –ø—Ä–∏ –≤—Å—ë–º –ø—Ä–∏ —ç—Ç–æ–º —É–Ω–∏–∞—Ç—Å–∫–∞—è —Ü–µ—Ä–∫–æ–≤—å –≤—Å—ë –µ—â—ë ...   text      NaN   \n5847666                     –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ —á—Ç–æ —Å–∫–∞–∂–µ—Ç –ø–∞—Ç—Ä–∏–∞—Ä—Ö.   text      NaN   \n...                                                    ...    ...      ...   \n5860896  –ù–∞–≤–µ—Ä–Ω–æ–µ –∫–∞–∂–¥—ã–π –Ω–∞ —Å–≤–æ—ë–º –ø—É—Ç–∏ –≤—Å—Ç—Ä–µ—á–∞–ª —Ç–∞–∫–æ–≥–æ ...  photo      NaN   \n5860898  –ê –µ—â—ë –∏–Ω–æ–≥–¥–∞ –±—É–¥—É—Ç —Å–º–µ—à–Ω—ã–µ –¥–ª—è –º–µ–Ω—è –º–µ–º—ã —Å–æ–±—Å—Ç...   text      NaN   \n5860899  –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –º–∏—Ä –≤–æ–∫—Ä—É–≥ —Å–µ–±—è, –Ω–µ –Ω—É–∂–Ω–æ...   text      NaN   \n5860900  –ò–Ω—Ç–µ—Ä–µ—Å–Ω—É—é –≤–µ—â—å –∑–∞–º–µ—Ç–∏–ª: –∫–∞–∂–¥—ã–π —Ä–∞–∑ –∫–æ–≥–¥–∞ –≤ –ú–°...   text      NaN   \n5860901  –°–ª–æ–≤–∏–ª —Å–µ–±—è –Ω–∞ –º—ã—Å–ª–∏, —á—Ç–æ –ø–µ—Ä–µ—Å—Ç–∞–≤ –ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å...   text      NaN   \n\n0         channel_name frw_from_title frw_from_name msg_entity lang  \n5847662  Topaz_Govorit            NaN           NaN        NaN   ru  \n5847663  Topaz_Govorit            NaN           NaN        NaN   ru  \n5847664  Topaz_Govorit            NaN           NaN        NaN   ru  \n5847665  Topaz_Govorit            NaN           NaN        NaN   ru  \n5847666  Topaz_Govorit            NaN           NaN        NaN   ru  \n...                ...            ...           ...        ...  ...  \n5860896  Topaz_Govorit            NaN           NaN        NaN   ru  \n5860898  Topaz_Govorit            NaN           NaN        NaN   ru  \n5860899  Topaz_Govorit            NaN           NaN        NaN   ru  \n5860900  Topaz_Govorit            NaN           NaN        NaN   ru  \n5860901  Topaz_Govorit            NaN           NaN        NaN   ru  \n\n[12090 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>views</th>\n      <th>reactions</th>\n      <th>to_id</th>\n      <th>fwd_from</th>\n      <th>message</th>\n      <th>type</th>\n      <th>duration</th>\n      <th>channel_name</th>\n      <th>frw_from_title</th>\n      <th>frw_from_name</th>\n      <th>msg_entity</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5847662</th>\n      <td>2762.0</td>\n      <td>2022-12-02 18:01:03+00:00</td>\n      <td>8538.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1321128351)</td>\n      <td>NaN</td>\n      <td>–ü–æ–º–Ω–∏—Ç—Å—è, —á—Ç–æ –∑–∞ –º–µ—Å—è—Ü –¥–æ –Ω–∞—á–∞–ª–∞ –≤–æ–π–Ω—ã —Å –°–æ—Ñ–∏–π...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>5847663</th>\n      <td>980465.0</td>\n      <td>2022-12-02 18:01:55+00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1679205140)</td>\n      <td>NaN</td>\n      <td>–ù–∞ –±—É–º–∞–≥–µ –Ω–∏–∫–∞–∫–æ–π –≤–æ–π–Ω—ã –Ω–µ—Ç</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>5847664</th>\n      <td>980466.0</td>\n      <td>2022-12-02 18:02:11+00:00</td>\n      <td>NaN</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1679205140)</td>\n      <td>NaN</td>\n      <td>–¢–∞–∫ —ç—Ç–æ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å –í–° –†–§ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –Ω–µ ...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>5847665</th>\n      <td>980467.0</td>\n      <td>2022-12-02 18:02:31+00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1679205140)</td>\n      <td>NaN</td>\n      <td>–∏ –ø—Ä–∏ –≤—Å—ë–º –ø—Ä–∏ —ç—Ç–æ–º —É–Ω–∏–∞—Ç—Å–∫–∞—è —Ü–µ—Ä–∫–æ–≤—å –≤—Å—ë –µ—â—ë ...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>5847666</th>\n      <td>980468.0</td>\n      <td>2022-12-02 18:02:37+00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1679205140)</td>\n      <td>NaN</td>\n      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ —á—Ç–æ —Å–∫–∞–∂–µ—Ç –ø–∞—Ç—Ä–∏–∞—Ä—Ö.</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5860896</th>\n      <td>10.0</td>\n      <td>2019-07-29 16:08:49+00:00</td>\n      <td>1793.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1321128351)</td>\n      <td>NaN</td>\n      <td>–ù–∞–≤–µ—Ä–Ω–æ–µ –∫–∞–∂–¥—ã–π –Ω–∞ —Å–≤–æ—ë–º –ø—É—Ç–∏ –≤—Å—Ç—Ä–µ—á–∞–ª —Ç–∞–∫–æ–≥–æ ...</td>\n      <td>photo</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>5860898</th>\n      <td>8.0</td>\n      <td>2019-07-29 15:31:10+00:00</td>\n      <td>1727.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1321128351)</td>\n      <td>NaN</td>\n      <td>–ê –µ—â—ë –∏–Ω–æ–≥–¥–∞ –±—É–¥—É—Ç —Å–º–µ—à–Ω—ã–µ –¥–ª—è –º–µ–Ω—è –º–µ–º—ã —Å–æ–±—Å—Ç...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>5860899</th>\n      <td>7.0</td>\n      <td>2019-07-29 15:15:42+00:00</td>\n      <td>1924.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1321128351)</td>\n      <td>NaN</td>\n      <td>–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –º–∏—Ä –≤–æ–∫—Ä—É–≥ —Å–µ–±—è, –Ω–µ –Ω—É–∂–Ω–æ...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>5860900</th>\n      <td>6.0</td>\n      <td>2019-07-29 14:20:06+00:00</td>\n      <td>1935.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1321128351)</td>\n      <td>NaN</td>\n      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω—É—é –≤–µ—â—å –∑–∞–º–µ—Ç–∏–ª: –∫–∞–∂–¥—ã–π —Ä–∞–∑ –∫–æ–≥–¥–∞ –≤ –ú–°...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>5860901</th>\n      <td>2.0</td>\n      <td>2019-07-29 13:37:58+00:00</td>\n      <td>1840.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1321128351)</td>\n      <td>NaN</td>\n      <td>–°–ª–æ–≤–∏–ª —Å–µ–±—è –Ω–∞ –º—ã—Å–ª–∏, —á—Ç–æ –ø–µ—Ä–µ—Å—Ç–∞–≤ –ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>Topaz_Govorit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>ru</td>\n    </tr>\n  </tbody>\n</table>\n<p>12090 rows √ó 14 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels[df_channels['channel_name']=='Topaz_Govorit']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "id_list = df_channels[['channel_name', 'to_id']].drop_duplicates(keep='first').drop_duplicates(subset=['channel_name'], keep='first').to_id.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_36611/1862213152.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_channels['is_post'] = df_channels.apply(lambda x: True if x.to_id in id_list else False, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_channels['is_post'] = df_channels.apply(lambda x: True if x.to_id in id_list else False, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.4% of messages are posts, the rest are comments\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(df_channels[df_channels[\"is_post\"]==True])/len(df_channels)*100:.1f}% of messages are posts, the rest are comments')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "df_comments = df_channels[df_channels['is_post']==False]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "df_channels = df_channels[df_channels['is_post']==True]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['mardanaka', 'rian_ru', 'tvrain', 'krispotupchik', 'akimapachev',\n       'go338', 'KotNaMirotvorze', 'emphasises', 'russ_orientalist',\n       'pravda_shuravi', 'voenacher', 'n_zackhaim', 'Hinshtein',\n       'kashinguru', 'lentachold', 'wargonzo', 'foxandraven',\n       'madam_secretar', 'russianfuture', 'vchkogpu', 'rusich_army',\n       'botcharov', 'mashmoyka', 'vv_volodin', 'Mikle1On',\n       'kremlinprachka', 'ctrs2018', 'mediazzzona', 'sotaproject',\n       'znachit_net', 'er_molnia', 'razvedkavperedZ', 'rasstrelny',\n       'govoritfursov', 'gramotyyaroslava', 'informnapalm',\n       'podosokorsky', 'mosnow', 'daokedao', 'chtddd', 'nevzorovtv',\n       'SonOfMonarchy', 'lesyaryabtseva', 'fontankaspb', 'tass_agency',\n       'ErnestV_2020', 'sorok40russia', 'odinokayakoko', 'pgubarev',\n       'swodki', 'meduzalive', 'Gori_spb', 'anna_news', 'readovkanews',\n       'umar_kremlev', 'government_rus', 'Alekhin_Telega', 'leylinurimm',\n       'pushilindenis', 'strelets_molodec', 'istrkalkglk', 'bbbreaking',\n       'mariabutina', 'Nackepelo', 'politadequate', 'GrafinyaNegoduet',\n       'Soldieroffortune777', 'politjoystic', 'kremlin_mother_expert',\n       'glavpolit', 'northerntechno', 'operdrain', 'mig41',\n       'kozakrichala', 'NeoficialniyBeZsonoV', 'navalny', 'larkin_doc',\n       'varlamov', 'astrahandm', 'metodi4ka', 'InsightPeople',\n       'dirtytatarstan', 'uranews', 'ostorozhno_novosti',\n       'thegraschenkov', 'tv360', 'rt_russian', 'shot_shot', 'epoddubny',\n       'rogers_kitchen', 'ebobo_rus', 'achexd2', 'Marinaslovo',\n       'notes_veterans', 'ENews112', 'readovkaru', 'ikakprosto',\n       'romasuperromasuper', 'rus_jansen', 'RtrDonetsk',\n       'boilerroomchannel', 'MariaVladimirovnaZakharova', 'moscowmap',\n       'rasstriga', 'thebell_io', 'OstashkoNews', 'new_militarycolumnist',\n       'worldprotest', 'separ_13', 'vysokygovorit', 'vladlentatarsky',\n       'NoodleRemoverPlus', 'kommersant', 'kryuchkovoleg',\n       'rustroyka1945', 'mediatech', 'sommerman', 'zvezdanews',\n       'momdontread', 'surf_noise1', 'ssigny', 'mediakiller',\n       'bolshiepushki', 'imnotbozhena', 'oreshkins', 'Medvedeva_Olesya',\n       'HersonVestnik', 'romagolovanov', 'oversized_shirts',\n       'akashevarova', 'ASGasparyan', 'Doninside', 'sashakon',\n       'stalin_gulag', 'truth_aggregator', 'skabeeva', 'fuckyouthatswhy',\n       'rosich_ru', 'ChDambiev', 'corrkosarev', 'zakharprilepin',\n       'kolezev', 'russianquarantine', 'Abbasdjuma', 'grey_zone',\n       'RVvoenkor', 'criminalru', 'oper_goblin', 'otsuka_bld',\n       'ekvinokurova', 'smolyak', 'moscowach', 'radio_sputnik',\n       'vlast_Zh', 'romanov_92', 'rusbrief', 'temablog',\n       'margaritasimonyan', 'redakciya_channel', 'SIL0VIKI',\n       'anatoly_nesmiyan', 'varlamov_news', 'Gubery', 'vzglyad_ru',\n       'stormdaily', 'mod_russia', 'ia_steklomoy', 'Sladkov_plus',\n       'parfentiev_club', 'MedvedevVesti', 'ntvnews', 'RIAKremlinpool',\n       'imerkouri', 'SolovievLive', 'maester', 'zhogaartem', 'glavmedia',\n       'smotri_media', 'MoscowEcon', 'krasovkin', 'akitilop', 'stanovaya',\n       'DmitriySteshin', 'freeman365', 'lobaev_vlad', 'tolk_tolk',\n       'master_pera', 'superdolgov', 'denazi_UA', 'aleksandr_skif',\n       'kononenkome', 'vityzeva', 'msgazdiev', 'infantmilitario',\n       'vatnoeboloto', 'kstati_p', 'TanyaChuprova', 'truekpru',\n       'dimsmirnov175', 'ksbchk', 'mozhemobyasnit', 'ru2ch_news',\n       'novaya_pishet', 'nemorgenshtern', 'vibornyk', 'razvedosaa',\n       'Ateobreaking', 'vandalslavyansk', 'HouseOfCardsRussia',\n       'dr_alex_sosnowski', 'Postovo', 'makarov_kb', 'vvgladkov',\n       'mnews_ru', 'insect_life', 'russica2', 'rtvimain',\n       'riafan_everywhere', 'polittemnik', 'svarschiki', 'Topaz_Govorit',\n       'veraafanasyeva', 'antiskrepa', 'RKadyrov_95', 'navideovidno',\n       'FridrihShow', 'holmogortalks', 'naralex88', 'mnogonazi',\n       'BattleSailor_13', 'mestamedia', 'donbassr', 'TheBadComedian',\n       'strelkovii', 'mkhusnullin', 'golosmordora', 'rbc_news',\n       'berdovaalena', 'ntnzn', 'olegderipaska', 'regnum_na',\n       'vladivostok1978', 'opersvodki', 'norin_ea', 'bogemasranaya',\n       'glava_lnr_info', 'MID_Russia', 'youlistenedmayak',\n       'medvedev_telegram', 'srochnow', 'obyasnayemrf', 'bbcrussian',\n       'optimistkavshtatskom', 'breakingmash', 'boris_rozhin',\n       'rlz_the_kraken', 'pdmnews', 'milchronicles', 'mariashukshina',\n       'minaevlife', 'tikandelaki', 'Baronova', 'postposttruth',\n       'SergeyKolyasnikov', 'comradepelevin', 'izvestia', 'sskarnaukhov',\n       'radiogovoritmsk', 'voenkorKotenok', 'sputniklive', 'RadioStydoba',\n       'kremlebezBashennik', 'lentadnya', 'evgenyprimakov', 'sashakots',\n       'orda_mordora', 'skvir', 'yurydud', 'thynk', 'kornilov1968',\n       'PlushevChannel', 'octagonmedia', 'Lauradjagadiary',\n       'archivarius_dz', 'maryananaumova', 'warfakes', 'rusvesnasu',\n       'infomoscow24', 'sncmag', 'lu_di_z', 'kshulika', 'maxim2004live',\n       'grishkafilippov', 'karaulny', 'milinfolive', 'bazabazon',\n       'olegtsarov', 'obrazbuduschego2', 'bloodysx'], dtype=object)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels.channel_name.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing breaks and repr symbols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'–ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å  https://www.youtube.com/watch?v=4L7T3u7utSw'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = df_channels[df_channels['is_post']==True].message[0]\n",
    "test_string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "splitters = ['\\n', '\\t', '\\\\n','\\xa0', '\\u200b']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_56821/3913600352.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_channels['message_no_breaks'] = df_channels['message'].str.replace('\\n|\\t|\\\\n', ' ', case=False)\n"
     ]
    }
   ],
   "source": [
    "df_channels['message_no_breaks'] = df_channels['message'].str.replace('\\n|\\t|\\\\n', ' ', case=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Isolating emojis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_emoji_count(text):\n",
    "    return collections.Counter([match[\"emoji\"] for word in text for match in emoji.emoji_list(word)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r' ', string)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 42s, sys: 1.77 s, total: 3min 44s\n",
      "Wall time: 8min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_channels['emojis'] = df_channels['message'].apply(lambda x: get_emoji_count(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.78 s, sys: 189 ms, total: 7.97 s\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_channels['message_no_emoji'] = df_channels['message_no_breaks'].apply(lambda x: remove_emoji(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "'–°–µ–Ω—Å–∞—Ü–∏–æ–Ω–Ω–æ–µ –Ω–∞—É—á–Ω–æ–µ –æ—Ç–∫—Ä—ã—Ç–∏–µ!'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels['message_no_emoji'].sample(10).iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Isolating urls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def find_urls(text):\n",
    "    try:\n",
    "        links =  re.findall(r'(https?://[^\\s]+)', text)\n",
    "        return [urlparse(item).netloc for item in links]\n",
    "    except ValueError:\n",
    "        return []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "df_channels['url_list'] = df_channels['message_no_emoji'].apply(lambda x: find_urls(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_56821/343568952.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_channels['message_no_urls'] = df_channels['message_no_emoji'].str.replace('http\\S+|www.\\S+', '', case=False)\n"
     ]
    }
   ],
   "source": [
    "df_channels['message_no_urls'] = df_channels['message_no_emoji'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[]    1226517\nName: message_no_urls, dtype: int64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bs check\n",
    "(df_channels['message_no_urls']\n",
    " .apply(lambda x: find_urls(x))\n",
    " .value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "'  –í–ª–∞—Å—Ç–∏ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏ –æ–¥–æ–±—Ä–∏–ª–∏ —É–∂–µ—Å—Ç–æ—á–µ–Ω–∏–µ —Å–∞–Ω–∫—Ü–∏–π –ø—Ä–æ—Ç–∏–≤ –†–æ—Å—Å–∏–∏  –í–ª–∞—Å—Ç–∏ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏ –æ–¥–æ–±—Ä–∏–ª–∏ –ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω—É –æ —Å–∞–Ω–∫—Ü–∏—è—Ö –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –†–æ—Å—Å–∏–∏. –¢–µ–ø–µ—Ä—å –≤–ª–∞—Å—Ç–∏ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏ –ø–æ —Å–≤–æ–µ–º—É —É—Å–º–æ—Ç—Ä–µ–Ω–∏—é —Å–º–æ–≥—É—Ç —É–∂–µ—Å—Ç–æ—á–∏—Ç—å —Ä–∞–Ω–µ–µ –Ω–∞–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ä—ã.  –ü–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω—É –¥–æ–ø—É—Å–∫–∞—é—Ç —Å–∞–Ω–∫—Ü–∏–∏ –ø—Ä–æ—Ç–∏–≤ —à–∏—Ä–æ–∫–æ–≥–æ –∫—Ä—É–≥–∞ –ª–∏—Ü –∏ –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ –†–§, –∫–æ—Ç–æ—Ä—ã–µ, –ø–æ –º–Ω–µ–Ω–∏—é –±—Ä–∏—Ç–∞–Ω—Å–∫–∏—Ö –≤–ª–∞—Å—Ç–µ–π, –ø—Ä–∏—á–∞—Å—Ç–Ω—ã –∫ –¥–µ—Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∏ —É –≥—Ä–∞–Ω–∏—Ü—ã –£–∫—Ä–∞–∏–Ω—ã.'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels['message_no_urls'].sample(10).iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract mentions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df_channels['mentions'] = df_channels['message_no_urls'].str.findall(r\"@([a-zA-Z0-9_]{1,50})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0           mentions                                    message_no_urls\n397948            []  –û—Å–Ω–æ–≤–∞—Ç–µ–ª—å Pink Floyd –†–æ–¥–∂–µ—Ä –£–æ—Ç–µ—Ä—Å –∑–∞—è–≤–∏–ª, —á—Ç...\n1185708           []  ¬´–ï—Å–ª–∏ –ù–ê–¢–û –ø—Ä–∏–∑–Ω–∞–µ—Ç, —á—Ç–æ –Ω–∞—à —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π —Å—Ç—Ä...\n1267463   [kstati_p]  –ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∫–∞—Ä—Ç–∏–Ω–∞ - –õ—é–±–æ–≤—å –°–æ–±–æ–ª—å ...\n1456731   [izvestia]   –°–æ–≤–µ—Ç—Å–∫–∏–π —Ö–æ–∫–∫–µ–∏—Å—Ç –∏ —Ç—Ä–µ–Ω–µ—Ä –í—è—á–µ—Å–ª–∞–≤ –°—Ç–∞—Ä—à–∏–Ω–æ...\n644824            []    ¬´–í –ì–µ—Ä–º–∞–Ω–∏–∏, –ë–µ–ª—å–≥–∏–∏, –ß–µ—Ö–∏–∏, –î–∞–Ω–∏–∏ –Ω–µ—Ç —Ç–∞–∫–æ–≥...\n609666            []  ‚Äã‚Äã–ë–æ–ª—å—à–µ –Ω–µ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç  –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω–∞ –ú–∏...\n1001016  [glavpolit]  –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–æ—Å—Å–∏–∏ –ú–∏—Ö–∞–∏–ª –ú–∏—à—É—Å...\n1169556           []   –ù–∞—Ü–∏—Å—Ç—ã –±–µ–≥—É—Ç –∏–∑ –ö—Ä–∞—Å–Ω–æ–≥–æ –õ–∏–º–∞–Ω–∞, —É–∫—Ä–∞–∏–Ω—Å–∫–∏–µ ...\n1078016           []    –í –ò–∑—Ä–∞–∏–ª–µ –æ–±—ä—è—Å–Ω–∏–ª–∏ —Ç–∞–π–Ω—ã–π –≤–∏–∑–∏—Ç –ù–µ—Ç–∞–Ω—å—è—Ö—É –≤...\n715297            []  –ü—Ä–æ—Å—Ç–æ –Ω–∞—Ä–¥–µ–ø –ü–∞—Ä—É–±–∏–π –Ω–∞ –±–ª–æ–∫–ø–æ—Å—Ç—É –ø–æ–¥ –ö–∏–µ–≤–æ–º....",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mentions</th>\n      <th>message_no_urls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>397948</th>\n      <td>[]</td>\n      <td>–û—Å–Ω–æ–≤–∞—Ç–µ–ª—å Pink Floyd –†–æ–¥–∂–µ—Ä –£–æ—Ç–µ—Ä—Å –∑–∞—è–≤–∏–ª, —á—Ç...</td>\n    </tr>\n    <tr>\n      <th>1185708</th>\n      <td>[]</td>\n      <td>¬´–ï—Å–ª–∏ –ù–ê–¢–û –ø—Ä–∏–∑–Ω–∞–µ—Ç, —á—Ç–æ –Ω–∞—à —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π —Å—Ç—Ä...</td>\n    </tr>\n    <tr>\n      <th>1267463</th>\n      <td>[kstati_p]</td>\n      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∫–∞—Ä—Ç–∏–Ω–∞ - –õ—é–±–æ–≤—å –°–æ–±–æ–ª—å ...</td>\n    </tr>\n    <tr>\n      <th>1456731</th>\n      <td>[izvestia]</td>\n      <td>–°–æ–≤–µ—Ç—Å–∫–∏–π —Ö–æ–∫–∫–µ–∏—Å—Ç –∏ —Ç—Ä–µ–Ω–µ—Ä –í—è—á–µ—Å–ª–∞–≤ –°—Ç–∞—Ä—à–∏–Ω–æ...</td>\n    </tr>\n    <tr>\n      <th>644824</th>\n      <td>[]</td>\n      <td>¬´–í –ì–µ—Ä–º–∞–Ω–∏–∏, –ë–µ–ª—å–≥–∏–∏, –ß–µ—Ö–∏–∏, –î–∞–Ω–∏–∏ –Ω–µ—Ç —Ç–∞–∫–æ–≥...</td>\n    </tr>\n    <tr>\n      <th>609666</th>\n      <td>[]</td>\n      <td>‚Äã‚Äã–ë–æ–ª—å—à–µ –Ω–µ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç  –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω–∞ –ú–∏...</td>\n    </tr>\n    <tr>\n      <th>1001016</th>\n      <td>[glavpolit]</td>\n      <td>–ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–æ—Å—Å–∏–∏ –ú–∏—Ö–∞–∏–ª –ú–∏—à—É—Å...</td>\n    </tr>\n    <tr>\n      <th>1169556</th>\n      <td>[]</td>\n      <td>–ù–∞—Ü–∏—Å—Ç—ã –±–µ–≥—É—Ç –∏–∑ –ö—Ä–∞—Å–Ω–æ–≥–æ –õ–∏–º–∞–Ω–∞, —É–∫—Ä–∞–∏–Ω—Å–∫–∏–µ ...</td>\n    </tr>\n    <tr>\n      <th>1078016</th>\n      <td>[]</td>\n      <td>–í –ò–∑—Ä–∞–∏–ª–µ –æ–±—ä—è—Å–Ω–∏–ª–∏ —Ç–∞–π–Ω—ã–π –≤–∏–∑–∏—Ç –ù–µ—Ç–∞–Ω—å—è—Ö—É –≤...</td>\n    </tr>\n    <tr>\n      <th>715297</th>\n      <td>[]</td>\n      <td>–ü—Ä–æ—Å—Ç–æ –Ω–∞—Ä–¥–µ–ø –ü–∞—Ä—É–±–∏–π –Ω–∞ –±–ª–æ–∫–ø–æ—Å—Ç—É –ø–æ–¥ –ö–∏–µ–≤–æ–º....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels[['mentions','message_no_urls']].sample(10)\n",
    "# df_channels[['mentions','message_no_urls']].message_no_urls.iloc[1265478]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# text_tst = df_channels[['mentions','message_no_urls']].message_no_urls.iloc[1265478]\n",
    "# m_list = df_channels[['mentions','message_no_urls']].mentions.iloc[1265478]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def cut_mentions(list_of_mentions, text):\n",
    "    for word in list_of_mentions:\n",
    "        wrd = '@' + word\n",
    "        text = text.replace(wrd, '')\n",
    "    return text.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.02 s, sys: 2.56 s, total: 7.57 s\n",
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_channels['message_no_mentions'] = df_channels.apply(lambda x: cut_mentions(x['mentions'], x['message_no_urls']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "mentions_col_list = df_channels[df_channels['mentions'].map(lambda d: len(d)) > 0]['mentions'].tolist()\n",
    "mentions_list = [item for sublist in mentions_col_list for item in sublist]\n",
    "mentions_unique = list(set(mentions_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 9872 unique channel names among 288370 mentions for dataset\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(mentions_unique)} unique channel names among {len(mentions_list)} mentions for dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "dict = {\"names\": mentions_list}\n",
    "json_object = json.dumps(dict, indent=4)\n",
    "with open(\"/Users/katerynaburovova/PycharmProjects/dehumanization/data/names_from_mentions.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unify and isolate quotes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_56821/4136279409.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_channels['message_no_mentions'] = df_channels['message_no_mentions'].str.replace('|'.join(to_replace),'\"')\n"
     ]
    }
   ],
   "source": [
    "to_replace = [\"¬´\", \"¬ª\", \"‚Äú\"]\n",
    "\n",
    "df_channels['message_no_mentions'] = df_channels['message_no_mentions'].str.replace('|'.join(to_replace),'\"')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 2.58 s, total: 4.27 s\n",
      "Wall time: 5.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_channels['quotes'] = df_channels['message_no_mentions'].str.findall(r'\"(.*?)\"')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Isolate hashtags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.28 s, sys: 1.33 s, total: 9.61 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_channels['hashtags'] = df_channels['message_no_mentions'].str.findall(\"#[A-Za-z0-9_]+\")\n",
    "df_channels['hashtags'] = df_channels['message_no_mentions'].apply(lambda x: {word.strip(\",\").strip(\".\") for word in x.split() if word.startswith(\"#\")})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "0                                hashtags  \\\n1339153  {#–£–∫—Ä–∞–∏–Ω–∞, #–†–æ—Å—Å–∏—è, #–ë–µ–ª–æ—Ä—É—Å—Å–∏—è}   \n303670                                 {}   \n1472075                                {}   \n1271839                                {}   \n897397                                 {}   \n1522199                                {}   \n1543638                                {}   \n1120040                                {}   \n1535100                                {}   \n1037127                                {}   \n\n0                                      message_no_mentions  \n1339153  –ù–∞ –ø–æ–≤–µ—Å—Ç–∫–µ —Å–Ω–æ–≤–∞ –°–≤–µ—Ç–ª–∞–Ω–∞ –¢–∏—Ö–∞–Ω–æ–≤—Å–∫–∞—è. –ù–∞ —ç—Ç–æ...  \n303670   –í–∞—É! –ú–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ —Ä–µ–∫–ª–∞–º—É —Ä–∞–∑–º–µ—â–∞—Ç—å —É —Å–µ–±—è. ...  \n1472075  –ï–≤–≥–µ–Ω–∏–π –†—ã–ª–æ–≤ ‚Äî –ø–µ—Ä–≤—ã–π, –Ω–æ —Å—Ç–∞–≤–∏—Ç –ø–ª–∞–Ω–∫—É —Å–µ–±–µ ...  \n1271839              –ö–∞–∫–æ–µ –Ω–µ–±–æ –≥–æ–ª—É–±–æ–µ...  ‚Äç  —£—£ –∏—Å—Ç–æ—á–Ω–∏–∫  \n897397                 –ì–æ—Å–ø–æ–¥–∏, –•–∞–±–∞—Ä–æ–≤—Å–∫–∏–π —Å–ª–µ–¥ –≤ –ë–µ–π—Ä—É—Ç–µ  \n1522199  –ñ–∏—Ç–µ–ª–µ–π –≤–±–ª–∏–∑–∏ –•–æ–¥—ã–Ω—Å–∫–æ–≥–æ –±—É–ª—å–≤–∞—Ä–∞ –∏–∑–±–∞–≤—è—Ç –æ—Ç ...  \n1543638  –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –ü–∞—Ç—Ä–∏–æ—Ç–∏—á–µ—Å–∫–æ–π –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–∏ –î–æ–Ω–±–∞—Å—Å...  \n1120040  –û–ø–ø–æ–∑–∏—Ü–∏–æ–Ω–µ—Ä –ê–ª–µ–∫—Å–µ–π –ù–∞–≤–∞–ª—å–Ω—ã–π –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª –Ω–∞ ...  \n1535100  ‚Äº –í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –∏ –†–µ–¥–∂–µ–ø –≠—Ä–¥–æ–≥–∞–Ω –≤ —Ö–æ–¥–µ –≤—Å—Ç—Ä–µ...  \n1037127  ü™ñ–ù–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hashtags</th>\n      <th>message_no_mentions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1339153</th>\n      <td>{#–£–∫—Ä–∞–∏–Ω–∞, #–†–æ—Å—Å–∏—è, #–ë–µ–ª–æ—Ä—É—Å—Å–∏—è}</td>\n      <td>–ù–∞ –ø–æ–≤–µ—Å—Ç–∫–µ —Å–Ω–æ–≤–∞ –°–≤–µ—Ç–ª–∞–Ω–∞ –¢–∏—Ö–∞–Ω–æ–≤—Å–∫–∞—è. –ù–∞ —ç—Ç–æ...</td>\n    </tr>\n    <tr>\n      <th>303670</th>\n      <td>{}</td>\n      <td>–í–∞—É! –ú–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ —Ä–µ–∫–ª–∞–º—É —Ä–∞–∑–º–µ—â–∞—Ç—å —É —Å–µ–±—è. ...</td>\n    </tr>\n    <tr>\n      <th>1472075</th>\n      <td>{}</td>\n      <td>–ï–≤–≥–µ–Ω–∏–π –†—ã–ª–æ–≤ ‚Äî –ø–µ—Ä–≤—ã–π, –Ω–æ —Å—Ç–∞–≤–∏—Ç –ø–ª–∞–Ω–∫—É —Å–µ–±–µ ...</td>\n    </tr>\n    <tr>\n      <th>1271839</th>\n      <td>{}</td>\n      <td>–ö–∞–∫–æ–µ –Ω–µ–±–æ –≥–æ–ª—É–±–æ–µ...  ‚Äç  —£—£ –∏—Å—Ç–æ—á–Ω–∏–∫</td>\n    </tr>\n    <tr>\n      <th>897397</th>\n      <td>{}</td>\n      <td>–ì–æ—Å–ø–æ–¥–∏, –•–∞–±–∞—Ä–æ–≤—Å–∫–∏–π —Å–ª–µ–¥ –≤ –ë–µ–π—Ä—É—Ç–µ</td>\n    </tr>\n    <tr>\n      <th>1522199</th>\n      <td>{}</td>\n      <td>–ñ–∏—Ç–µ–ª–µ–π –≤–±–ª–∏–∑–∏ –•–æ–¥—ã–Ω—Å–∫–æ–≥–æ –±—É–ª—å–≤–∞—Ä–∞ –∏–∑–±–∞–≤—è—Ç –æ—Ç ...</td>\n    </tr>\n    <tr>\n      <th>1543638</th>\n      <td>{}</td>\n      <td>–ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –ü–∞—Ç—Ä–∏–æ—Ç–∏—á–µ—Å–∫–æ–π –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–∏ –î–æ–Ω–±–∞—Å—Å...</td>\n    </tr>\n    <tr>\n      <th>1120040</th>\n      <td>{}</td>\n      <td>–û–ø–ø–æ–∑–∏—Ü–∏–æ–Ω–µ—Ä –ê–ª–µ–∫—Å–µ–π –ù–∞–≤–∞–ª—å–Ω—ã–π –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª –Ω–∞ ...</td>\n    </tr>\n    <tr>\n      <th>1535100</th>\n      <td>{}</td>\n      <td>‚Äº –í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –∏ –†–µ–¥–∂–µ–ø –≠—Ä–¥–æ–≥–∞–Ω –≤ —Ö–æ–¥–µ –≤—Å—Ç—Ä–µ...</td>\n    </tr>\n    <tr>\n      <th>1037127</th>\n      <td>{}</td>\n      <td>ü™ñ–ù–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels[['hashtags', 'message_no_mentions']].sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "'–ó–µ–ª–µ–Ω—Å–∫–∏–π –ø—Ä–æ –ø–æ–≥–∏–±—à—É—é –≤ –ü–µ—Ä–≤–æ–º–∞–π—Å–∫–µ –∂–µ–Ω—â–∏–Ω—É: ‚Äò—É –Ω–∞—Å –µ—Å—Ç—å –æ–¥–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞....‚Äô  –£–∂–∞—Å –∫–∞–∫–æ–π!'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels[['hashtags', 'message_no_mentions']].message_no_mentions.iloc[52089]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def cut_hasgtags(set_of_hashtags, text):\n",
    "    for word in list(set_of_hashtags):\n",
    "        text = text.replace(word, '')\n",
    "    return text.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "df_channels['message_no_hashtags'] = df_channels.apply(lambda x: cut_hasgtags(x['hashtags'], x['message_no_mentions']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove everything except letters and punctuation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "punctuation_minimal = '!(),-.:;?%'\n",
    "\n",
    "cyrillic_letters = u\"–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø\"\n",
    "latin_letters_numbers = \"1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \"\n",
    "allowed_symbols = cyrillic_letters+latin_letters_numbers + punctuation_minimal\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def clean_text(string, allowed_symbols=allowed_symbols):\n",
    "    getVals = list(filter(lambda x: x in allowed_symbols, string))\n",
    "    result = \"\".join(getVals)\n",
    "    result = re.sub(' +', ' ', result)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 s, sys: 2.31 s, total: 49.2 s\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_channels['message_clean'] = df_channels['message_no_hashtags'].apply(lambda x: clean_text(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "'–°–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–º–∏—Ç–µ—Ç –≥–æ—Ä–¥–∞ –ú–æ—Å–∫–≤—ã - –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ—Ä–≥–∞–Ω. –î–∞–ª—å—à–µ –º–æ–∂–Ω–æ –Ω–µ —á–∏—Ç–∞—Ç—å. –í –ú–æ—Å–∫–≤–µ –¥–µ–π—Å—Ç–≤—É–µ—Ç –ì–ª–∞–≤–Ω–æ–µ —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ –≥–æ—Ä–æ–¥—É –ú–æ—Å–∫–≤–µ –°–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–º–∏—Ç–µ—Ç–∞ –†–æ—Å—Å–∏–∏. –°–∏—Ç—É–∞—Ü–∏—è, –∫–æ–≥–¥–∞ –¥—É—Ä–∞–∫—É –ø–æ—Ä—É—á–∏–ª–∏ —Ñ–µ–π–∫ –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å, –∞ –æ–Ω –¥–∞–∂–µ —Å–ø–∏—Å–∞—Ç—å —Å —à–∞–ø–∫–∏ –±–ª–∞–Ω–∫–∞ –Ω–µ —Å–º–æ–≥ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∞.'"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels['message_clean'].sample(10).iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 11355 (0.925792%) empty clean messages\n"
     ]
    }
   ],
   "source": [
    "print(f' We have {len(df_channels[df_channels[\"message_clean\"]==\"\"])} ({100*len(df_channels[df_channels[\"message_clean\"]==\"\"])/len(df_channels):2f}%) empty clean messages')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 1215162 (99.074208%) meaningful clean messages\n"
     ]
    }
   ],
   "source": [
    "print(f' We have {len(df_channels[df_channels[\"message_clean\"]!=\"\"])} ({100*len(df_channels[df_channels[\"message_clean\"]!=\"\"])/len(df_channels):2f}%) meaningful clean messages')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "only_letters = cyrillic_letters+latin_letters_numbers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.8 s, sys: 2.64 s, total: 50.4 s\n",
      "Wall time: 57.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_channels['message_words_only_lower'] = df_channels['message_clean'].apply(lambda x: clean_text(x, allowed_symbols=only_letters).lower())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "'–Ω—É –∞–Ω–¥—Ä—é—Ö–∞ —ç—Ç–æ –ø—Ä–∏ —Å–≤–∏–¥–µ—Ç–µ–ª—è—Ö –≥–æ–≤–æ—Ä–∏–ª –¥–∞ –∏ –≤ —Å–µ—Ç–∏ —á–∞—Å—Ç–æ —Ñ–µ–ª—å–¥–º–∞–Ω–∞ –ø–æ–¥–∫–∞–ª—ã–≤–∞–ª –Ω–æ —è –Ω–µ –≥–æ–≤–æ—Ä–∏–ª —á—Ç–æ –Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –ø—Ä–æ—Å—Ç–æ –ª—é–±–∏–ª –µ–≥–æ –ø—Ä–∏—Ç—Ä–æ–ª–∏—Ç—å'"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels['message_words_only_lower'].sample(10).iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Approaches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spacy RU model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.ru.examples import sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#python3 -m spacy download ru_core_news_md"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "outputs": [],
   "source": [
    "# spacy.util.set_data_path(\"/Users/katerynaburovova/PycharmProjects/dehumanization/lib/python3.10/site-packages/ru_core_news_md\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "nlp = spacy.load('ru_core_news_md')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def tokenize_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        result.append([token.text, token.pos_, token.dep_, token.lemma_, token.morph])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "[['Apple',\n  'PROPN',\n  'nsubj',\n  'apple',\n  Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing],\n ['—Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç',\n  'VERB',\n  'ROOT',\n  '—Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å',\n  Aspect=Imp|Mood=Ind|Number=Sing|Person=Third|Tense=Pres|VerbForm=Fin|Voice=Act],\n ['–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å',\n  'NOUN',\n  'obj',\n  '–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å',\n  Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing],\n ['–ø–æ–∫—É–ø–∫–∏',\n  'NOUN',\n  'nmod',\n  '–ø–æ–∫—É–ø–∫–∞',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['—Å—Ç–∞—Ä—Ç–∞–ø–∞',\n  'NOUN',\n  'nmod',\n  '—Å—Ç–∞—Ä—Ç–∞–ø',\n  Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing],\n ['–∏–∑', 'ADP', 'case', '–∏–∑', ],\n ['–°–æ–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ',\n  'ADJ',\n  'amod',\n  '—Å–æ–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ',\n  Case=Gen|Degree=Pos|Gender=Neut|Number=Sing],\n ['–ö–æ—Ä–æ–ª–µ–≤—Å—Ç–≤–∞',\n  'PROPN',\n  'nmod',\n  '–∫–æ—Ä–æ–ª–µ–≤—Å—Ç–≤–æ',\n  Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing],\n ['–∑–∞', 'ADP', 'case', '–∑–∞', ],\n ['$', 'SYM', 'nmod', '$', ],\n ['1', 'NUM', 'appos', '1', ],\n ['–º–ª—Ä–¥',\n  'NOUN',\n  'nmod',\n  '–º–ª—Ä–¥',\n  Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing]]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_spacy(sentences[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RAZDEL tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Handles \"... - ... \" as one word (even for composite ones)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "# from razdel import tokenize\n",
    "# def tokenize_razdel(text):\n",
    "#     return(list(tokenize(text)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## spacy_russian_tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/aatimofeev/spacy_russian_tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() takes exactly 2 positional arguments (339 given)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [342], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m nlp \u001B[38;5;241m=\u001B[39m Russian()\n\u001B[1;32m      5\u001B[0m doc \u001B[38;5;241m=\u001B[39m nlp(text)\n\u001B[0;32m----> 6\u001B[0m russian_tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mRussianTokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnlp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMERGE_PATTERNS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m nlp\u001B[38;5;241m.\u001B[39madd_pipe(russian_tokenizer, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrussian_tokenizer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      8\u001B[0m doc \u001B[38;5;241m=\u001B[39m nlp(text)\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/spacy_russian_tokenizer/__init__.py:17\u001B[0m, in \u001B[0;36mRussianTokenizer.__init__\u001B[0;34m(self, nlp, merge_patterns, terminal_patterns)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentence_terminal \u001B[38;5;241m=\u001B[39m nlp\u001B[38;5;241m.\u001B[39mvocab\u001B[38;5;241m.\u001B[39mstrings[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentence_terminal\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m merge_patterns:\n\u001B[0;32m---> 17\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoken_merge\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmerge_patterns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m terminal_patterns:\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmatcher\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentence_terminal, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39mterminal_patterns)\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/spacy/matcher/matcher.pyx:76\u001B[0m, in \u001B[0;36mspacy.matcher.matcher.Matcher.add\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: add() takes exactly 2 positional arguments (339 given)"
     ]
    }
   ],
   "source": [
    "# from spacy.lang.ru import Russian\n",
    "# from spacy_russian_tokenizer import RussianTokenizer, MERGE_PATTERNS\n",
    "# text = \"–ù–µ –≤–µ—Ç–µ—Ä, –∞ –∫–∞–∫–æ–π-—Ç–æ —É—Ä–∞–≥–∞–Ω!\"\n",
    "# nlp = Russian()\n",
    "# doc = nlp(text)\n",
    "# russian_tokenizer = RussianTokenizer(nlp, MERGE_PATTERNS)\n",
    "# nlp.add_pipe(russian_tokenizer, name='russian_tokenizer')\n",
    "# doc = nlp(text)\n",
    "# print([token.text for token in doc])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## lang-uk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[–Ω–µ —Å–∞–±–≤–æ—Ä–¥](https://github.com/lang-uk/ner-uk/blob/master/doc/tokenization.md)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# from tokenize_uk import tokenize_words\n",
    "# tokenize_words(text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## stanza\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# import stanza\n",
    "# stanza.download('ru')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# nlp_ru = stanza.Pipeline('ru', processors='tokenize')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# def get_stanza_tokens(text):\n",
    "#     doc = nlp_ru(text)\n",
    "#     word_tokens = [token.text for sent in doc.sentences for token in sent.tokens]\n",
    "#     # result = [word for word in word_tokens if word not in stop_words_ru]\n",
    "#     return word_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Subword (BPE?) BERT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Subword, but weird NER"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "# model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "# # pip install transformers sentencepiece\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "# model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "# # model.cuda()  # uncomment it if you have a GPU\n",
    "#\n",
    "# def embed_bert_cls(text, model, tokenizer):\n",
    "#     t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "#     with torch.no_grad():\n",
    "#         model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "#     embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "#     embeddings = torch.nn.functional.normalize(embeddings)\n",
    "#     return embeddings[0].cpu().numpy()\n",
    "#\n",
    "# print(embed_bert_cls('–ø—Ä–∏–≤–µ—Ç –º–∏—Ä', model, tokenizer).shape)\n",
    "# # (312,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]',\n '[UNK]',\n '11',\n '-',\n '–≥–æ',\n '–ø–æ–ª–∫–∞',\n '–≥–æ–Ω',\n '##—è—é—Ç',\n '—Ç–∞–Ω–∫',\n '[UNK]',\n '11',\n '–ø–æ–ª–∫',\n '–ù',\n '##–ú',\n '–î–ù–†',\n '–ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç',\n '–Ω–∞–Ω–æ—Å–∏—Ç—å',\n '—É–¥–∞—Ä—ã',\n '–ø–æ',\n '–ø—Ä–æ—Ç–∏–≤–Ω–∏–∫—É',\n '–≤',\n '–ü–µ—Ä–≤–æ–º–∞–π',\n '##—Å–∫–æ–º',\n '.',\n '–ù–∞',\n '–≤–∏–¥–µ–æ',\n '—Ç–∞–Ω–∫–æ–≤—ã–π',\n '–±–∞—Ç–∞–ª—å–æ–Ω',\n '–ø–æ–¥',\n '–∫–æ–º–∞–Ω–¥–æ–≤–∞–Ω–∏–µ–º',\n '–°–µ–≤–µ—Ä–∞',\n '–±—å–µ—Ç',\n '–ø–æ',\n '–ø–æ–∑–∏—Ü–∏—è–º',\n '–í–°–£',\n ',',\n '–∑–∞–æ–¥–Ω–æ',\n '–∑–∞—Å—Ç–∞–≤–ª—è—è',\n '–º–µ—Ç–∞',\n '##—Ç—å—Å—è',\n '–∏',\n '—Å–ø–µ—à–Ω–æ',\n '—É–¥–∞–ª—è—Ç—å',\n '##—Å—è',\n '–ø–æ—è–≤–∏',\n '##–≤—à–∏–π—Å—è',\n '–Ω–∞',\n '—Å–≤–æ—é',\n '–±–µ–¥—É',\n '—É–∫—Ä–∞–∏–Ω—Å–∫–∏–π',\n '—Ç–∞–Ω–∫',\n '.',\n '@',\n 'war',\n '##gon',\n '##zo',\n '*',\n '–Ω–∞—à',\n '–ø—Ä–æ–µ–∫—Ç',\n '—Å—É—â–µ—Å—Ç–≤—É–µ—Ç',\n '–Ω–∞',\n '—Å—Ä–µ–¥—Å—Ç–≤–∞',\n '–ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤',\n ',',\n '–∫–∞—Ä—Ç–∞',\n '–¥–ª—è',\n '–ø–æ–º–æ—â–∏',\n '427',\n '##9',\n '380',\n '##6',\n '984',\n '##2',\n '952',\n '##1',\n '[SEP]']"
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def tokens_bert_cls(text, model, tokenizer):\n",
    "#     encoding = tokenizer.encode(text)\n",
    "#     return tokenizer.convert_ids_to_tokens(encoding)\n",
    "#\n",
    "# tokens_bert_cls(test_string, model, tokenizer)\n",
    "# # (312,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]', '–ù–µ', '–≤–µ—Ç–µ—Ä', ',', '–∞', '–∫–∞–∫–æ–π', '-', '—Ç–æ', '—É—Ä–∞–≥–∞–Ω', '!', '[SEP]']"
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens_bert_cls(text, model, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execution time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_test_sample = df_channels.sample(100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 1.02 s, total: 20.5 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# df_test_sample['spacy_tokens'] = df_test_sample['message'].apply(lambda x: tokenize_spacy(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 331 ms, total: 13.3 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# df_test_sample['bert_tokens'] = df_test_sample['message'].apply(lambda x: tokens_bert_cls(x, model, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 75.3 ms, total: 1.99 s\n",
      "Wall time: 2.02 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# df_test_sample['lang_uk_tokens'] = df_test_sample['message'].apply(lambda x: tokenize_words(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 2.08 s, total: 15.9 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# df_test_sample['razdel_tokens'] = df_test_sample['message'].apply(lambda x: tokenize_razdel(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 234 ms, total: 3.05 s\n",
      "Wall time: 3.11 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# df_test_sample['stanza_tokens'] = df_test_sample['message'].sample(100).apply(lambda x: get_stanza_tokens(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 18s, sys: 2min 44s, total: 43min 2s\n",
      "Wall time: 45min\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# df_test_sample['stanza_tokens'] = df_test_sample['message'].apply(lambda x: get_stanza_tokens(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "data": {
      "text/plain": "'–û—Ç–ø—Ä–∞–≤–∫–∞ –ø–æ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç–µ 2_5325905093675979275.pdf'"
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from random import randrange\n",
    "#\n",
    "# df_channels.message.iloc[randrange(len(df_channels))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ–æ–±—â–∞–µ—Ç—Å—è –æ —Ä–∞–Ω–µ–Ω—ã—Ö –≤ —Ä—è–¥–∞—Ö —Ç—É—Ä–µ—Ü–∫–∏—Ö —Å–∏–ª –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ–¥—Ä—ã–≤–∞ –º–∏–Ω—ã –Ω–∞ —Ç—Ä–∞—Å—Å–µ –ú4 –≤ –ø—Ä–æ–≤–∏–Ω—Ü–∏–∏ –ò–¥–ª–∏–±. –¢—É—Ä–µ—Ü–∫–∏–µ –≤–µ—Ä—Ç–æ–ª–µ—Ç—ã –Ω–∞–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –∫ –º–µ—Å—Ç—É –≤–∑—Ä—ã–≤–∞ –¥–ª—è —ç–≤–∞–∫—É–∞—Ü–∏–∏ —Ä–∞–Ω–µ–Ω—ã—Ö.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[['–°–æ–æ–±—â–∞–µ—Ç—Å—è', 'VERB', 'ROOT', '—Å–æ–æ–±—â–∞—Ç—å—Å—è'],\n ['–æ', 'ADP', 'case', '–æ'],\n ['—Ä–∞–Ω–µ–Ω—ã—Ö', 'NOUN', 'obl', '—Ä–∞–Ω–µ–Ω—ã–π'],\n ['–≤', 'ADP', 'case', '–≤'],\n ['—Ä—è–¥–∞—Ö', 'NOUN', 'nmod', '—Ä—è–¥'],\n ['—Ç—É—Ä–µ—Ü–∫–∏—Ö', 'ADJ', 'amod', '—Ç—É—Ä–µ—Ü–∫–∏–π'],\n ['—Å–∏–ª', 'NOUN', 'nmod', '—Å–∏–ª–∞'],\n ['–≤', 'ADP', 'case', '–≤'],\n ['—Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ', 'NOUN', 'obl', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç'],\n ['–ø–æ–¥—Ä—ã–≤–∞', 'NOUN', 'nmod', '–ø–æ–¥—Ä—ã–≤'],\n ['–º–∏–Ω—ã', 'NOUN', 'nmod', '–º–∏–Ω–∞'],\n ['–Ω–∞', 'ADP', 'case', '–Ω–∞'],\n ['—Ç—Ä–∞—Å—Å–µ', 'NOUN', 'nmod', '—Ç—Ä–∞—Å—Å–∞'],\n ['–ú4', 'PROPN', 'appos', '–º4'],\n ['–≤', 'ADP', 'case', '–≤'],\n ['–ø—Ä–æ–≤–∏–Ω—Ü–∏–∏', 'NOUN', 'nmod', '–ø—Ä–æ–≤–∏–Ω—Ü–∏—è'],\n ['–ò–¥–ª–∏–±', 'PROPN', 'appos', '–∏–¥–ª–∏–±'],\n ['.', 'PUNCT', 'punct', '.'],\n ['–¢—É—Ä–µ—Ü–∫–∏–µ', 'ADJ', 'amod', '—Ç—É—Ä–µ—Ü–∫–∏–π'],\n ['–≤–µ—Ä—Ç–æ–ª–µ—Ç—ã', 'NOUN', 'nsubj', '–≤–µ—Ä—Ç–æ–ª—ë—Ç'],\n ['–Ω–∞–ø—Ä–∞–≤–ª—è—é—Ç—Å—è', 'VERB', 'ROOT', '–Ω–∞–ø—Ä–∞–≤–ª—è—Ç—å—Å—è'],\n ['–∫', 'ADP', 'case', '–∫'],\n ['–º–µ—Å—Ç—É', 'NOUN', 'obl', '–º–µ—Å—Ç–æ'],\n ['–≤–∑—Ä—ã–≤–∞', 'NOUN', 'nmod', '–≤–∑—Ä—ã–≤'],\n ['–¥–ª—è', 'ADP', 'case', '–¥–ª—è'],\n ['—ç–≤–∞–∫—É–∞—Ü–∏–∏', 'NOUN', 'nmod', '—ç–≤–∞–∫—É–∞—Ü–∏—è'],\n ['—Ä–∞–Ω–µ–Ω—ã—Ö', 'NOUN', 'nmod', '—Ä–∞–Ω–µ–Ω—ã–π'],\n ['.', 'PUNCT', 'punct', '.']]"
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnd_text = df_channels.message.iloc[randrange(len(df_channels))]\n",
    "# print(rnd_text)\n",
    "#\n",
    "# tokenize_spacy(rnd_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenization and lemmatization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def tokenize_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        result.append([token.text, token.pos_, token.dep_, token.lemma_, token.morph])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def get_lemmas(text):\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        result.append([token.lemma_])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "df_sample = df_channels.sample(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 352 ms, total: 17 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sample['tokens'] = df_sample['message_words_only_lower'].apply(lambda x: tokenize_spacy(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "'–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —Ä–æ—Å—Å–∏–∏ –≤–ª–∞–¥–∏–º–∏—Ä –ø—É—Ç–∏–Ω –Ω–∞–≥—Ä–∞–¥–∏–ª –±–æ—Ä–∏—Å–∞ –≥—Ä—ã–∑–ª–æ–≤–∞ –æ—Ä–¥–µ–Ω–æ–º –∑–∞ –∑–∞—Å–ª—É–≥–∏ –ø–µ—Ä–µ–¥ –æ—Ç–µ—á–µ—Å—Ç–≤–æ–º i —Å—Ç–µ–ø–µ–Ω–∏ –æ—Ä–¥–µ–Ω –≤—Ä—É—á–µ–Ω –∑–∞ –≤—ã–¥–∞—é—â–∏–µ—Å—è –∑–∞—Å–ª—É–≥–∏ –≤ —É–∫—Ä–µ–ø–ª–µ–Ω–∏–∏ —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–Ω–µ—à–Ω–µ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫—É—Ä—Å–∞ —Å—Ç—Ä–∞–Ω—ã —Ç–∞–∫–∂–µ –æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º –¥–ª—è –Ω–∞–≥—Ä–∞–¥—ã –ø–æ—Å–ª—É–∂–∏–ª–∏ –µ–≥–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ –æ–±–æ—Ä–æ–Ω–Ω–æ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–º–ø–ª–µ–∫—Å–∞ —Ä–æ—Å—Å–∏–∏ –∏ –º–Ω–æ–≥–æ–ª–µ—Ç–Ω—è—è –¥–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞'"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['message_words_only_lower'].iloc[536]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "[['–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n  'NOUN',\n  'nsubj',\n  '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n  Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing],\n ['—Ä–æ—Å—Å–∏–∏',\n  'PROPN',\n  'nmod',\n  '—Ä–æ—Å—Å–∏—è',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['–≤–ª–∞–¥–∏–º–∏—Ä',\n  'PROPN',\n  'appos',\n  '–≤–ª–∞–¥–∏–º–∏—Ä',\n  Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing],\n ['–ø—É—Ç–∏–Ω',\n  'PROPN',\n  'flat:name',\n  '–ø—É—Ç–∏–Ω',\n  Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing],\n ['–Ω–∞–≥—Ä–∞–¥–∏–ª',\n  'VERB',\n  'ROOT',\n  '–Ω–∞–≥—Ä–∞–¥–∏—Ç—å',\n  Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act],\n ['–±–æ—Ä–∏—Å–∞',\n  'PROPN',\n  'obj',\n  '–±–æ—Ä–∏—Å',\n  Animacy=Anim|Case=Acc|Gender=Masc|Number=Sing],\n ['–≥—Ä—ã–∑–ª–æ–≤–∞',\n  'PROPN',\n  'flat:name',\n  '–≥—Ä—ã–∑–ª–æ–≤',\n  Animacy=Anim|Case=Acc|Gender=Masc|Number=Sing],\n ['–æ—Ä–¥–µ–Ω–æ–º',\n  'NOUN',\n  'xcomp',\n  '–æ—Ä–¥–µ–Ω',\n  Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing],\n ['–∑–∞', 'ADP', 'case', '–∑–∞', ],\n ['–∑–∞—Å–ª—É–≥–∏',\n  'NOUN',\n  'obl',\n  '–∑–∞—Å–ª—É–≥–∞',\n  Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur],\n ['–ø–µ—Ä–µ–¥', 'ADP', 'case', '–ø–µ—Ä–µ–¥', ],\n ['–æ—Ç–µ—á–µ—Å—Ç–≤–æ–º',\n  'NOUN',\n  'nmod',\n  '–æ—Ç–µ—á–µ—Å—Ç–≤–æ',\n  Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing],\n ['i', 'ADJ', 'amod', 'i', ],\n ['—Å—Ç–µ–ø–µ–Ω–∏',\n  'NOUN',\n  'nmod',\n  '—Å—Ç–µ–ø–µ–Ω—å',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['–æ—Ä–¥–µ–Ω',\n  'NOUN',\n  'nsubj:pass',\n  '–æ—Ä–¥–µ–Ω',\n  Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing],\n ['–≤—Ä—É—á–µ–Ω',\n  'VERB',\n  'conj',\n  '–≤—Ä—É—á–∏—Ç—å',\n  Aspect=Perf|Gender=Masc|Number=Sing|StyleVariant=Short|Tense=Past|VerbForm=Part|Voice=Pass],\n ['–∑–∞', 'ADP', 'case', '–∑–∞', ],\n ['–≤—ã–¥–∞—é—â–∏–µ—Å—è',\n  'ADJ',\n  'amod',\n  '–≤—ã–¥–∞—é—â–∏–π—Å—è',\n  Animacy=Inan|Case=Acc|Degree=Pos|Number=Plur],\n ['–∑–∞—Å–ª—É–≥–∏',\n  'NOUN',\n  'obl',\n  '–∑–∞—Å–ª—É–≥–∞',\n  Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur],\n ['–≤', 'ADP', 'case', '–≤', ],\n ['—É–∫—Ä–µ–ø–ª–µ–Ω–∏–∏',\n  'NOUN',\n  'nmod',\n  '—É–∫—Ä–µ–ø–ª–µ–Ω–∏–µ',\n  Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing],\n ['—Ä–æ—Å—Å–∏–π—Å–∫–æ–π',\n  'ADJ',\n  'amod',\n  '—Ä–æ—Å—Å–∏–π—Å–∫–∏–π',\n  Case=Gen|Degree=Pos|Gender=Fem|Number=Sing],\n ['–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏',\n  'NOUN',\n  'nmod',\n  '–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['–∏', 'CCONJ', 'cc', '–∏', ],\n ['—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏',\n  'NOUN',\n  'conj',\n  '—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['–≤–Ω–µ—à–Ω–µ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ',\n  'ADJ',\n  'amod',\n  '–≤–Ω–µ—à–Ω–µ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–π',\n  Case=Gen|Degree=Pos|Gender=Masc|Number=Sing],\n ['–∫—É—Ä—Å–∞',\n  'NOUN',\n  'nmod',\n  '–∫—É—Ä—Å',\n  Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing],\n ['—Å—Ç—Ä–∞–Ω—ã',\n  'NOUN',\n  'nmod',\n  '—Å—Ç—Ä–∞–Ω–∞',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['—Ç–∞–∫–∂–µ', 'ADV', 'advmod', '—Ç–∞–∫–∂–µ', Degree=Pos],\n ['–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º',\n  'NOUN',\n  'obl',\n  '–æ—Å–Ω–æ–≤–∞–Ω–∏–µ',\n  Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing],\n ['–¥–ª—è', 'ADP', 'case', '–¥–ª—è', ],\n ['–Ω–∞–≥—Ä–∞–¥—ã',\n  'NOUN',\n  'nmod',\n  '–Ω–∞–≥—Ä–∞–¥–∞',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['–ø–æ—Å–ª—É–∂–∏–ª–∏',\n  'VERB',\n  'conj',\n  '–ø–æ—Å–ª—É–∂–∏—Ç—å',\n  Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act],\n ['–µ–≥–æ', 'DET', 'det', '–µ–≥–æ', ],\n ['–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π',\n  'ADJ',\n  'amod',\n  '–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π',\n  Case=Nom|Degree=Pos|Gender=Masc|Number=Sing],\n ['–≤–∫–ª–∞–¥',\n  'NOUN',\n  'nsubj',\n  '–≤–∫–ª–∞–¥',\n  Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing],\n ['–≤', 'ADP', 'case', '–≤', ],\n ['—Ä–∞–∑–≤–∏—Ç–∏–µ',\n  'NOUN',\n  'nmod',\n  '—Ä–∞–∑–≤–∏—Ç–∏–µ',\n  Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing],\n ['–æ–±–æ—Ä–æ–Ω–Ω–æ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ',\n  'ADJ',\n  'amod',\n  '–æ–±–æ—Ä–æ–Ω–Ω–æ–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ',\n  Case=Gen|Degree=Pos|Gender=Masc|Number=Sing],\n ['–∫–æ–º–ø–ª–µ–∫—Å–∞',\n  'NOUN',\n  'nmod',\n  '–∫–æ–º–ø–ª–µ–∫—Å',\n  Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing],\n ['—Ä–æ—Å—Å–∏–∏',\n  'PROPN',\n  'nmod',\n  '—Ä–æ—Å—Å–∏—è',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['–∏', 'CCONJ', 'cc', '–∏', ],\n ['–º–Ω–æ–≥–æ–ª–µ—Ç–Ω—è—è',\n  'ADJ',\n  'amod',\n  '–º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–π',\n  Case=Nom|Degree=Pos|Gender=Fem|Number=Sing],\n ['–¥–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω–∞—è',\n  'ADJ',\n  'amod',\n  '–¥–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω—ã–π',\n  Case=Nom|Degree=Pos|Gender=Fem|Number=Sing],\n ['—Ä–∞–±–æ—Ç–∞',\n  'NOUN',\n  'conj',\n  '—Ä–∞–±–æ—Ç–∞',\n  Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing]]"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['tokens'].iloc[536]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 433 ms, total: 17.2 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sample['lemmas'] = df_sample['message_words_only_lower'].apply(lambda x: get_lemmas(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "[['–∫–∞–∫', 'SCONJ', 'mark', '–∫–∞–∫', ],\n ['–ø–æ–∫–∞–∑–∞–ª–æ',\n  'VERB',\n  'parataxis',\n  '–ø–æ–∫–∞–∑–∞—Ç—å',\n  Aspect=Perf|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act],\n ['–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ',\n  'NOUN',\n  'nsubj',\n  '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ',\n  Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing],\n ['statista', 'X', 'appos', 'statista', Foreign=Yes],\n ['global', 'X', 'flat:foreign', 'global', Foreign=Yes],\n ['consumer', 'X', 'flat:foreign', 'consumer', Foreign=Yes],\n ['survey', 'X', 'flat:foreign', 'survey', Foreign=Yes],\n ['–ø–æ—á—Ç–∏', 'ADV', 'advmod', '–ø–æ—á—Ç–∏', Degree=Pos],\n ['–∫–∞–∂–¥—ã–π', 'DET', 'det', '–∫–∞–∂–¥—ã–π', Case=Nom|Gender=Masc|Number=Sing],\n ['–ø—è—Ç—ã–π',\n  'ADJ',\n  'amod',\n  '–ø—è—Ç—ã–π',\n  Case=Nom|Degree=Pos|Gender=Masc|Number=Sing],\n ['—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç',\n  'NOUN',\n  'nsubj',\n  '—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç',\n  Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing],\n ['–∏–∑', 'ADP', 'case', '–∏–∑', ],\n ['–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏',\n  'PROPN',\n  'nmod',\n  '–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing],\n ['18', 'NUM', 'appos', '18', ],\n ['–æ–±—ã—á–Ω–æ', 'ADV', 'advmod', '–æ–±—ã—á–Ω–æ', Degree=Pos],\n ['—Å—Ç—Ä–∞–¥–∞–µ—Ç',\n  'VERB',\n  'ROOT',\n  '—Å—Ç—Ä–∞–¥–∞—Ç—å',\n  Aspect=Imp|Mood=Ind|Number=Sing|Person=Third|Tense=Pres|VerbForm=Fin|Voice=Act],\n ['–æ—Ç', 'ADP', 'case', '–æ—Ç', ],\n ['–ø–æ—Ö–º–µ–ª—å—è',\n  'NOUN',\n  'obl',\n  '–ø–æ—Ö–º–µ–ª–∏–µ',\n  Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing],\n ['–Ω–∞', 'ADP', 'case', '–Ω–∞', ],\n ['—Å–ª–µ–¥—É—é—â–µ–µ',\n  'ADJ',\n  'amod',\n  '—Å–ª–µ–¥—É—é—â–∏–π',\n  Animacy=Inan|Case=Acc|Degree=Pos|Gender=Neut|Number=Sing],\n ['—É—Ç—Ä–æ',\n  'NOUN',\n  'obl',\n  '—É—Ç—Ä–æ',\n  Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing],\n ['–ø–æ—Å–ª–µ', 'ADP', 'case', '–ø–æ—Å–ª–µ', ],\n ['–ø—Ä–∏–µ–º–∞',\n  'NOUN',\n  'obl',\n  '–ø—Ä–∏—ë–º',\n  Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing],\n ['–∞–ª–∫–æ–≥–æ–ª—è',\n  'NOUN',\n  'nmod',\n  '–∞–ª–∫–æ–≥–æ–ª—å',\n  Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing],\n ['—Ç–∞–∫–∏–º', 'DET', 'det', '—Ç–∞–∫–æ–π', Case=Ins|Gender=Masc|Number=Sing],\n ['–æ–±—Ä–∞–∑–æ–º',\n  'NOUN',\n  'obl',\n  '–æ–±—Ä–∞–∑',\n  Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing],\n ['–±—Ä–∏—Ç–∞–Ω—Ü—ã',\n  'NOUN',\n  'nsubj',\n  '–±—Ä–∏—Ç–∞–Ω–µ—Ü',\n  Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur],\n ['–æ–∫–∞–∑–∞–ª–∏—Å—å',\n  'VERB',\n  'conj',\n  '–æ–∫–∞–∑–∞—Ç—å—Å—è',\n  Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Mid],\n ['–Ω–∞–∏–±–æ–ª–µ–µ', 'ADV', 'advmod', '–Ω–∞–∏–±–æ–ª–µ–µ', Degree=Pos],\n ['–ø–æ–¥–≤–µ—Ä–∂–µ–Ω—ã',\n  'ADJ',\n  'xcomp',\n  '–ø–æ–¥–≤–µ—Ä–∂–µ–Ω–Ω—ã–π',\n  Degree=Pos|Number=Plur|StyleVariant=Short],\n ['—ç—Ç–æ–º—É', 'DET', 'det', '—ç—Ç–æ—Ç', Case=Dat|Gender=Masc|Number=Sing],\n ['–Ω–µ–¥—É–≥—É',\n  'NOUN',\n  'iobj',\n  '–Ω–µ–¥—É–≥',\n  Animacy=Inan|Case=Dat|Gender=Masc|Number=Sing],\n ['—Å—Ä–µ–¥–∏', 'ADP', 'case', '—Å—Ä–µ–¥–∏', ],\n ['–∂–∏—Ç–µ–ª–µ–π',\n  'NOUN',\n  'obl',\n  '–∂–∏—Ç–µ–ª—å',\n  Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur],\n ['–≤–æ—Å—å–º–∏', 'NUM', 'nummod', '–≤–æ—Å–µ–º—å', Case=Gen],\n ['—Å—Ç—Ä–∞–Ω',\n  'NOUN',\n  'nmod',\n  '—Å—Ç—Ä–∞–Ω–∞',\n  Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur],\n ['—É—á–∞—Å—Ç–≤–æ–≤–∞–≤—à–∏—Ö',\n  'VERB',\n  'amod',\n  '—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å',\n  Aspect=Imp|Case=Gen|Number=Plur|Tense=Past|VerbForm=Part|Voice=Act],\n ['–≤', 'ADP', 'case', '–≤', ],\n ['–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏',\n  'NOUN',\n  'obl',\n  '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ',\n  Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing]]"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['tokens'].iloc[536]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "[['–∫–∞–∫'],\n ['–ø–æ–∫–∞–∑–∞—Ç—å'],\n ['–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ'],\n ['statista'],\n ['global'],\n ['consumer'],\n ['survey'],\n ['–ø–æ—á—Ç–∏'],\n ['–∫–∞–∂–¥—ã–π'],\n ['–ø—è—Ç—ã–π'],\n ['—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç'],\n ['–∏–∑'],\n ['–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è'],\n ['18'],\n ['–æ–±—ã—á–Ω–æ'],\n ['—Å—Ç—Ä–∞–¥–∞—Ç—å'],\n ['–æ—Ç'],\n ['–ø–æ—Ö–º–µ–ª–∏–µ'],\n ['–Ω–∞'],\n ['—Å–ª–µ–¥—É—é—â–∏–π'],\n ['—É—Ç—Ä–æ'],\n ['–ø–æ—Å–ª–µ'],\n ['–ø—Ä–∏—ë–º'],\n ['–∞–ª–∫–æ–≥–æ–ª—å'],\n ['—Ç–∞–∫–æ–π'],\n ['–æ–±—Ä–∞–∑'],\n ['–±—Ä–∏—Ç–∞–Ω–µ—Ü'],\n ['–æ–∫–∞–∑–∞—Ç—å—Å—è'],\n ['–Ω–∞–∏–±–æ–ª–µ–µ'],\n ['–ø–æ–¥–≤–µ—Ä–∂–µ–Ω–Ω—ã–π'],\n ['—ç—Ç–æ—Ç'],\n ['–Ω–µ–¥—É–≥'],\n ['—Å—Ä–µ–¥–∏'],\n ['–∂–∏—Ç–µ–ª—å'],\n ['–≤–æ—Å–µ–º—å'],\n ['—Å—Ç—Ä–∞–Ω–∞'],\n ['—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å'],\n ['–≤'],\n ['–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ']]"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['lemmas'].iloc[45]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "'–±–ª—É–º–±–µ—Ä–≥ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è –±–∞–π–¥–µ–Ω–∞ –ø–æ–¥—Ç–∞–ª–∫–∏–≤–∞–µ—Ç —Å–æ—é–∑–Ω–∏–∫–æ–≤ –µ—Å –∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —à–∏—Ä–æ–∫–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Å–∞–Ω–∫—Ü–∏–π –ø—Ä–æ—Ç–∏–≤ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –±–∞–Ω–∫–æ–≤ –∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤–≤–µ–¥–µ–Ω—ã —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å —Å—à–∞ –µ—Å–ª–∏ –∫—Ä–µ–º–ª—å –Ω–∞–ø–∞–¥–µ—Ç –Ω–∞ —É–∫—Ä–∞–∏–Ω—É –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —à–∞–≥–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ —Ç–∞–∫–∏–µ –∫–∞–∫ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Ä–æ—Å—Å–∏–∏ –æ—Ç –ø–ª–∞—Ç–µ–∂–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã swift —Å—á–∏—Ç–∞—é—Ç—Å—è –∫—Ä–∞–π–Ω–µ –ø—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–Ω—ã–º–∏ —Å–∫–∞–∑–∞–ª–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∏ –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞ —Å—Å—ã–ª–∞—è—Å—å –Ω–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –º–∏—Ä–æ–≤—ã—Ö —Ä—ã–Ω–∫–æ–≤ —ç–Ω–µ—Ä–≥–æ–Ω–æ—Å–∏—Ç–µ–ª–µ–π –∏ –¥—Ä—É–≥–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ —ç–∫—Å–ø–æ—Ä—Ç–∞ –µ—â–µ –æ–¥–Ω–∏–º –ø—Ä–µ–¥–º–µ—Ç–æ–º –±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–∞ —è–≤–ª—è–µ—Ç—Å—è –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∞ —Ç–æ–≥–æ —á—Ç–æ –ø—É—Ç–∏–Ω –º–æ–∂–µ—Ç –ø—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å —ç–∫—Å–ø–æ—Ä—Ç –≥–∞–∑–∞ —Ä–æ—Å—Å–∏—è –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ–∫–æ–ª–æ 40 –ø–æ—Å—Ç–∞–≤–æ–∫ –≤ –µ–≤—Ä–æ–ø—É –≤ —Å—É—Ö–æ–º –æ—Å—Ç–∞—Ç–∫–µ –ø–ª–∞–Ω —á—Ç–æ –∏ –≥–æ–≤–æ—Ä–∏—Ç—å –±—ã–ª –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ—Å—Ç–æ–π –∏ —è—Å–Ω—ã–π –ª—É—á—à–µ –Ω–µ –ø—Ä–∏–¥—É–º–∞—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ —É –Ω–µ–≥–æ –±—ã–ª —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –±—ã–ª–æ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ –∫–∞–∫ –ø—Ä–∏–≤–µ—Å—Ç–∏ –µ–≥–æ –≤ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ'"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['message_words_only_lower'].iloc[56]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def get_lemma_vec(text):\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        result.append([token.lemma])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "[['—Ö–æ—Ö–ª—è—Ü–∫–æ–≥–æ',\n  'ADJ',\n  'ROOT',\n  '—Ö–æ—Ö–ª—è—Ü–∫–æ–≥–æ',\n  Animacy=Anim|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing]]"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_spacy('—Ö–æ—Ö–ª—è—Ü–∫–æ–≥–æ')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OOV handling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://spacy.io/usage/processing-pipelines#custom-components-user-hooks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "should we add a hook that returns zero vectors for OOV terms?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_channels['lemmas'] = df_channels['message_words_only_lower'].apply(lambda x: get_lemmas(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:1\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4668\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4670\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/apply.py:1105\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m-> 1105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/apply.py:1155\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1153\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m_values\u001B[38;5;241m.\u001B[39mmap(f)\n\u001B[1;32m   1154\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1155\u001B[0m         values \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mobject\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m   1156\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mmap_infer(\n\u001B[1;32m   1157\u001B[0m             values,\n\u001B[1;32m   1158\u001B[0m             f,\n\u001B[1;32m   1159\u001B[0m             convert\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_dtype,\n\u001B[1;32m   1160\u001B[0m         )\n\u001B[1;32m   1162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1163\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1164\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/generic.py:6240\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m   6233\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   6234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[:, i]\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[1;32m   6235\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[1;32m   6236\u001B[0m     ]\n\u001B[1;32m   6238\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6239\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[0;32m-> 6240\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_data)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6243\u001B[0m \u001B[38;5;66;03m# GH 33113: handle empty frame or series\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/internals/managers.py:445\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mastype\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, dtype, copy: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, errors: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m--> 445\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mastype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/internals/managers.py:347\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001B[0m\n\u001B[1;32m    345\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    346\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 347\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mNotImplementedError\u001B[39;00m):\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ignore_failures:\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/internals/blocks.py:526\u001B[0m, in \u001B[0;36mBlock.astype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[1;32m    510\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    524\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m--> 526\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[1;32m    529\u001B[0m newb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_block(new_values)\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:299\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[0;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    296\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m values\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 299\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/dehumanization/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:222\u001B[0m, in \u001B[0;36mastype_array\u001B[0;34m(values, dtype, copy)\u001B[0m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_dtype_equal(values\u001B[38;5;241m.\u001B[39mdtype, dtype):\n\u001B[1;32m    221\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[0;32m--> 222\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m values\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(values, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[1;32m    226\u001B[0m     \u001B[38;5;66;03m# i.e. ExtensionArray\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_channels['tokens'] = df_channels['message_words_only_lower'].apply(lambda x: tokenize_spacy(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "0           id                       date     views  \\\n0        12347  2022-12-15 16:32:15+00:00    9914.0   \n1        12346  2022-12-15 15:00:03+00:00   29207.0   \n2        12345  2022-12-15 14:21:22+00:00   41058.0   \n3        12344  2022-12-15 13:08:35+00:00   40696.0   \n4        12343  2022-12-15 12:31:23+00:00   51690.0   \n...        ...                        ...       ...   \n1607921      7  2019-09-28 10:13:52+00:00    3190.0   \n1607922      6  2019-09-28 09:35:07+00:00    3239.0   \n1607923      5  2019-09-28 07:34:47+00:00     314.0   \n1607924      4  2019-09-28 07:08:55+00:00    4339.0   \n1607925      3  2019-09-27 21:31:04+00:00  105193.0   \n\n0                                                reactions  \\\n0        MessageReactions(results=[ReactionCount(reacti...   \n1        MessageReactions(results=[ReactionCount(reacti...   \n2        MessageReactions(results=[ReactionCount(reacti...   \n3        MessageReactions(results=[ReactionCount(reacti...   \n4        MessageReactions(results=[ReactionCount(reacti...   \n...                                                    ...   \n1607921                                                NaN   \n1607922                                                NaN   \n1607923                                                NaN   \n1607924                                                NaN   \n1607925                                                NaN   \n\n0                                     to_id  \\\n0        PeerChannel(channel_id=1183570279)   \n1        PeerChannel(channel_id=1183570279)   \n2        PeerChannel(channel_id=1183570279)   \n3        PeerChannel(channel_id=1183570279)   \n4        PeerChannel(channel_id=1183570279)   \n...                                     ...   \n1607921  PeerChannel(channel_id=1253974160)   \n1607922  PeerChannel(channel_id=1253974160)   \n1607923  PeerChannel(channel_id=1253974160)   \n1607924  PeerChannel(channel_id=1253974160)   \n1607925  PeerChannel(channel_id=1253974160)   \n\n0                                                 fwd_from  \\\n0                                                      NaN   \n1                                                      NaN   \n2                                                      NaN   \n3        MessageFwdHeader(date=datetime.datetime(2022, ...   \n4                                                      NaN   \n...                                                    ...   \n1607921                                                NaN   \n1607922                                                NaN   \n1607923  MessageFwdHeader(date=datetime.datetime(2019, ...   \n1607924                                                NaN   \n1607925                                                NaN   \n\n0                                                  message   type duration  \\\n0        –ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å...  photo      NaN   \n1        –í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...  photo      NaN   \n2        ¬´–ö–∞—Ç–∞—Ä–≥–µ–π—Ç¬ª –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...   text      NaN   \n3        üî•–í –≥–æ—Å—Ç—è—Ö —É @Metametrica –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ ...  photo      NaN   \n4        –ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...   text      NaN   \n...                                                    ...    ...      ...   \n1607921  –ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏: @obrazbuduschego2_bot –î–æ–Ω–∞—Å—Ç—Ä–æ–µ...   text      NaN   \n1607922  –ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...   text      NaN   \n1607923  –¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...   text      NaN   \n1607924  –û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...   text      NaN   \n1607925  –•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ ¬´...  photo      NaN   \n\n0            channel_name  ...  \\\n0               mardanaka  ...   \n1               mardanaka  ...   \n2               mardanaka  ...   \n3               mardanaka  ...   \n4               mardanaka  ...   \n...                   ...  ...   \n1607921  obrazbuduschego2  ...   \n1607922  obrazbuduschego2  ...   \n1607923  obrazbuduschego2  ...   \n1607924  obrazbuduschego2  ...   \n1607925  obrazbuduschego2  ...   \n\n0                                         message_no_emoji           url_list  \\\n0        –ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å...  [www.youtube.com]   \n1        –í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...                 []   \n2        ¬´–ö–∞—Ç–∞—Ä–≥–µ–π—Ç¬ª –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...                 []   \n3         –í –≥–æ—Å—Ç—è—Ö —É @Metametrica –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ ...                 []   \n4        –ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...                 []   \n...                                                    ...                ...   \n1607921  –ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏: @obrazbuduschego2_bot –î–æ–Ω–∞—Å—Ç—Ä–æ–µ...                 []   \n1607922  –ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...                 []   \n1607923  –¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...                 []   \n1607924  –û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...                 []   \n1607925  –•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ ¬´...             [t.me]   \n\n0                                          message_no_urls  \\\n0         –ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å     \n1        –í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...   \n2        ¬´–ö–∞—Ç–∞—Ä–≥–µ–π—Ç¬ª –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...   \n3         –í –≥–æ—Å—Ç—è—Ö —É @Metametrica –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ ...   \n4        –ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...   \n...                                                    ...   \n1607921  –ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏: @obrazbuduschego2_bot –î–æ–Ω–∞—Å—Ç—Ä–æ–µ...   \n1607922  –ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...   \n1607923  –¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...   \n1607924  –û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...   \n1607925  –•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ ¬´...   \n\n0                                                 mentions  \\\n0                                                       []   \n1                                                       []   \n2                                                       []   \n3                               [Metametrica, Metametrica]   \n4                                                       []   \n...                                                    ...   \n1607921                 [obrazbuduschego2_bot, protonmail]   \n1607922                                                 []   \n1607923                                                 []   \n1607924                                                 []   \n1607925  [russica2, kremlebezBashennik, master_pera, sh...   \n\n0                                      message_no_mentions  \\\n0           –ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å   \n1        –í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...   \n2        \"–ö–∞—Ç–∞—Ä–≥–µ–π—Ç\" –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...   \n3        –í –≥–æ—Å—Ç—è—Ö —É  –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø...   \n4        –ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...   \n...                                                    ...   \n1607921  –ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏:  –î–æ–Ω–∞—Å—Ç—Ä–æ–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –∫—Ç–æ...   \n1607922  –ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...   \n1607923  –¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...   \n1607924  –û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...   \n1607925  –•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ \"...   \n\n0                                                   quotes hashtags  \\\n0                                                       []       {}   \n1                               [–ú–≠–§. –≠–∫–æ–Ω–æ–º–∏–∫–∞ –¥–ª—è –ª—é–¥–µ–π]       {}   \n2                                              [–ö–∞—Ç–∞—Ä–≥–µ–π—Ç]       {}   \n3                                   [–ë–æ–≥–¥–∞–Ω–∞ –•–º–µ–ª—å–Ω–∏—Ü–∫–æ–≥–æ]       {}   \n4        [–ï—Å—Ç—å —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ –µ–¥—É—Ç –≤–æ–µ–≤–∞—Ç—å –∑–∞ –≥–æ–Ω–æ—Ä–∞—Ä, –≤...       {}   \n...                                                    ...      ...   \n1607921                                                 []       {}   \n1607922           [–ß–∞–π, –∫–æ—Ñ–µ –∏ –¥—Ä—É–≥–∏–µ –∫–æ–ª–æ–Ω–∏–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã]       {}   \n1607923                                                 []       {}   \n1607924  [–¥–æ–º–æ–≥–∞—Ç–µ–ª—å—Å—Ç–≤, –ø–∞—Ä—Ç–∏—è –ö–æ–∑–∞–∫–∞-–õ–∞–≤—Ä–æ–≤–∞, –ø–∞—Ä—Ç–∏—è ...       {}   \n1607925                                [–ü—è—Ä –≤–æ –≤—Ä–µ–º—è —á—É–º—ã]       {}   \n\n0                                      message_no_hashtags  \\\n0           –ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å   \n1        –í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...   \n2        \"–ö–∞—Ç–∞—Ä–≥–µ–π—Ç\" –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...   \n3        –í –≥–æ—Å—Ç—è—Ö —É  –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø...   \n4        –ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...   \n...                                                    ...   \n1607921  –ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏:  –î–æ–Ω–∞—Å—Ç—Ä–æ–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –∫—Ç–æ...   \n1607922  –ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...   \n1607923  –¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...   \n1607924  –û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...   \n1607925  –•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ \"...   \n\n0                                            message_clean  \\\n0           –ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å   \n1        –í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...   \n2        –ö–∞—Ç–∞—Ä–≥–µ–π—Ç –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ—Ä—Ä...   \n3        –í –≥–æ—Å—Ç—è—Ö —É –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø—Ä...   \n4        –ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...   \n...                                                    ...   \n1607921  –ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏: –î–æ–Ω–∞—Å—Ç—Ä–æ–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –∫—Ç–æ-...   \n1607922  –ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...   \n1607923  –¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...   \n1607924  –û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...   \n1607925  –•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ –ü...   \n\n0                                 message_words_only_lower  \n0            –∞ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç –ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å  \n1        –≤ —Ä–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å –Ω...  \n2        –∫–∞—Ç–∞—Ä–≥–µ–π—Ç –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã –æ–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ—Ä—Ä—É–ø...  \n3        –≤ –≥–æ—Å—Ç—è—Ö —É –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø—Ä...  \n4        –≥–ª–∞–≤–∞ –º–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –≥—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...  \n...                                                    ...  \n1607921  –±–æ—Ç –¥–ª—è —Å–≤—è–∑–∏ –¥–æ–Ω–∞—Å—Ç—Ä–æ–µ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –µ—Å–ª–∏ –∫—Ç–æ—Ç–æ –Ω...  \n1607922  –ø–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –º–∞—Ä–∫–µ –∑–∞—Ö–∞—Ä–æ–≤–µ —á–µ–ª–æ–≤–µ–∫–µ –∫–æ—Ç–æ...  \n1607923  —Ç—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω —á—Ç–æ –∫–æ–Ω–µ—á–Ω–æ –∑–∞—Å–ª—É...  \n1607924  –æ—Ç—Å—Ç–∞–≤–∫–∞ –∫—É—Ä—Ç–∞ –≤–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...  \n1607925  —Ö–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ –ø...  \n\n[1226517 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>views</th>\n      <th>reactions</th>\n      <th>to_id</th>\n      <th>fwd_from</th>\n      <th>message</th>\n      <th>type</th>\n      <th>duration</th>\n      <th>channel_name</th>\n      <th>...</th>\n      <th>message_no_emoji</th>\n      <th>url_list</th>\n      <th>message_no_urls</th>\n      <th>mentions</th>\n      <th>message_no_mentions</th>\n      <th>quotes</th>\n      <th>hashtags</th>\n      <th>message_no_hashtags</th>\n      <th>message_clean</th>\n      <th>message_words_only_lower</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12347</td>\n      <td>2022-12-15 16:32:15+00:00</td>\n      <td>9914.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1183570279)</td>\n      <td>NaN</td>\n      <td>–ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å...</td>\n      <td>photo</td>\n      <td>NaN</td>\n      <td>mardanaka</td>\n      <td>...</td>\n      <td>–ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å...</td>\n      <td>[www.youtube.com]</td>\n      <td>–ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å</td>\n      <td>[]</td>\n      <td>–ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å</td>\n      <td>[]</td>\n      <td>{}</td>\n      <td>–ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å</td>\n      <td>–ê —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å</td>\n      <td>–∞ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∏–¥–µ—Ç –ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12346</td>\n      <td>2022-12-15 15:00:03+00:00</td>\n      <td>29207.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1183570279)</td>\n      <td>NaN</td>\n      <td>–í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...</td>\n      <td>photo</td>\n      <td>NaN</td>\n      <td>mardanaka</td>\n      <td>...</td>\n      <td>–í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...</td>\n      <td>[]</td>\n      <td>–í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...</td>\n      <td>[]</td>\n      <td>–í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...</td>\n      <td>[–ú–≠–§. –≠–∫–æ–Ω–æ–º–∏–∫–∞ –¥–ª—è –ª—é–¥–µ–π]</td>\n      <td>{}</td>\n      <td>–í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...</td>\n      <td>–í –†–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ, –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å ...</td>\n      <td>–≤ —Ä–æ—Å—Å–∏–∏ –µ—â—ë –µ—Å—Ç—å —Ç–µ –∫—Ç–æ —Å–ø–æ—Å–æ–±–µ–Ω –≤–æ–∑—Ä–æ–∂–¥–∞—Ç—å –Ω...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12345</td>\n      <td>2022-12-15 14:21:22+00:00</td>\n      <td>41058.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1183570279)</td>\n      <td>NaN</td>\n      <td>¬´–ö–∞—Ç–∞—Ä–≥–µ–π—Ç¬ª –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>mardanaka</td>\n      <td>...</td>\n      <td>¬´–ö–∞—Ç–∞—Ä–≥–µ–π—Ç¬ª –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...</td>\n      <td>[]</td>\n      <td>¬´–ö–∞—Ç–∞—Ä–≥–µ–π—Ç¬ª –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...</td>\n      <td>[]</td>\n      <td>\"–ö–∞—Ç–∞—Ä–≥–µ–π—Ç\" –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...</td>\n      <td>[–ö–∞—Ç–∞—Ä–≥–µ–π—Ç]</td>\n      <td>{}</td>\n      <td>\"–ö–∞—Ç–∞—Ä–≥–µ–π—Ç\" –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ...</td>\n      <td>–ö–∞—Ç–∞—Ä–≥–µ–π—Ç –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã - –û–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ—Ä—Ä...</td>\n      <td>–∫–∞—Ç–∞—Ä–≥–µ–π—Ç –Ω–∞–±–∏—Ä–∞–µ—Ç –æ–±–æ—Ä–æ—Ç—ã –æ–±–≤–∏–Ω—è–µ–º–∞—è –≤ –∫–æ—Ä—Ä—É–ø...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12344</td>\n      <td>2022-12-15 13:08:35+00:00</td>\n      <td>40696.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1183570279)</td>\n      <td>MessageFwdHeader(date=datetime.datetime(2022, ...</td>\n      <td>üî•–í –≥–æ—Å—Ç—è—Ö —É @Metametrica –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ ...</td>\n      <td>photo</td>\n      <td>NaN</td>\n      <td>mardanaka</td>\n      <td>...</td>\n      <td>–í –≥–æ—Å—Ç—è—Ö —É @Metametrica –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ ...</td>\n      <td>[]</td>\n      <td>–í –≥–æ—Å—Ç—è—Ö —É @Metametrica –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ ...</td>\n      <td>[Metametrica, Metametrica]</td>\n      <td>–í –≥–æ—Å—Ç—è—Ö —É  –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø...</td>\n      <td>[–ë–æ–≥–¥–∞–Ω–∞ –•–º–µ–ª—å–Ω–∏—Ü–∫–æ–≥–æ]</td>\n      <td>{}</td>\n      <td>–í –≥–æ—Å—Ç—è—Ö —É  –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø...</td>\n      <td>–í –≥–æ—Å—Ç—è—Ö —É –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø—Ä...</td>\n      <td>–≤ –≥–æ—Å—Ç—è—Ö —É –ø–æ–±—ã–≤–∞–ª–∏ —Ç–æ–≤–∞—Ä–∏—â–∏ –∏–∑ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø—Ä...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12343</td>\n      <td>2022-12-15 12:31:23+00:00</td>\n      <td>51690.0</td>\n      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n      <td>PeerChannel(channel_id=1183570279)</td>\n      <td>NaN</td>\n      <td>–ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>mardanaka</td>\n      <td>...</td>\n      <td>–ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...</td>\n      <td>[]</td>\n      <td>–ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...</td>\n      <td>[]</td>\n      <td>–ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...</td>\n      <td>[–ï—Å—Ç—å —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ –µ–¥—É—Ç –≤–æ–µ–≤–∞—Ç—å –∑–∞ –≥–æ–Ω–æ—Ä–∞—Ä, –≤...</td>\n      <td>{}</td>\n      <td>–ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...</td>\n      <td>–ì–ª–∞–≤–∞ –ú–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –ì—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...</td>\n      <td>–≥–ª–∞–≤–∞ –º–∏–Ω–æ–±–æ—Ä–æ–Ω—ã –≥—Ä—É–∑–∏–∏ –Ω–∞–∑–≤–∞–ª –≥—Ä—É–∑–∏–Ω—Å–∫–∏—Ö –Ω–∞–µ–º...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1607921</th>\n      <td>7</td>\n      <td>2019-09-28 10:13:52+00:00</td>\n      <td>3190.0</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1253974160)</td>\n      <td>NaN</td>\n      <td>–ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏: @obrazbuduschego2_bot –î–æ–Ω–∞—Å—Ç—Ä–æ–µ...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>obrazbuduschego2</td>\n      <td>...</td>\n      <td>–ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏: @obrazbuduschego2_bot –î–æ–Ω–∞—Å—Ç—Ä–æ–µ...</td>\n      <td>[]</td>\n      <td>–ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏: @obrazbuduschego2_bot –î–æ–Ω–∞—Å—Ç—Ä–æ–µ...</td>\n      <td>[obrazbuduschego2_bot, protonmail]</td>\n      <td>–ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏:  –î–æ–Ω–∞—Å—Ç—Ä–æ–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –∫—Ç–æ...</td>\n      <td>[]</td>\n      <td>{}</td>\n      <td>–ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏:  –î–æ–Ω–∞—Å—Ç—Ä–æ–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –∫—Ç–æ...</td>\n      <td>–ë–æ—Ç –¥–ª—è —Å–≤—è–∑–∏: –î–æ–Ω–∞—Å—Ç—Ä–æ–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –∫—Ç–æ-...</td>\n      <td>–±–æ—Ç –¥–ª—è —Å–≤—è–∑–∏ –¥–æ–Ω–∞—Å—Ç—Ä–æ–µ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –µ—Å–ª–∏ –∫—Ç–æ—Ç–æ –Ω...</td>\n    </tr>\n    <tr>\n      <th>1607922</th>\n      <td>6</td>\n      <td>2019-09-28 09:35:07+00:00</td>\n      <td>3239.0</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1253974160)</td>\n      <td>NaN</td>\n      <td>–ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>obrazbuduschego2</td>\n      <td>...</td>\n      <td>–ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...</td>\n      <td>[]</td>\n      <td>–ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...</td>\n      <td>[]</td>\n      <td>–ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...</td>\n      <td>[–ß–∞–π, –∫–æ—Ñ–µ –∏ –¥—Ä—É–≥–∏–µ –∫–æ–ª–æ–Ω–∏–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã]</td>\n      <td>{}</td>\n      <td>–ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...</td>\n      <td>–ü–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –ú–∞—Ä–∫–µ –ó–∞—Ö–∞—Ä–æ–≤–µ, —á–µ–ª–æ–≤–µ–∫–µ, –∫–æ...</td>\n      <td>–ø–µ—á–∞–ª—å–Ω–∞—è –≤–µ—Å—Ç—å –æ –º–∞—Ä–∫–µ –∑–∞—Ö–∞—Ä–æ–≤–µ —á–µ–ª–æ–≤–µ–∫–µ –∫–æ—Ç–æ...</td>\n    </tr>\n    <tr>\n      <th>1607923</th>\n      <td>5</td>\n      <td>2019-09-28 07:34:47+00:00</td>\n      <td>314.0</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1253974160)</td>\n      <td>MessageFwdHeader(date=datetime.datetime(2019, ...</td>\n      <td>–¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>obrazbuduschego2</td>\n      <td>...</td>\n      <td>–¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...</td>\n      <td>[]</td>\n      <td>–¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...</td>\n      <td>[]</td>\n      <td>–¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...</td>\n      <td>[]</td>\n      <td>{}</td>\n      <td>–¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...</td>\n      <td>–¢—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω, —á—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –∑–∞...</td>\n      <td>—Ç—Ä–∞–º–ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—á–µ–Ω —á—Ç–æ –∫–æ–Ω–µ—á–Ω–æ –∑–∞—Å–ª—É...</td>\n    </tr>\n    <tr>\n      <th>1607924</th>\n      <td>4</td>\n      <td>2019-09-28 07:08:55+00:00</td>\n      <td>4339.0</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1253974160)</td>\n      <td>NaN</td>\n      <td>–û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...</td>\n      <td>text</td>\n      <td>NaN</td>\n      <td>obrazbuduschego2</td>\n      <td>...</td>\n      <td>–û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...</td>\n      <td>[]</td>\n      <td>–û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...</td>\n      <td>[]</td>\n      <td>–û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...</td>\n      <td>[–¥–æ–º–æ–≥–∞—Ç–µ–ª—å—Å—Ç–≤, –ø–∞—Ä—Ç–∏—è –ö–æ–∑–∞–∫–∞-–õ–∞–≤—Ä–æ–≤–∞, –ø–∞—Ä—Ç–∏—è ...</td>\n      <td>{}</td>\n      <td>–û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...</td>\n      <td>–û—Ç—Å—Ç–∞–≤–∫–∞ –ö—É—Ä—Ç–∞ –í–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...</td>\n      <td>–æ—Ç—Å—Ç–∞–≤–∫–∞ –∫—É—Ä—Ç–∞ –≤–æ–ª–∫–µ—Ä–∞ —Å –ø–æ—Å—Ç–∞ —Å–ø–µ—Ü–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ...</td>\n    </tr>\n    <tr>\n      <th>1607925</th>\n      <td>3</td>\n      <td>2019-09-27 21:31:04+00:00</td>\n      <td>105193.0</td>\n      <td>NaN</td>\n      <td>PeerChannel(channel_id=1253974160)</td>\n      <td>NaN</td>\n      <td>–•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ ¬´...</td>\n      <td>photo</td>\n      <td>NaN</td>\n      <td>obrazbuduschego2</td>\n      <td>...</td>\n      <td>–•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ ¬´...</td>\n      <td>[t.me]</td>\n      <td>–•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ ¬´...</td>\n      <td>[russica2, kremlebezBashennik, master_pera, sh...</td>\n      <td>–•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ \"...</td>\n      <td>[–ü—è—Ä –≤–æ –≤—Ä–µ–º—è —á—É–º—ã]</td>\n      <td>{}</td>\n      <td>–•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ \"...</td>\n      <td>–•–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ –ü...</td>\n      <td>—Ö–æ—Ç–µ–ª –±—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –≤—Å–µ–º —á–∏—Ç–∞—Ç–µ–ª—è–º –∫–∞–Ω–∞–ª–∞ –ø...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1226517 rows √ó 27 columns</p>\n</div>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "'–∏ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –µ–ª–µ–Ω—É —Å–µ—Ä–≤–µ—Ç—Ç–∞–∑ –æ–Ω–∞ —Ç–∞–º –º–µ—Å—Ç–∞–º–∏ —Å—Ä—ã–≤–∞–µ—Ç –ø–æ–∫—Ä–æ–≤—ã –ø—Ä–æ –∞–ª—å–±–∞—Ü –±—Ä–∞—É–¥–µ—Ä–∞ –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ –∏ –≤–æ–æ–±—â–µ –æ–Ω–∞ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∞—è'"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels.message_words_only_lower.iloc[33330]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#pymorphy2\n",
    "#sparknlp\n",
    "#–Ω–∞ —á–æ–º—É —Ç—Ä–µ–Ω—É–≤–∞–≤—Å—è spacy - –≤–∑—è—Ç–∏ –∑ —Ü—å–æ–≥–æ –∫–æ—Ä–ø—É—Å—É —Å–ª–æ–≤–Ω–∏–∫\n",
    "#–≤–∑—è—Ç–∏—Å–ª–æ–≤–Ω–∏–∫\n",
    "#—Å–ª—É–∂–±–æ–≤—ñ —á–∞—Å—Ç–∏–Ω–∏ –º–æ–≤–∏ –∑–∞–±—Ä–∞—Ç–∏"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}