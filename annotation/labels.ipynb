{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have created a 20% overlap for the samples to be labeled to assess the inter-rated agreement. Since annotator vary for each label duplicate pair, we can't use the sklearn's solution as it assumes that raters are the same in each case. Averaging the sklearn's  cohen_kappa_score along the pairs is not a viable solution since if you only have one data point per rater pair, the Cohen's kappa score calculation will result in a warning because it expects more variation in the data (or will return 0 if values are different).\n",
    "\n",
    "We have calculated the Cohen's kappa for the dataset with the (wrong) assumption that there are only two annotators.\n",
    "Further we improved the calculation with averaging the pairs, for that we have used this [solution](https://towardsdatascience.com/inter-annotator-agreement-2f46c6d37bf3) instead."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/inter-annotator-agreement-2f46c6d37bf3\n",
    "def cohen_kappa(ann1, ann2):\n",
    "    \"\"\"Computes Cohen kappa for pair-wise annotators.\n",
    "    :param ann1: annotations provided by first annotator\n",
    "    :type ann1: list\n",
    "    :param ann2: annotations provided by second annotator\n",
    "    :type ann2: list\n",
    "    :rtype: float\n",
    "    :return: Cohen kappa statistic\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for an1, an2 in zip(ann1, ann2):\n",
    "        if an1 == an2:\n",
    "            count += 1\n",
    "    A = count / len(ann1)  # observed agreement A (Po)\n",
    "\n",
    "    uniq = set(ann1 + ann2)\n",
    "    E = 0  # expected agreement E (Pe)\n",
    "    for item in uniq:\n",
    "        cnt1 = ann1.count(item)\n",
    "        cnt2 = ann2.count(item)\n",
    "        count = ((cnt1 / len(ann1)) * (cnt2 / len(ann2)))\n",
    "        E += count\n",
    "\n",
    "    return round((A - E) / (1 - E), 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading and preprocessing the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_labels = pd.read_json('/Users/katerynaburovova/PycharmProjects/dehumanization/annotation/labels_ready.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "import json\n",
    "def extract_class_pairs(json_lst):\n",
    "    pairs = []\n",
    "    for json_str in json_lst:\n",
    "        question_title = json_str['title']\n",
    "        answer_title = json_str['answer']['title']\n",
    "        pairs.append([question_title,answer_title])\n",
    "    return pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "df_labels['pairs'] = df_labels['Label'].apply(lambda x: extract_class_pairs(x['classifications']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "df = df_labels[['Created By', 'pairs', 'External ID']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_11694/3128516445.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(unique_rows.index, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "value_counts = df['External ID'].value_counts()\n",
    "unique_rows = df[df['External ID'].isin(value_counts[value_counts == 1].index)]\n",
    "df.drop(unique_rows.index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_11694/262876240.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df['pairs'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_11694/262876240.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df['pairs'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "/var/folders/2w/hygxgpp5353_dy_tk88gw2100000gn/T/ipykernel_11694/262876240.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df['pairs'].apply(lambda x: x[i] if len(x) > i else None)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    col_name = 'pair{}'.format(i+1)\n",
    "    df[col_name] = df['pairs'].apply(lambda x: x[i] if len(x) > i else None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "df = df[~df['pair1'].isna()]\n",
    "df.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "['Чи прирівнюються українці до неістот, тварин чи людей, позбавлених людських рис (частково або повністю)?',\n 'ні']"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = df['pair2'].iloc[9]\n",
    "text2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "['Чи присутня в тексті емоційна оцінка українців?', 'ні, оцінка не присутня']"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = df['pair3'].iloc[9]\n",
    "text3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "def replace_with(cell, replace_list):\n",
    "    if cell is None:\n",
    "        return replace_list\n",
    "    else:\n",
    "        return cell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "df[\"Dehumanization\"] = df.pair2.apply(lambda x: replace_with(x, text2)[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "df[\"Emotion\"] = df.pair3.apply(lambda x: replace_with(x, text3)[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "df[\"Mention\"] = df['pair1'].apply(lambda x: x[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "df = df.sort_values(by='External ID')\n",
    "df.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First attempt to calculate with the assumption that annotators are same"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "df['Rater'] = ['Rater1' if i % 2 == 0 else 'Rater2' for i in range(len(df))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# define a function to calculate Cohen's kappa for a given column\n",
    "def calculate_kappa(column_name):\n",
    "    rater1_labels = df[column_name].loc[df['Rater'] == 'Rater1'].tolist()\n",
    "    rater2_labels = df[column_name].loc[df['Rater'] == 'Rater2'].tolist()\n",
    "    kappa = cohen_kappa_score(rater1_labels, rater2_labels)\n",
    "    return kappa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa for Dehumanization: 0.50\n",
      "Cohen's kappa for Emotion: 0.49\n",
      "Cohen's kappa for Mention: 0.64\n"
     ]
    }
   ],
   "source": [
    "# calculate Cohen's kappa for the 'Dehumanization' column\n",
    "dehumanization_kappa = calculate_kappa('Dehumanization')\n",
    "print(\"Cohen's kappa for Dehumanization: {:.2f}\".format(dehumanization_kappa))\n",
    "\n",
    "# repeat the above for the 'Emotion' and 'Mention' columns\n",
    "emotion_kappa = calculate_kappa('Emotion')\n",
    "print(\"Cohen's kappa for Emotion: {:.2f}\".format(emotion_kappa))\n",
    "\n",
    "mention_kappa = calculate_kappa('Mention')\n",
    "print(\"Cohen's kappa for Mention: {:.2f}\".format(mention_kappa))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correct calculation under the real conditions of different annotators"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "def calculate_cohens_kappa(df, col_name):\n",
    "    # creating the data for question\n",
    "    df_column = df[['External ID', 'Created By', col_name]]\n",
    "\n",
    "    # identifying the overlapping samples and raters who labeled them\n",
    "    overlapping_samples = df_column.groupby('External ID').filter(lambda x: len(x) > 1)\n",
    "    unique_sample_ids = overlapping_samples['External ID'].unique()\n",
    "    rater_pairs = []\n",
    "    for sample_id in unique_sample_ids:\n",
    "        raters = overlapping_samples[overlapping_samples['External ID'] == sample_id]['Created By'].tolist()\n",
    "        rater_pairs.append(raters)\n",
    "\n",
    "    # averaging the kappa scores for pairs\n",
    "    kappa_scores = []\n",
    "    for sample_id, rater_pair in zip(unique_sample_ids, rater_pairs):\n",
    "        sample_data = overlapping_samples[overlapping_samples['External ID'] == sample_id]\n",
    "        rater1_labels = sample_data[sample_data['Created By'] == rater_pair[0]][col_name].tolist()[0]\n",
    "        rater2_labels = sample_data[sample_data['Created By'] == rater_pair[1]][col_name].tolist()[0]\n",
    "        kappa = cohen_kappa(rater1_labels, rater2_labels)\n",
    "        kappa_scores.append(kappa)\n",
    "    mean_kappa_score = sum(kappa_scores) / len(kappa_scores)\n",
    "\n",
    "    return mean_kappa_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8456889204545459"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cohens_kappa(df, 'Dehumanization')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "data": {
      "text/plain": "0.969028693181818"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cohens_kappa(df, 'Mention')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8472082386363637"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cohens_kappa(df, 'Emotion')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}