{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#python ./spert.py train --config configs/train_reduced.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting the texts that are not in labeled data, separating into 2 parts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('/Users/katerynaburovova/PycharmProjects/dehumanization/annotation/final_labels.csv', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "df_labels = df_labels[df_labels['Dehumanization']!='не можу визначитись з правильною відповіддю'].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "df_labels['label'] = df_labels['Dehumanization'].apply(lambda x: 0 if x=='ні' else 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "                      Emotion Dehumanization Mention   External ID  \\\n1219  так, присутня негативна            так     так     row_0.txt   \n1218   ні, оцінка не присутня             ні      ні     row_1.txt   \n1591  так, присутня негативна            так     так    row_10.txt   \n1198  так, присутня негативна            так     так   row_100.txt   \n3247   ні, оцінка не присутня             ні     так  row_1000.txt   \n...                       ...            ...     ...           ...   \n3613   ні, оцінка не присутня             ні     так   row_995.txt   \n3612  так, присутня негативна             ні     так   row_996.txt   \n4121  так, присутня негативна             ні     так   row_997.txt   \n4120   ні, оцінка не присутня            так     так   row_998.txt   \n3248   ні, оцінка не присутня             ні      ні   row_999.txt   \n\n                        Created By  \\\n1219      snizannabotvin@gmail.com   \n1218      snizannabotvin@gmail.com   \n1591      snizannabotvin@gmail.com   \n1198      snizannabotvin@gmail.com   \n3247        tutovadesign@gmail.com   \n...                            ...   \n3613        tutovadesign@gmail.com   \n3612        tutovadesign@gmail.com   \n4121  yevhen.marchenko91@gmail.com   \n4120  yevhen.marchenko91@gmail.com   \n3248        tutovadesign@gmail.com   \n\n                                                   text  rating  label  \n1219  Всвязи с этим немного поправлю коллег ⤵️  \"Они...       4      1  \n1218  Литературный критик Галина Юзефович о новом ро...       4      0  \n1591  Почему на базах неонацистов стоят языческие ис...       4      1  \n1198  Группа добровольцев-медиков из Чеченской Респу...       4      1  \n3247  ВСУшники, переходите на сторону добра, у нас т...       5      0  \n...                                                 ...     ...    ...  \n3613  Утренний брифинг Минобороны России:  ▪️ россий...       5      0  \n3612  И понеслась мазепинщино-петлюровщино-бандеровщ...       5      0  \n4121  Наш соратник по русскому движению Алексей Сели...       3      0  \n4120  Хорошее видео от 4 бригады НМ ЛНР https://t.me...       3      1  \n3248  Замоскворецкий районный суд Москвы отклонил ис...       5      0  \n\n[3494 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotion</th>\n      <th>Dehumanization</th>\n      <th>Mention</th>\n      <th>External ID</th>\n      <th>Created By</th>\n      <th>text</th>\n      <th>rating</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1219</th>\n      <td>так, присутня негативна</td>\n      <td>так</td>\n      <td>так</td>\n      <td>row_0.txt</td>\n      <td>snizannabotvin@gmail.com</td>\n      <td>Всвязи с этим немного поправлю коллег ⤵️  \"Они...</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1218</th>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>ні</td>\n      <td>row_1.txt</td>\n      <td>snizannabotvin@gmail.com</td>\n      <td>Литературный критик Галина Юзефович о новом ро...</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1591</th>\n      <td>так, присутня негативна</td>\n      <td>так</td>\n      <td>так</td>\n      <td>row_10.txt</td>\n      <td>snizannabotvin@gmail.com</td>\n      <td>Почему на базах неонацистов стоят языческие ис...</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>так, присутня негативна</td>\n      <td>так</td>\n      <td>так</td>\n      <td>row_100.txt</td>\n      <td>snizannabotvin@gmail.com</td>\n      <td>Группа добровольцев-медиков из Чеченской Респу...</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3247</th>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_1000.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>ВСУшники, переходите на сторону добра, у нас т...</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3613</th>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_995.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>Утренний брифинг Минобороны России:  ▪️ россий...</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3612</th>\n      <td>так, присутня негативна</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_996.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>И понеслась мазепинщино-петлюровщино-бандеровщ...</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4121</th>\n      <td>так, присутня негативна</td>\n      <td>ні</td>\n      <td>так</td>\n      <td>row_997.txt</td>\n      <td>yevhen.marchenko91@gmail.com</td>\n      <td>Наш соратник по русскому движению Алексей Сели...</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4120</th>\n      <td>ні, оцінка не присутня</td>\n      <td>так</td>\n      <td>так</td>\n      <td>row_998.txt</td>\n      <td>yevhen.marchenko91@gmail.com</td>\n      <td>Хорошее видео от 4 бригады НМ ЛНР https://t.me...</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3248</th>\n      <td>ні, оцінка не присутня</td>\n      <td>ні</td>\n      <td>ні</td>\n      <td>row_999.txt</td>\n      <td>tutovadesign@gmail.com</td>\n      <td>Замоскворецкий районный суд Москвы отклонил ис...</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3494 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "dehumanizing_target_sequences = ['рейх', 'нацист', 'питек', 'бандерло', 'свино', 'вермахт', 'питек']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def contains_target_sequence(text, target_sequences):\n",
    "    for seq in target_sequences:\n",
    "        if re.search(seq, text, re.IGNORECASE):\n",
    "            return True\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def split_test_data_by_target_sequences(X, y, text_columns, target_sequences):\n",
    "    contains_seq = X.apply(lambda row: any(contains_target_sequence(row[col], target_sequences) for col in text_columns), axis=1)\n",
    "    X_pos, y_pos = X[contains_seq], y[contains_seq]\n",
    "    X_neg, y_neg = X[~contains_seq], y[~contains_seq]\n",
    "\n",
    "    return X_pos, y_pos, X_neg, y_neg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# excluding the rows that were labeled for SpERT training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "df_labels_CoNLL04 = pd.read_json('/Users/katerynaburovova/PycharmProjects/dehumanization/annotation/CoNLL04_annotation/SpERT_dataset/export_400samples.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "exclusion_list = df_labels_CoNLL04['External ID'].to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "['row_1566.txt',\n 'row_1565.txt',\n 'row_1564.txt',\n 'row_1563.txt',\n 'row_1562.txt',\n 'row_1561.txt',\n 'row_1560.txt',\n 'row_1559.txt',\n 'row_1558.txt',\n 'row_1557.txt',\n 'row_1556.txt',\n 'row_1555.txt',\n 'row_1554.txt',\n 'row_1553.txt',\n 'row_1552.txt',\n 'row_1551.txt',\n 'row_1550.txt',\n 'row_1549.txt',\n 'row_1548.txt',\n 'row_1547.txt',\n 'row_1546.txt',\n 'row_1545.txt',\n 'row_566.txt',\n 'row_565.txt',\n 'row_564.txt',\n 'row_563.txt',\n 'row_562.txt',\n 'row_561.txt',\n 'row_560.txt',\n 'row_559.txt',\n 'row_558.txt',\n 'row_557.txt',\n 'row_555.txt',\n 'row_554.txt',\n 'row_1544.txt',\n 'row_1543.txt',\n 'row_1542.txt',\n 'row_556.txt',\n 'row_1541.txt',\n 'row_1540.txt',\n 'row_553.txt',\n 'row_552.txt',\n 'row_551.txt',\n 'row_550.txt',\n 'row_549.txt',\n 'row_548.txt',\n 'row_547.txt',\n 'row_1539.txt',\n 'row_1538.txt',\n 'row_1537.txt',\n 'row_1536.txt',\n 'row_1535.txt',\n 'row_1534.txt',\n 'row_1533.txt',\n 'row_1532.txt',\n 'row_1531.txt',\n 'row_1530.txt',\n 'row_1529.txt',\n 'row_1528.txt',\n 'row_1527.txt',\n 'row_1526.txt',\n 'row_1525.txt',\n 'row_1524.txt',\n 'row_1523.txt',\n 'row_1522.txt',\n 'row_1521.txt',\n 'row_1520.txt',\n 'row_1519.txt',\n 'row_1518.txt',\n 'row_1517.txt',\n 'row_1516.txt',\n 'row_1515.txt',\n 'row_1514.txt',\n 'row_1513.txt',\n 'row_1512.txt',\n 'row_1511.txt',\n 'row_1510.txt',\n 'row_1509.txt',\n 'row_1508.txt',\n 'row_1507.txt',\n 'row_1506.txt',\n 'row_1505.txt',\n 'row_1504.txt',\n 'row_1503.txt',\n 'row_1502.txt',\n 'row_1501.txt',\n 'row_546.txt',\n 'row_545.txt',\n 'row_544.txt',\n 'row_1500.txt',\n 'row_1499.txt',\n 'row_1498.txt',\n 'row_1497.txt',\n 'row_1496.txt',\n 'row_1495.txt',\n 'row_1494.txt',\n 'row_1493.txt',\n 'row_1492.txt',\n 'row_1491.txt',\n 'row_1490.txt',\n 'row_1489.txt',\n 'row_1488.txt',\n 'row_1487.txt',\n 'row_1486.txt',\n 'row_1485.txt',\n 'row_1484.txt',\n 'row_1483.txt',\n 'row_1482.txt',\n 'row_543.txt',\n 'row_542.txt',\n 'row_541.txt',\n 'row_540.txt',\n 'row_539.txt',\n 'row_538.txt',\n 'row_537.txt',\n 'row_536.txt',\n 'row_1481.txt',\n 'row_1478.txt',\n 'row_1477.txt',\n 'row_1476.txt',\n 'row_1475.txt',\n 'row_1474.txt',\n 'row_1473.txt',\n 'row_1472.txt',\n 'row_1471.txt',\n 'row_1470.txt',\n 'row_1469.txt',\n 'row_1468.txt',\n 'row_1467.txt',\n 'row_1466.txt',\n 'row_1465.txt',\n 'row_1464.txt',\n 'row_1463.txt',\n 'row_535.txt',\n 'row_532.txt',\n 'row_531.txt',\n 'row_534.txt',\n 'row_533.txt',\n 'row_530.txt',\n 'row_529.txt',\n 'row_528.txt',\n 'row_1462.txt',\n 'row_527.txt',\n 'row_526.txt',\n 'row_525.txt',\n 'row_524.txt',\n 'row_523.txt',\n 'row_522.txt',\n 'row_521.txt',\n 'row_520.txt',\n 'row_519.txt',\n 'row_518.txt',\n 'row_517.txt',\n 'row_1461.txt',\n 'row_1458.txt',\n 'row_1457.txt',\n 'row_1456.txt',\n 'row_1455.txt',\n 'row_1453.txt',\n 'row_1452.txt',\n 'row_1451.txt',\n 'row_1454.txt',\n 'row_511.txt',\n 'row_510.txt',\n 'row_509.txt',\n 'row_508.txt',\n 'row_507.txt',\n 'row_506.txt',\n 'row_1449.txt',\n 'row_505.txt',\n 'row_504.txt',\n 'row_1450.txt',\n 'row_1448.txt',\n 'row_1447.txt',\n 'row_1446.txt',\n 'row_1442.txt',\n 'row_1445.txt',\n 'row_1444.txt',\n 'row_1443.txt',\n 'row_1441.txt',\n 'row_1440.txt',\n 'row_1439.txt',\n 'row_1436.txt',\n 'row_1435.txt',\n 'row_1438.txt',\n 'row_1437.txt',\n 'row_1434.txt',\n 'row_1431.txt',\n 'row_1430.txt',\n 'row_1433.txt',\n 'row_1432.txt',\n 'row_503.txt',\n 'row_502.txt',\n 'row_501.txt',\n 'row_500.txt',\n 'row_499.txt',\n 'row_498.txt',\n 'row_497.txt',\n 'row_1429.txt',\n 'row_496.txt',\n 'row_1480.txt',\n 'row_1479.txt',\n 'row_1460.txt',\n 'row_1459.txt',\n 'row_516.txt',\n 'row_515.txt',\n 'row_514.txt',\n 'row_513.txt',\n 'row_512.txt',\n 'row_1423.txt',\n 'row_1422.txt',\n 'row_1421.txt',\n 'row_1420.txt',\n 'row_1419.txt',\n 'row_1427.txt',\n 'row_1418.txt',\n 'row_495.txt',\n 'row_1428.txt',\n 'row_1426.txt',\n 'row_1417.txt',\n 'row_1416.txt',\n 'row_1425.txt',\n 'row_1424.txt',\n 'row_1415.txt',\n 'row_1413.txt',\n 'row_1412.txt',\n 'row_494.txt',\n 'row_1414.txt',\n 'row_493.txt',\n 'row_492.txt',\n 'row_491.txt',\n 'row_1408.txt',\n 'row_1411.txt',\n 'row_1410.txt',\n 'row_1409.txt',\n 'row_1407.txt',\n 'row_1403.txt',\n 'row_1406.txt',\n 'row_1405.txt',\n 'row_1404.txt',\n 'row_1402.txt',\n 'row_1401.txt',\n 'row_1400.txt',\n 'row_1399.txt',\n 'row_1398.txt',\n 'row_1397.txt',\n 'row_1393.txt',\n 'row_1396.txt',\n 'row_1395.txt',\n 'row_1394.txt',\n 'row_1392.txt',\n 'row_487.txt',\n 'row_490.txt',\n 'row_489.txt',\n 'row_488.txt',\n 'row_1391.txt',\n 'row_1390.txt',\n 'row_1389.txt',\n 'row_1388.txt',\n 'row_1387.txt',\n 'row_1386.txt',\n 'row_1382.txt',\n 'row_1385.txt',\n 'row_1384.txt',\n 'row_1383.txt',\n 'row_1381.txt',\n 'row_1377.txt',\n 'row_1380.txt',\n 'row_1379.txt',\n 'row_1378.txt',\n 'row_1376.txt',\n 'row_485.txt',\n 'row_1375.txt',\n 'row_1374.txt',\n 'row_486.txt',\n 'row_484.txt',\n 'row_483.txt',\n 'row_482.txt',\n 'row_481.txt',\n 'row_480.txt',\n 'row_1373.txt',\n 'row_1372.txt',\n 'row_1371.txt',\n 'row_1370.txt',\n 'row_1369.txt',\n 'row_1368.txt',\n 'row_1367.txt',\n 'row_1366.txt',\n 'row_1365.txt',\n 'row_1364.txt',\n 'row_1363.txt',\n 'row_1362.txt',\n 'row_1361.txt',\n 'row_1360.txt',\n 'row_1359.txt',\n 'row_1358.txt',\n 'row_1354.txt',\n 'row_1357.txt',\n 'row_1356.txt',\n 'row_1355.txt',\n 'row_479.txt',\n 'row_478.txt',\n 'row_477.txt',\n 'row_476.txt',\n 'row_475.txt',\n 'row_474.txt',\n 'row_1352.txt',\n 'row_473.txt',\n 'row_472.txt',\n 'row_1353.txt',\n 'row_1351.txt',\n 'row_1347.txt',\n 'row_1350.txt',\n 'row_1349.txt',\n 'row_1343.txt',\n 'row_1342.txt',\n 'row_1348.txt',\n 'row_1346.txt',\n 'row_1345.txt',\n 'row_1344.txt',\n 'row_1341.txt',\n 'row_1340.txt',\n 'row_1339.txt',\n 'row_1338.txt',\n 'row_466.txt',\n 'row_465.txt',\n 'row_464.txt',\n 'row_463.txt',\n 'row_1336.txt',\n 'row_1335.txt',\n 'row_1334.txt',\n 'row_1333.txt',\n 'row_1332.txt',\n 'row_1331.txt',\n 'row_1330.txt',\n 'row_1329.txt',\n 'row_1328.txt',\n 'row_1327.txt',\n 'row_1326.txt',\n 'row_1325.txt',\n 'row_1324.txt',\n 'row_1323.txt',\n 'row_1322.txt',\n 'row_1321.txt',\n 'row_1320.txt',\n 'row_1319.txt',\n 'row_1318.txt',\n 'row_1317.txt',\n 'row_462.txt',\n 'row_461.txt',\n 'row_460.txt',\n 'row_459.txt',\n 'row_458.txt',\n 'row_457.txt',\n 'row_456.txt',\n 'row_455.txt',\n 'row_454.txt',\n 'row_1316.txt',\n 'row_1315.txt',\n 'row_1314.txt',\n 'row_1313.txt',\n 'row_1312.txt',\n 'row_1311.txt',\n 'row_1310.txt',\n 'row_1309.txt',\n 'row_1308.txt',\n 'row_1307.txt',\n 'row_1306.txt',\n 'row_1305.txt',\n 'row_1304.txt',\n 'row_1303.txt',\n 'row_1302.txt',\n 'row_1301.txt',\n 'row_1300.txt',\n 'row_1299.txt',\n 'row_1298.txt',\n 'row_1297.txt',\n 'row_453.txt',\n 'row_452.txt',\n 'row_451.txt',\n 'row_450.txt',\n 'row_449.txt',\n 'row_448.txt',\n 'row_447.txt',\n 'row_446.txt',\n 'row_445.txt',\n 'row_1296.txt',\n 'row_1295.txt',\n 'row_1294.txt',\n 'row_1293.txt',\n 'row_1292.txt',\n 'row_1291.txt',\n 'row_1290.txt',\n 'row_1289.txt',\n 'row_1288.txt',\n 'row_1287.txt',\n 'row_1286.txt',\n 'row_1285.txt',\n 'row_1284.txt',\n 'row_1283.txt',\n 'row_1282.txt',\n 'row_1281.txt',\n 'row_1280.txt',\n 'row_1279.txt',\n 'row_1278.txt',\n 'row_1277.txt',\n 'row_444.txt',\n 'row_443.txt',\n 'row_442.txt',\n 'row_441.txt',\n 'row_440.txt',\n 'row_439.txt',\n 'row_438.txt',\n 'row_437.txt',\n 'row_436.txt',\n 'row_1276.txt',\n 'row_1275.txt',\n 'row_1274.txt',\n 'row_1273.txt',\n 'row_1272.txt',\n 'row_1271.txt',\n 'row_1270.txt',\n 'row_1269.txt',\n 'row_1268.txt',\n 'row_1267.txt',\n 'row_1266.txt',\n 'row_1265.txt',\n 'row_1264.txt',\n 'row_1263.txt',\n 'row_1262.txt',\n 'row_1261.txt',\n 'row_1260.txt',\n 'row_1259.txt',\n 'row_1258.txt',\n 'row_435.txt',\n 'row_434.txt',\n 'row_433.txt',\n 'row_432.txt',\n 'row_431.txt',\n 'row_430.txt',\n 'row_429.txt',\n 'row_428.txt',\n 'row_1257.txt',\n 'row_1256.txt',\n 'row_1255.txt',\n 'row_1254.txt',\n 'row_1253.txt',\n 'row_1252.txt',\n 'row_1251.txt',\n 'row_1250.txt',\n 'row_1249.txt',\n 'row_1248.txt',\n 'row_1247.txt',\n 'row_1246.txt',\n 'row_1245.txt',\n 'row_1244.txt',\n 'row_1243.txt',\n 'row_1242.txt',\n 'row_1241.txt',\n 'row_1240.txt',\n 'row_1239.txt',\n 'row_1238.txt',\n 'row_427.txt',\n 'row_426.txt',\n 'row_425.txt',\n 'row_424.txt',\n 'row_423.txt',\n 'row_422.txt',\n 'row_421.txt',\n 'row_420.txt',\n 'row_419.txt',\n 'row_418.txt',\n 'row_1237.txt',\n 'row_1236.txt',\n 'row_1235.txt',\n 'row_417.txt',\n 'row_416.txt',\n 'row_415.txt']"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusion_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df_clean_labels = df_labels[~df_labels['External ID'].isin(exclusion_list)].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "X_test_pos, y_test_pos, X_test_neg, y_test_neg = split_test_data_by_target_sequences(df_clean_labels[['text']], df_clean_labels['label'], ['text'], dehumanizing_target_sequences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return [token.text for token in nlp(text)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def get_SpERT_formatted_input(X):\n",
    "    formatted_texts = []\n",
    "\n",
    "    for text in X.text:\n",
    "        tokens = tokenize_text(text)\n",
    "        formatted_text = {\"tokens\": tokens}\n",
    "        formatted_texts.append([formatted_text, tokens, text])\n",
    "\n",
    "    return formatted_texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.88 s, sys: 139 ms, total: 9.02 s\n",
      "Wall time: 9.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test_pos_formatted = get_SpERT_formatted_input(X_test_pos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 160 ms, total: 16.6 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test_neg_formatted = get_SpERT_formatted_input(X_test_neg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "X_test_neg_list_of_dicts = []\n",
    "for doc in X_test_neg_formatted:\n",
    "    X_test_neg_list_of_dicts.append(doc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "X_test_pos_list_of_dicts = []\n",
    "for doc in X_test_pos_formatted:\n",
    "    X_test_pos_list_of_dicts.append(doc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path_neg_one_sample = '/Users/katerynaburovova/PycharmProjects/dehumanization/spert/data/datasets/test_datasets/test_neg.json'\n",
    "\n",
    "with open(file_path_neg_one_sample, 'w', encoding='utf-8') as f:\n",
    "    json.dump(X_test_neg_list_of_dicts, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "file_path_pos_one_sample = '/Users/katerynaburovova/PycharmProjects/dehumanization/spert/data/datasets/test_datasets/test_pos.json'\n",
    "\n",
    "with open(file_path_pos_one_sample, 'w', encoding='utf-8') as f:\n",
    "    json.dump(X_test_pos_list_of_dicts, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "file_n_path = '/Users/katerynaburovova/PycharmProjects/dehumanization/spert/data/predictions_neg.json'\n",
    "\n",
    "with open(file_n_path, 'r') as file:\n",
    "    data_neg = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_neg[0]['entities'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "file_p_path = '/Users/katerynaburovova/PycharmProjects/dehumanization/spert/data/predictions_pos.json'\n",
    "\n",
    "with open(file_p_path, 'r') as file:\n",
    "    data_pos = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "for sentence in data_neg:\n",
    "    if len(sentence['entities'])==0:\n",
    "        sentence['pred'] = 0\n",
    "    else:\n",
    "        sentence['pred'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "for sentence in data_pos:\n",
    "    if len(sentence['entities'])==0:\n",
    "        sentence['pred'] = 0\n",
    "    else:\n",
    "        sentence['pred'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "X_test_pos.reset_index(inplace = True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "text    Мобики 2-го батальона 56-й бригады ВСУ жалуютс...\nName: 13, dtype: object"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pos.iloc[13]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "{'tokens': ['Мобики',\n  '2-го',\n  'батальона',\n  '56-й',\n  'бригады',\n  'ВСУ',\n  'жалуются',\n  ',',\n  'что',\n  'их',\n  'без',\n  'подготовки',\n  'и',\n  'соответствующей',\n  'экипировки',\n  'кинули',\n  'на',\n  'Пески',\n  ',',\n  'где',\n  'у',\n  'хохловермахта',\n  'посыпался',\n  'фронт'],\n 'entities': [{'type': 'HIGH_UH_LOW_NH', 'start': 21, 'end': 22}],\n 'relations': [],\n 'pred': 1}"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pos[13]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "pos_predictions = [sentence['pred'] for sentence in data_pos]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "neg_predictions = [sentence['pred'] for sentence in data_neg]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.29      0.48      0.36        60\n",
      "     class_1       0.97      0.93      0.95       967\n",
      "\n",
      "    accuracy                           0.90      1027\n",
      "   macro avg       0.63      0.70      0.65      1027\n",
      "weighted avg       0.93      0.90      0.91      1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test_pos, pos_predictions, target_names=['class_0', 'class_1'])\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.87      0.94      0.90      1621\n",
      "     class_1       0.59      0.39      0.47       386\n",
      "\n",
      "    accuracy                           0.83      2007\n",
      "   macro avg       0.73      0.66      0.68      2007\n",
      "weighted avg       0.81      0.83      0.82      2007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test_neg, neg_predictions, target_names=['class_0', 'class_1'])\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sampling the timedata from the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. read timestep data\n",
    "2. sample the unedited texts\n",
    "3. get random sentences from selected text\n",
    "4. save this df with dates, authors\n",
    "5. write into df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}